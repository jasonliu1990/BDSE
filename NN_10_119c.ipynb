{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. read_csv 並做一點處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\n",
    "    'dataset/train.csv',usecols=[1,2,3,4,5],\n",
    "    dtype={'onpromotion':bool,\n",
    "           'store_nbr':int,\n",
    "           'item_nbr':int},\n",
    "    parse_dates=['date'],\n",
    "    converters={'unit_sales': lambda u: np.log1p(\n",
    "        float(u)) if float(u) > 0 else 0},\n",
    "    skiprows=range(1,66458909)  # 2016-01-01   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>unit_sales</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>105574</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>105575</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>105857</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>108634</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>108701</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  store_nbr  item_nbr  unit_sales  onpromotion\n",
       "0 2016-01-01         25    105574    2.564949        False\n",
       "1 2016-01-01         25    105575    2.302585        False\n",
       "2 2016-01-01         25    105857    1.386294        False\n",
       "3 2016-01-01         25    108634    1.386294        False\n",
       "4 2016-01-01         25    108701    1.098612         True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date           False\n",
       "store_nbr      False\n",
       "item_nbr       False\n",
       "unit_sales     False\n",
       "onpromotion    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>96995</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497040</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99197</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497041</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103501</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497042</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103520</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497043</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103665</th>\n",
       "      <th>2017-08-16</th>\n",
       "      <td>125497044</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      id  onpromotion\n",
       "store_nbr item_nbr date                              \n",
       "1         96995    2017-08-16  125497040        False\n",
       "          99197    2017-08-16  125497041        False\n",
       "          103501   2017-08-16  125497042        False\n",
       "          103520   2017-08-16  125497043        False\n",
       "          103665   2017-08-16  125497044        False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\n",
    "    'dataset/test.csv',usecols=[0,1,2,3,4],\n",
    "    dtype={'onpromotion':bool,\n",
    "           'store_nbr':int,\n",
    "           'item_nbr':int},\n",
    "    parse_dates=['date']\n",
    ").set_index(\n",
    "    ['store_nbr','item_nbr','date']\n",
    ")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family</th>\n",
       "      <th>class</th>\n",
       "      <th>perishable</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96995</th>\n",
       "      <td>GROCERY I</td>\n",
       "      <td>1093</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99197</th>\n",
       "      <td>GROCERY I</td>\n",
       "      <td>1067</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103501</th>\n",
       "      <td>CLEANING</td>\n",
       "      <td>3008</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103520</th>\n",
       "      <td>GROCERY I</td>\n",
       "      <td>1028</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103665</th>\n",
       "      <td>BREAD/BAKERY</td>\n",
       "      <td>2712</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                family  class  perishable\n",
       "item_nbr                                 \n",
       "96995        GROCERY I   1093           0\n",
       "99197        GROCERY I   1067           0\n",
       "103501        CLEANING   3008           0\n",
       "103520       GROCERY I   1028           0\n",
       "103665    BREAD/BAKERY   2712           1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = pd.read_csv(\n",
    "    \"dataset/items.csv\",\n",
    ").set_index(\"item_nbr\")\n",
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>type</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Santo Domingo</td>\n",
       "      <td>Santo Domingo de los Tsachilas</td>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    city                           state type  cluster\n",
       "store_nbr                                                             \n",
       "1                  Quito                       Pichincha    D       13\n",
       "2                  Quito                       Pichincha    D       13\n",
       "3                  Quito                       Pichincha    D        8\n",
       "4                  Quito                       Pichincha    D        9\n",
       "5          Santo Domingo  Santo Domingo de los Tsachilas    D        4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stores = pd.read_csv(\n",
    "    \"dataset/stores.csv\",\n",
    ").set_index('store_nbr')\n",
    "\n",
    "stores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. LabelEncode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "items['family'] = le.fit_transform(items['family'].values)\n",
    "stores['city'] = le.fit_transform(stores['city'].values)\n",
    "stores['state'] = le.fit_transform(stores['state'].values)\n",
    "stores['type'] = le.fit_transform(stores['type'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family</th>\n",
       "      <th>class</th>\n",
       "      <th>perishable</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96995</th>\n",
       "      <td>12</td>\n",
       "      <td>1093</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99197</th>\n",
       "      <td>12</td>\n",
       "      <td>1067</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103501</th>\n",
       "      <td>7</td>\n",
       "      <td>3008</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103520</th>\n",
       "      <td>12</td>\n",
       "      <td>1028</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103665</th>\n",
       "      <td>5</td>\n",
       "      <td>2712</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          family  class  perishable\n",
       "item_nbr                           \n",
       "96995         12   1093           0\n",
       "99197         12   1067           0\n",
       "103501         7   3008           0\n",
       "103520        12   1028           0\n",
       "103665         5   2712           1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4100 entries, 96995 to 2134244\n",
      "Data columns (total 3 columns):\n",
      "family        4100 non-null int64\n",
      "class         4100 non-null int64\n",
      "perishable    4100 non-null int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 128.1 KB\n"
     ]
    }
   ],
   "source": [
    "items.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 將欄位攤開, 沒有銷售紀錄的補0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017 = df_train.loc[df_train.date>=pd.datetime(2017,1,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "promo_train_2017 = df_2017.set_index(\n",
    "    [\"store_nbr\", \"item_nbr\", \"date\"])[[\"onpromotion\"]].unstack(\n",
    "        level=-1).fillna(False)\n",
    "promo_train_2017.columns = promo_train_2017.columns.get_level_values(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "promo_test_2017 = df_test[['onpromotion']].unstack(level=-1).fillna(False)\n",
    "promo_test_2017.columns = promo_test_2017.columns.get_level_values(1)\n",
    "promo_test_2017 = promo_test_2017.reindex(promo_train_2017.index).fillna(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "promo_2017 = pd.concat([promo_train_2017,promo_test_2017],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>2017-01-01 00:00:00</th>\n",
       "      <th>2017-01-02 00:00:00</th>\n",
       "      <th>2017-01-03 00:00:00</th>\n",
       "      <th>2017-01-04 00:00:00</th>\n",
       "      <th>2017-01-05 00:00:00</th>\n",
       "      <th>2017-01-06 00:00:00</th>\n",
       "      <th>2017-01-07 00:00:00</th>\n",
       "      <th>2017-01-08 00:00:00</th>\n",
       "      <th>2017-01-09 00:00:00</th>\n",
       "      <th>2017-01-10 00:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2017-08-22 00:00:00</th>\n",
       "      <th>2017-08-23 00:00:00</th>\n",
       "      <th>2017-08-24 00:00:00</th>\n",
       "      <th>2017-08-25 00:00:00</th>\n",
       "      <th>2017-08-26 00:00:00</th>\n",
       "      <th>2017-08-27 00:00:00</th>\n",
       "      <th>2017-08-28 00:00:00</th>\n",
       "      <th>2017-08-29 00:00:00</th>\n",
       "      <th>2017-08-30 00:00:00</th>\n",
       "      <th>2017-08-31 00:00:00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>96995</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99197</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103520</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103665</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105574</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 243 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "date                2017-01-01  2017-01-02  2017-01-03  2017-01-04  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995          False       False       False       False   \n",
       "          99197          False       False       False       False   \n",
       "          103520         False       False       False       False   \n",
       "          103665         False       False       False       False   \n",
       "          105574         False       False        True       False   \n",
       "\n",
       "date                2017-01-05  2017-01-06  2017-01-07  2017-01-08  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995          False       False       False       False   \n",
       "          99197          False       False       False       False   \n",
       "          103520         False       False       False       False   \n",
       "          103665         False       False       False       False   \n",
       "          105574         False        True       False       False   \n",
       "\n",
       "date                2017-01-09  2017-01-10     ...      2017-08-22  \\\n",
       "store_nbr item_nbr                             ...                   \n",
       "1         96995          False       False     ...           False   \n",
       "          99197          False       False     ...           False   \n",
       "          103520         False       False     ...           False   \n",
       "          103665         False       False     ...           False   \n",
       "          105574         False       False     ...           False   \n",
       "\n",
       "date                2017-08-23  2017-08-24  2017-08-25  2017-08-26  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995          False       False       False       False   \n",
       "          99197          False       False       False       False   \n",
       "          103520         False       False       False       False   \n",
       "          103665         False       False       False       False   \n",
       "          105574         False       False       False       False   \n",
       "\n",
       "date                2017-08-27  2017-08-28  2017-08-29  2017-08-30  2017-08-31  \n",
       "store_nbr item_nbr                                                              \n",
       "1         96995          False       False       False       False       False  \n",
       "          99197          False       False       False       False       False  \n",
       "          103520         False       False       False       False       False  \n",
       "          103665         False       False       False       False       False  \n",
       "          105574         False       False       False       False       False  \n",
       "\n",
       "[5 rows x 243 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promo_2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017 = df_2017.set_index(\n",
    "    [\"store_nbr\", \"item_nbr\", \"date\"])[[\"unit_sales\"]].unstack(\n",
    "        level=-1).fillna(0)\n",
    "df_2017.columns = df_2017.columns.get_level_values(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>2017-01-01 00:00:00</th>\n",
       "      <th>2017-01-02 00:00:00</th>\n",
       "      <th>2017-01-03 00:00:00</th>\n",
       "      <th>2017-01-04 00:00:00</th>\n",
       "      <th>2017-01-05 00:00:00</th>\n",
       "      <th>2017-01-06 00:00:00</th>\n",
       "      <th>2017-01-07 00:00:00</th>\n",
       "      <th>2017-01-08 00:00:00</th>\n",
       "      <th>2017-01-09 00:00:00</th>\n",
       "      <th>2017-01-10 00:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2017-08-06 00:00:00</th>\n",
       "      <th>2017-08-07 00:00:00</th>\n",
       "      <th>2017-08-08 00:00:00</th>\n",
       "      <th>2017-08-09 00:00:00</th>\n",
       "      <th>2017-08-10 00:00:00</th>\n",
       "      <th>2017-08-11 00:00:00</th>\n",
       "      <th>2017-08-12 00:00:00</th>\n",
       "      <th>2017-08-13 00:00:00</th>\n",
       "      <th>2017-08-14 00:00:00</th>\n",
       "      <th>2017-08-15 00:00:00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>96995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99197</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103520</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103665</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105574</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.609438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 227 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "date                2017-01-01  2017-01-02  2017-01-03  2017-01-04  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995            0.0    0.000000    0.000000    0.000000   \n",
       "          99197            0.0    0.000000    1.386294    0.693147   \n",
       "          103520           0.0    0.693147    1.098612    0.000000   \n",
       "          103665           0.0    0.000000    0.000000    1.386294   \n",
       "          105574           0.0    0.000000    1.791759    2.564949   \n",
       "\n",
       "date                2017-01-05  2017-01-06  2017-01-07  2017-01-08  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995       0.000000    0.000000    0.000000    0.000000   \n",
       "          99197       0.693147    0.693147    1.098612    0.000000   \n",
       "          103520      1.098612    1.386294    0.693147    0.000000   \n",
       "          103665      1.098612    1.098612    0.693147    1.098612   \n",
       "          105574      2.302585    1.945910    1.609438    1.098612   \n",
       "\n",
       "date                2017-01-09  2017-01-10     ...      2017-08-06  \\\n",
       "store_nbr item_nbr                             ...                   \n",
       "1         96995       0.000000    0.000000     ...        1.098612   \n",
       "          99197       0.000000    0.693147     ...        0.000000   \n",
       "          103520      0.693147    0.693147     ...        0.000000   \n",
       "          103665      0.000000    2.079442     ...        0.693147   \n",
       "          105574      1.386294    2.302585     ...        0.000000   \n",
       "\n",
       "date                2017-08-07  2017-08-08  2017-08-09  2017-08-10  \\\n",
       "store_nbr item_nbr                                                   \n",
       "1         96995       1.098612    0.000000    0.000000    0.693147   \n",
       "          99197       1.098612    0.000000    1.098612    0.000000   \n",
       "          103520      0.000000    1.386294    0.000000    1.386294   \n",
       "          103665      1.098612    0.000000    2.079442    2.302585   \n",
       "          105574      1.791759    2.079442    1.945910    2.397895   \n",
       "\n",
       "date                2017-08-11  2017-08-12  2017-08-13  2017-08-14  2017-08-15  \n",
       "store_nbr item_nbr                                                              \n",
       "1         96995       0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "          99197       0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "          103520      0.693147    0.693147    0.693147    0.000000    0.000000  \n",
       "          103665      1.098612    0.000000    0.000000    0.693147    0.693147  \n",
       "          105574      1.791759    1.791759    0.000000    1.386294    1.609438  \n",
       "\n",
       "[5 rows x 227 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#依照df_train的item_nbr重新排序items, stores\n",
    "items = items.reindex(df_2017.index.get_level_values(1))\n",
    "stores = stores.reindex(df_2017.index.get_level_values(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family</th>\n",
       "      <th>class</th>\n",
       "      <th>perishable</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96995</th>\n",
       "      <td>12</td>\n",
       "      <td>1093</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99197</th>\n",
       "      <td>12</td>\n",
       "      <td>1067</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103520</th>\n",
       "      <td>12</td>\n",
       "      <td>1028</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103665</th>\n",
       "      <td>5</td>\n",
       "      <td>2712</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105574</th>\n",
       "      <td>12</td>\n",
       "      <td>1045</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          family  class  perishable\n",
       "item_nbr                           \n",
       "96995         12   1093           0\n",
       "99197         12   1067           0\n",
       "103520        12   1028           0\n",
       "103665         5   2712           1\n",
       "105574        12   1045           0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>type</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           city  state  type  cluster\n",
       "store_nbr                            \n",
       "1            18     12     3       13\n",
       "1            18     12     3       13\n",
       "1            18     12     3       13\n",
       "1            18     12     3       13\n",
       "1            18     12     3       13"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017_item = df_2017.groupby('item_nbr')[df_2017.columns].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>date</th>\n",
       "      <th>2017-01-01 00:00:00</th>\n",
       "      <th>2017-01-02 00:00:00</th>\n",
       "      <th>2017-01-03 00:00:00</th>\n",
       "      <th>2017-01-04 00:00:00</th>\n",
       "      <th>2017-01-05 00:00:00</th>\n",
       "      <th>2017-01-06 00:00:00</th>\n",
       "      <th>2017-01-07 00:00:00</th>\n",
       "      <th>2017-01-08 00:00:00</th>\n",
       "      <th>2017-01-09 00:00:00</th>\n",
       "      <th>2017-01-10 00:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2017-08-06 00:00:00</th>\n",
       "      <th>2017-08-07 00:00:00</th>\n",
       "      <th>2017-08-08 00:00:00</th>\n",
       "      <th>2017-08-09 00:00:00</th>\n",
       "      <th>2017-08-10 00:00:00</th>\n",
       "      <th>2017-08-11 00:00:00</th>\n",
       "      <th>2017-08-12 00:00:00</th>\n",
       "      <th>2017-08-13 00:00:00</th>\n",
       "      <th>2017-08-14 00:00:00</th>\n",
       "      <th>2017-08-15 00:00:00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96995</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.662960</td>\n",
       "      <td>7.454720</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>5.950643</td>\n",
       "      <td>5.545177</td>\n",
       "      <td>8.841014</td>\n",
       "      <td>7.742402</td>\n",
       "      <td>4.969813</td>\n",
       "      <td>7.167038</td>\n",
       "      <td>7.742402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99197</th>\n",
       "      <td>0.693147</td>\n",
       "      <td>17.422746</td>\n",
       "      <td>16.604036</td>\n",
       "      <td>20.569303</td>\n",
       "      <td>16.203025</td>\n",
       "      <td>16.278613</td>\n",
       "      <td>14.775909</td>\n",
       "      <td>17.317386</td>\n",
       "      <td>14.986630</td>\n",
       "      <td>15.833927</td>\n",
       "      <td>...</td>\n",
       "      <td>3.178054</td>\n",
       "      <td>4.969813</td>\n",
       "      <td>3.178054</td>\n",
       "      <td>4.969813</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103501</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>55.868320</td>\n",
       "      <td>54.627085</td>\n",
       "      <td>42.810313</td>\n",
       "      <td>39.555298</td>\n",
       "      <td>35.717635</td>\n",
       "      <td>47.208504</td>\n",
       "      <td>47.542538</td>\n",
       "      <td>40.189274</td>\n",
       "      <td>39.200893</td>\n",
       "      <td>...</td>\n",
       "      <td>38.578235</td>\n",
       "      <td>33.531460</td>\n",
       "      <td>35.296421</td>\n",
       "      <td>35.584104</td>\n",
       "      <td>26.270815</td>\n",
       "      <td>32.776619</td>\n",
       "      <td>34.416498</td>\n",
       "      <td>36.546914</td>\n",
       "      <td>34.773173</td>\n",
       "      <td>35.512841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103520</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.875486</td>\n",
       "      <td>35.822995</td>\n",
       "      <td>34.979211</td>\n",
       "      <td>42.252967</td>\n",
       "      <td>51.397412</td>\n",
       "      <td>49.505990</td>\n",
       "      <td>33.846832</td>\n",
       "      <td>33.336007</td>\n",
       "      <td>31.741073</td>\n",
       "      <td>...</td>\n",
       "      <td>35.630624</td>\n",
       "      <td>32.567752</td>\n",
       "      <td>47.213872</td>\n",
       "      <td>41.198030</td>\n",
       "      <td>43.569852</td>\n",
       "      <td>48.697330</td>\n",
       "      <td>47.015385</td>\n",
       "      <td>39.070042</td>\n",
       "      <td>33.798042</td>\n",
       "      <td>40.030669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103665</th>\n",
       "      <td>2.079442</td>\n",
       "      <td>56.225402</td>\n",
       "      <td>40.233610</td>\n",
       "      <td>46.138063</td>\n",
       "      <td>38.100507</td>\n",
       "      <td>49.690810</td>\n",
       "      <td>54.725492</td>\n",
       "      <td>54.286513</td>\n",
       "      <td>39.602739</td>\n",
       "      <td>35.899957</td>\n",
       "      <td>...</td>\n",
       "      <td>50.919628</td>\n",
       "      <td>41.262812</td>\n",
       "      <td>34.711732</td>\n",
       "      <td>34.095546</td>\n",
       "      <td>48.162787</td>\n",
       "      <td>50.980653</td>\n",
       "      <td>39.807856</td>\n",
       "      <td>39.016553</td>\n",
       "      <td>34.262348</td>\n",
       "      <td>35.741351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 227 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "date      2017-01-01  2017-01-02  2017-01-03  2017-01-04  2017-01-05  \\\n",
       "item_nbr                                                               \n",
       "96995       0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "99197       0.693147   17.422746   16.604036   20.569303   16.203025   \n",
       "103501      0.000000   55.868320   54.627085   42.810313   39.555298   \n",
       "103520      0.000000   38.875486   35.822995   34.979211   42.252967   \n",
       "103665      2.079442   56.225402   40.233610   46.138063   38.100507   \n",
       "\n",
       "date      2017-01-06  2017-01-07  2017-01-08  2017-01-09  2017-01-10  \\\n",
       "item_nbr                                                               \n",
       "96995       0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "99197      16.278613   14.775909   17.317386   14.986630   15.833927   \n",
       "103501     35.717635   47.208504   47.542538   40.189274   39.200893   \n",
       "103520     51.397412   49.505990   33.846832   33.336007   31.741073   \n",
       "103665     49.690810   54.725492   54.286513   39.602739   35.899957   \n",
       "\n",
       "date         ...      2017-08-06  2017-08-07  2017-08-08  2017-08-09  \\\n",
       "item_nbr     ...                                                       \n",
       "96995        ...        5.662960    7.454720    2.484907    5.950643   \n",
       "99197        ...        3.178054    4.969813    3.178054    4.969813   \n",
       "103501       ...       38.578235   33.531460   35.296421   35.584104   \n",
       "103520       ...       35.630624   32.567752   47.213872   41.198030   \n",
       "103665       ...       50.919628   41.262812   34.711732   34.095546   \n",
       "\n",
       "date      2017-08-10  2017-08-11  2017-08-12  2017-08-13  2017-08-14  \\\n",
       "item_nbr                                                               \n",
       "96995       5.545177    8.841014    7.742402    4.969813    7.167038   \n",
       "99197       2.079442    2.197225    1.386294    2.079442    0.000000   \n",
       "103501     26.270815   32.776619   34.416498   36.546914   34.773173   \n",
       "103520     43.569852   48.697330   47.015385   39.070042   33.798042   \n",
       "103665     48.162787   50.980653   39.807856   39.016553   34.262348   \n",
       "\n",
       "date      2017-08-15  \n",
       "item_nbr              \n",
       "96995       7.742402  \n",
       "99197       0.000000  \n",
       "103501     35.512841  \n",
       "103520     40.030669  \n",
       "103665     35.741351  \n",
       "\n",
       "[5 rows x 227 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2017_item.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "promo_2017_item = promo_2017.groupby('item_nbr')[promo_2017.columns].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>date</th>\n",
       "      <th>2017-01-01 00:00:00</th>\n",
       "      <th>2017-01-02 00:00:00</th>\n",
       "      <th>2017-01-03 00:00:00</th>\n",
       "      <th>2017-01-04 00:00:00</th>\n",
       "      <th>2017-01-05 00:00:00</th>\n",
       "      <th>2017-01-06 00:00:00</th>\n",
       "      <th>2017-01-07 00:00:00</th>\n",
       "      <th>2017-01-08 00:00:00</th>\n",
       "      <th>2017-01-09 00:00:00</th>\n",
       "      <th>2017-01-10 00:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2017-08-22 00:00:00</th>\n",
       "      <th>2017-08-23 00:00:00</th>\n",
       "      <th>2017-08-24 00:00:00</th>\n",
       "      <th>2017-08-25 00:00:00</th>\n",
       "      <th>2017-08-26 00:00:00</th>\n",
       "      <th>2017-08-27 00:00:00</th>\n",
       "      <th>2017-08-28 00:00:00</th>\n",
       "      <th>2017-08-29 00:00:00</th>\n",
       "      <th>2017-08-30 00:00:00</th>\n",
       "      <th>2017-08-31 00:00:00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99197</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103501</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103520</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103665</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 243 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "date      2017-01-01  2017-01-02  2017-01-03  2017-01-04  2017-01-05  \\\n",
       "item_nbr                                                               \n",
       "96995            0.0         0.0         0.0         0.0         0.0   \n",
       "99197            0.0         0.0         0.0         0.0         0.0   \n",
       "103501           0.0         0.0         0.0         0.0         0.0   \n",
       "103520           0.0         0.0         0.0         0.0         0.0   \n",
       "103665           0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "date      2017-01-06  2017-01-07  2017-01-08  2017-01-09  2017-01-10  \\\n",
       "item_nbr                                                               \n",
       "96995            0.0         0.0         0.0         0.0         0.0   \n",
       "99197            0.0         0.0         0.0         0.0         0.0   \n",
       "103501           0.0         0.0         0.0         0.0         0.0   \n",
       "103520           0.0         0.0         0.0         0.0         0.0   \n",
       "103665           0.0         0.0        13.0         0.0         0.0   \n",
       "\n",
       "date         ...      2017-08-22  2017-08-23  2017-08-24  2017-08-25  \\\n",
       "item_nbr     ...                                                       \n",
       "96995        ...             0.0         0.0         0.0         0.0   \n",
       "99197        ...             0.0         0.0         0.0         0.0   \n",
       "103501       ...             0.0         0.0         0.0         0.0   \n",
       "103520       ...             0.0         0.0         0.0         0.0   \n",
       "103665       ...             0.0         0.0         0.0         0.0   \n",
       "\n",
       "date      2017-08-26  2017-08-27  2017-08-28  2017-08-29  2017-08-30  \\\n",
       "item_nbr                                                               \n",
       "96995            0.0         0.0         0.0         0.0         1.0   \n",
       "99197            0.0         0.0         0.0         0.0         0.0   \n",
       "103501           0.0         0.0         0.0         0.0         3.0   \n",
       "103520           0.0         0.0         0.0         0.0         1.0   \n",
       "103665           0.0        12.0         0.0         0.0         1.0   \n",
       "\n",
       "date      2017-08-31  \n",
       "item_nbr              \n",
       "96995            0.0  \n",
       "99197            0.0  \n",
       "103501           1.0  \n",
       "103520           1.0  \n",
       "103665           0.0  \n",
       "\n",
       "[5 rows x 243 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promo_2017_item.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017_store_class = df_2017.reset_index()\n",
    "df_2017_store_class['class'] = items['class'].values\n",
    "df_2017_store_class_index = df_2017_store_class[['class', 'store_nbr']]\n",
    "df_2017_store_class = df_2017_store_class.groupby(['class', 'store_nbr'])[df_2017.columns].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>2017-01-01 00:00:00</th>\n",
       "      <th>2017-01-02 00:00:00</th>\n",
       "      <th>2017-01-03 00:00:00</th>\n",
       "      <th>2017-01-04 00:00:00</th>\n",
       "      <th>2017-01-05 00:00:00</th>\n",
       "      <th>2017-01-06 00:00:00</th>\n",
       "      <th>2017-01-07 00:00:00</th>\n",
       "      <th>2017-01-08 00:00:00</th>\n",
       "      <th>2017-01-09 00:00:00</th>\n",
       "      <th>2017-01-10 00:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2017-08-06 00:00:00</th>\n",
       "      <th>2017-08-07 00:00:00</th>\n",
       "      <th>2017-08-08 00:00:00</th>\n",
       "      <th>2017-08-09 00:00:00</th>\n",
       "      <th>2017-08-10 00:00:00</th>\n",
       "      <th>2017-08-11 00:00:00</th>\n",
       "      <th>2017-08-12 00:00:00</th>\n",
       "      <th>2017-08-13 00:00:00</th>\n",
       "      <th>2017-08-14 00:00:00</th>\n",
       "      <th>2017-08-15 00:00:00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1002</th>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.291569</td>\n",
       "      <td>11.901285</td>\n",
       "      <td>9.939627</td>\n",
       "      <td>12.817576</td>\n",
       "      <td>10.961278</td>\n",
       "      <td>13.708549</td>\n",
       "      <td>7.454720</td>\n",
       "      <td>18.598319</td>\n",
       "      <td>12.322254</td>\n",
       "      <td>...</td>\n",
       "      <td>6.068426</td>\n",
       "      <td>11.966952</td>\n",
       "      <td>13.458607</td>\n",
       "      <td>11.431281</td>\n",
       "      <td>13.367622</td>\n",
       "      <td>5.545177</td>\n",
       "      <td>13.628506</td>\n",
       "      <td>5.375278</td>\n",
       "      <td>18.639141</td>\n",
       "      <td>10.450452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>27.836761</td>\n",
       "      <td>21.942946</td>\n",
       "      <td>23.265525</td>\n",
       "      <td>20.405583</td>\n",
       "      <td>23.207544</td>\n",
       "      <td>32.629193</td>\n",
       "      <td>33.057327</td>\n",
       "      <td>18.878450</td>\n",
       "      <td>24.403008</td>\n",
       "      <td>...</td>\n",
       "      <td>28.459131</td>\n",
       "      <td>25.885741</td>\n",
       "      <td>22.351737</td>\n",
       "      <td>21.326989</td>\n",
       "      <td>16.401095</td>\n",
       "      <td>26.828830</td>\n",
       "      <td>27.567914</td>\n",
       "      <td>25.059788</td>\n",
       "      <td>21.576931</td>\n",
       "      <td>24.121024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>42.484074</td>\n",
       "      <td>29.286804</td>\n",
       "      <td>35.991684</td>\n",
       "      <td>29.124900</td>\n",
       "      <td>31.628492</td>\n",
       "      <td>36.412191</td>\n",
       "      <td>32.819483</td>\n",
       "      <td>27.527092</td>\n",
       "      <td>26.893368</td>\n",
       "      <td>...</td>\n",
       "      <td>38.142670</td>\n",
       "      <td>27.082659</td>\n",
       "      <td>30.859413</td>\n",
       "      <td>28.748667</td>\n",
       "      <td>30.232542</td>\n",
       "      <td>36.638416</td>\n",
       "      <td>31.272846</td>\n",
       "      <td>32.256757</td>\n",
       "      <td>33.608285</td>\n",
       "      <td>24.929109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>28.353452</td>\n",
       "      <td>21.278199</td>\n",
       "      <td>22.805993</td>\n",
       "      <td>20.207757</td>\n",
       "      <td>19.822911</td>\n",
       "      <td>24.720218</td>\n",
       "      <td>31.524160</td>\n",
       "      <td>21.634874</td>\n",
       "      <td>17.617490</td>\n",
       "      <td>...</td>\n",
       "      <td>26.304582</td>\n",
       "      <td>10.961278</td>\n",
       "      <td>17.278515</td>\n",
       "      <td>13.223041</td>\n",
       "      <td>17.735273</td>\n",
       "      <td>19.822911</td>\n",
       "      <td>16.806560</td>\n",
       "      <td>23.187741</td>\n",
       "      <td>16.267563</td>\n",
       "      <td>16.267563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>19.157935</td>\n",
       "      <td>15.744315</td>\n",
       "      <td>14.909440</td>\n",
       "      <td>12.177673</td>\n",
       "      <td>12.765460</td>\n",
       "      <td>12.306750</td>\n",
       "      <td>14.427014</td>\n",
       "      <td>15.168951</td>\n",
       "      <td>12.465355</td>\n",
       "      <td>...</td>\n",
       "      <td>12.647677</td>\n",
       "      <td>13.969433</td>\n",
       "      <td>11.901285</td>\n",
       "      <td>15.333254</td>\n",
       "      <td>13.851650</td>\n",
       "      <td>10.332669</td>\n",
       "      <td>14.416963</td>\n",
       "      <td>15.538049</td>\n",
       "      <td>11.192390</td>\n",
       "      <td>11.443704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 227 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "date             2017-01-01  2017-01-02  2017-01-03  2017-01-04  2017-01-05  \\\n",
       "class store_nbr                                                               \n",
       "1002  1                 0.0    6.291569   11.901285    9.939627   12.817576   \n",
       "      2                 0.0   27.836761   21.942946   23.265525   20.405583   \n",
       "      3                 0.0   42.484074   29.286804   35.991684   29.124900   \n",
       "      4                 0.0   28.353452   21.278199   22.805993   20.207757   \n",
       "      5                 0.0   19.157935   15.744315   14.909440   12.177673   \n",
       "\n",
       "date             2017-01-06  2017-01-07  2017-01-08  2017-01-09  2017-01-10  \\\n",
       "class store_nbr                                                               \n",
       "1002  1           10.961278   13.708549    7.454720   18.598319   12.322254   \n",
       "      2           23.207544   32.629193   33.057327   18.878450   24.403008   \n",
       "      3           31.628492   36.412191   32.819483   27.527092   26.893368   \n",
       "      4           19.822911   24.720218   31.524160   21.634874   17.617490   \n",
       "      5           12.765460   12.306750   14.427014   15.168951   12.465355   \n",
       "\n",
       "date                ...      2017-08-06  2017-08-07  2017-08-08  2017-08-09  \\\n",
       "class store_nbr     ...                                                       \n",
       "1002  1             ...        6.068426   11.966952   13.458607   11.431281   \n",
       "      2             ...       28.459131   25.885741   22.351737   21.326989   \n",
       "      3             ...       38.142670   27.082659   30.859413   28.748667   \n",
       "      4             ...       26.304582   10.961278   17.278515   13.223041   \n",
       "      5             ...       12.647677   13.969433   11.901285   15.333254   \n",
       "\n",
       "date             2017-08-10  2017-08-11  2017-08-12  2017-08-13  2017-08-14  \\\n",
       "class store_nbr                                                               \n",
       "1002  1           13.367622    5.545177   13.628506    5.375278   18.639141   \n",
       "      2           16.401095   26.828830   27.567914   25.059788   21.576931   \n",
       "      3           30.232542   36.638416   31.272846   32.256757   33.608285   \n",
       "      4           17.735273   19.822911   16.806560   23.187741   16.267563   \n",
       "      5           13.851650   10.332669   14.416963   15.538049   11.192390   \n",
       "\n",
       "date             2017-08-15  \n",
       "class store_nbr              \n",
       "1002  1           10.450452  \n",
       "      2           24.121024  \n",
       "      3           24.929109  \n",
       "      4           16.267563  \n",
       "      5           11.443704  \n",
       "\n",
       "[5 rows x 227 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2017_store_class.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017_promo_store_class = promo_2017.reset_index()\n",
    "df_2017_promo_store_class['class'] = items['class'].values\n",
    "df_2017_promo_store_class_index = df_2017_promo_store_class[['class', 'store_nbr']]\n",
    "df_2017_promo_store_class = df_2017_promo_store_class.groupby(['class', 'store_nbr'])[promo_2017.columns].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>2017-01-01 00:00:00</th>\n",
       "      <th>2017-01-02 00:00:00</th>\n",
       "      <th>2017-01-03 00:00:00</th>\n",
       "      <th>2017-01-04 00:00:00</th>\n",
       "      <th>2017-01-05 00:00:00</th>\n",
       "      <th>2017-01-06 00:00:00</th>\n",
       "      <th>2017-01-07 00:00:00</th>\n",
       "      <th>2017-01-08 00:00:00</th>\n",
       "      <th>2017-01-09 00:00:00</th>\n",
       "      <th>2017-01-10 00:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2017-08-22 00:00:00</th>\n",
       "      <th>2017-08-23 00:00:00</th>\n",
       "      <th>2017-08-24 00:00:00</th>\n",
       "      <th>2017-08-25 00:00:00</th>\n",
       "      <th>2017-08-26 00:00:00</th>\n",
       "      <th>2017-08-27 00:00:00</th>\n",
       "      <th>2017-08-28 00:00:00</th>\n",
       "      <th>2017-08-29 00:00:00</th>\n",
       "      <th>2017-08-30 00:00:00</th>\n",
       "      <th>2017-08-31 00:00:00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1002</th>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 243 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "date             2017-01-01  2017-01-02  2017-01-03  2017-01-04  2017-01-05  \\\n",
       "class store_nbr                                                               \n",
       "1002  1                 0.0         0.0         0.0         0.0         0.0   \n",
       "      2                 0.0         0.0         0.0         0.0         0.0   \n",
       "      3                 0.0         0.0         0.0         0.0         0.0   \n",
       "      4                 0.0         0.0         0.0         0.0         0.0   \n",
       "      5                 0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "date             2017-01-06  2017-01-07  2017-01-08  2017-01-09  2017-01-10  \\\n",
       "class store_nbr                                                               \n",
       "1002  1                 0.0         0.0         0.0         0.0         0.0   \n",
       "      2                 0.0         0.0         0.0         0.0         0.0   \n",
       "      3                 0.0         0.0         0.0         0.0         0.0   \n",
       "      4                 0.0         0.0         0.0         0.0         0.0   \n",
       "      5                 0.0         0.0         0.0         0.0         1.0   \n",
       "\n",
       "date                ...      2017-08-22  2017-08-23  2017-08-24  2017-08-25  \\\n",
       "class store_nbr     ...                                                       \n",
       "1002  1             ...             1.0         1.0         1.0         1.0   \n",
       "      2             ...             1.0         1.0         1.0         1.0   \n",
       "      3             ...             1.0         1.0         1.0         1.0   \n",
       "      4             ...             1.0         1.0         1.0         1.0   \n",
       "      5             ...             0.0         1.0         1.0         0.0   \n",
       "\n",
       "date             2017-08-26  2017-08-27  2017-08-28  2017-08-29  2017-08-30  \\\n",
       "class store_nbr                                                               \n",
       "1002  1                 1.0         1.0         1.0         1.0         1.0   \n",
       "      2                 1.0         1.0         1.0         1.0         1.0   \n",
       "      3                 1.0         1.0         1.0         1.0         1.0   \n",
       "      4                 1.0         1.0         1.0         1.0         1.0   \n",
       "      5                 1.0         1.0         1.0         1.0         1.0   \n",
       "\n",
       "date             2017-08-31  \n",
       "class store_nbr              \n",
       "1002  1                 1.0  \n",
       "      2                 1.0  \n",
       "      3                 1.0  \n",
       "      4                 2.0  \n",
       "      5                 0.0  \n",
       "\n",
       "[5 rows x 243 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2017_promo_store_class.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 切分train/val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timespan(df, dt, minus, periods, freq='D'):\n",
    "    return df[pd.date_range(dt - timedelta(days=minus), periods=periods, freq=freq)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(df, promo_df, t2017, is_train=True, name_prefix=None):\n",
    "    X = {\n",
    "        \"promo_3_2017\": get_timespan(promo_df, t2017, 3, 3).sum(axis=1).values,\n",
    "        \"promo_5_2017\": get_timespan(promo_df, t2017, 5, 5).sum(axis=1).values,\n",
    "        \"promo_7_2017\": get_timespan(promo_df, t2017, 7, 7).sum(axis=1).values,\n",
    "        \"promo_14_2017\": get_timespan(promo_df, t2017, 14, 14).sum(axis=1).values,\n",
    "        \"promo_30_2017\": get_timespan(promo_df, t2017, 30, 30).sum(axis=1).values,\n",
    "        \"promo_60_2017\": get_timespan(promo_df, t2017, 60, 60).sum(axis=1).values,\n",
    "        \"promo_140_2017\": get_timespan(promo_df, t2017, 140, 140).sum(axis=1).values,\n",
    "        \"promo_3_2017_aft\": get_timespan(promo_df, t2017 + timedelta(days=16), 15, 3).sum(axis=1).values,\n",
    "        \"promo_7_2017_aft\": get_timespan(promo_df, t2017 + timedelta(days=16), 15, 7).sum(axis=1).values,\n",
    "        \"promo_14_2017_aft\": get_timespan(promo_df, t2017 + timedelta(days=16), 15, 14).sum(axis=1).values,\n",
    "    }\n",
    "\n",
    "\n",
    "    for i in [3, 5, 7, 14, 30, 60, 140]:\n",
    "        tmp = get_timespan(df, t2017, i, i)\n",
    "        X['mean_%s' % i] = tmp.mean(axis=1).values\n",
    "        X['diff_%s_mean' % i] = tmp.diff(axis=1).mean(axis=1).values\n",
    "#         X['mean_%s_decay' % i] = (tmp * np.power(0.9, np.arange(i)[::-1])).sum(axis=1).values\n",
    "        X['median_%s' % i] = tmp.median(axis=1).values\n",
    "        X['min_%s' % i] = tmp.min(axis=1).values\n",
    "        X['max_%s' % i] = tmp.max(axis=1).values\n",
    "        X['std_%s' % i] = tmp.std(axis=1).values\n",
    "\n",
    "\n",
    "    for i in [7, 14, 30, 60, 140]:\n",
    "        tmp = get_timespan(df, t2017, i, i)\n",
    "        X['has_sales_days_in_last_%s' % i] = (tmp > 0).sum(axis=1).values\n",
    "        X['last_has_sales_day_in_last_%s' % i] = i - ((tmp > 0) * np.arange(i)).max(axis=1).values\n",
    "        X['first_has_sales_day_in_last_%s' % i] = ((tmp > 0) * np.arange(i, 0, -1)).max(axis=1).values\n",
    "\n",
    "        tmp = get_timespan(promo_df, t2017, i, i)\n",
    "        #X['has_promo_days_in_last_%s' % i] = (tmp > 0).sum(axis=1).values\n",
    "        X['last_has_promo_day_in_last_%s' % i] = i - ((tmp > 0) * np.arange(i)).max(axis=1).values\n",
    "        X['first_has_promo_day_in_last_%s' % i] = ((tmp > 0) * np.arange(i, 0, -1)).max(axis=1).values\n",
    "\n",
    "    tmp = get_timespan(promo_df, t2017 + timedelta(days=16), 15, 15)\n",
    "    X['has_promo_days_in_after_15_days'] = (tmp > 0).sum(axis=1).values\n",
    "    X['last_has_promo_day_in_after_15_days'] = i - ((tmp > 0) * np.arange(15)).max(axis=1).values\n",
    "    X['first_has_promo_day_in_after_15_days'] = ((tmp > 0) * np.arange(15, 0, -1)).max(axis=1).values\n",
    "\n",
    "    for i in range(7):\n",
    "        X['mean_4_dow{}_2017'.format(i)] = get_timespan(df, t2017, 28-i, 4, freq='7D').mean(axis=1).values\n",
    "        X['mean_20_dow{}_2017'.format(i)] = get_timespan(df, t2017, 140-i, 20, freq='7D').mean(axis=1).values\n",
    "\n",
    "    for i in range(16):\n",
    "        X[\"promo_{}\".format(i)] = promo_df[t2017 + timedelta(days=i)].values.astype(np.uint8)\n",
    "\n",
    "    X = pd.DataFrame(X)\n",
    "\n",
    "    if is_train:\n",
    "        y = df[\n",
    "            pd.date_range(t2017, periods=16)\n",
    "        ].values\n",
    "        return X, y\n",
    "    if name_prefix is not None:\n",
    "        X.columns = ['%s_%s' % (name_prefix, c) for c in X.columns]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2017, 7, 26, 0, 0)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime(2017,6,21)+timedelta(35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dataset...\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing dataset...\")\n",
    "# 5/31後八週; 6/21後四週\n",
    "\n",
    "t2017 = date(2017, 6, 21)\n",
    "X_l, y_l = [], []\n",
    "for i in range(4):\n",
    "    delta = timedelta(days=7 * i)\n",
    "    X_tmp, y_tmp = prepare_dataset(df_2017, promo_2017, t2017 + delta)\n",
    "\n",
    "#     X_tmp2 = prepare_dataset(df_2017_item, promo_2017_item, t2017 + delta, is_train=False, name_prefix='item')\n",
    "#     X_tmp2.index = df_2017_item.index\n",
    "#     X_tmp2 = X_tmp2.reindex(df_2017.index.get_level_values(1)).reset_index(drop=True)\n",
    "\n",
    "#     X_tmp3 = prepare_dataset(df_2017_store_class, df_2017_promo_store_class, t2017 + delta, is_train=False, name_prefix='store_class')\n",
    "#     X_tmp3.index = df_2017_store_class.index\n",
    "#     X_tmp3 = X_tmp3.reindex(df_2017_store_class_index).reset_index(drop=True)\n",
    "\n",
    "    \n",
    "    #X_tmp = pd.concat([X_tmp, X_tmp2, X_tmp3, items.reset_index(), stores.reset_index()], axis=1)\n",
    "    X_tmp = pd.concat([X_tmp, items.reset_index(), stores.reset_index()], axis=1)\n",
    "    X_l.append(X_tmp)\n",
    "    y_l.append(y_tmp)\n",
    "\n",
    "#    del X_tmp2\n",
    "    gc.collect()\n",
    "\n",
    "X_train = pd.concat(X_l, axis=0)\n",
    "y_train = np.concatenate(y_l, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(670060, 119)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "periods = 16\n",
    "\n",
    "X_val, y_val = prepare_dataset(df_2017, promo_2017, date(2017, 7, 26))\n",
    "X_val = pd.concat([X_val, items.reset_index(), stores.reset_index()], axis=1)\n",
    "# X_val2 = prepare_dataset(df_2017_item, promo_2017_item, date(2017, 7, 26), is_train=False, name_prefix='item')\n",
    "# X_val2.index = df_2017_item.index\n",
    "# X_val2 = X_val2.reindex(df_2017.index.get_level_values(1)).reset_index(drop=True)\n",
    "\n",
    "# X_val3 = prepare_dataset(df_2017_store_class, df_2017_promo_store_class, date(2017, 7, 26), is_train=False, name_prefix='store_class')\n",
    "# X_val3.index = df_2017_store_class.index\n",
    "# X_val3 = X_val3.reindex(df_2017_store_class_index).reset_index(drop=True)\n",
    "\n",
    "# X_val = pd.concat([X_val, X_val2, X_val3, items.reset_index(), stores.reset_index()], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = prepare_dataset(df_2017, promo_2017, date(2017, 8, 16), is_train=False)\n",
    "X_test = pd.concat([X_test, items.reset_index(), stores.reset_index()], axis=1)\n",
    "# X_test2 = prepare_dataset(df_2017_item, promo_2017_item, date(2017, 8, 16), is_train=False, name_prefix='item')\n",
    "# X_test2.index = df_2017_item.index\n",
    "# X_test2 = X_test2.reindex(df_2017.index.get_level_values(1)).reset_index(drop=True)\n",
    "\n",
    "# X_test3 = prepare_dataset(df_2017_store_class, df_2017_promo_store_class, date(2017, 8, 16), is_train=False, name_prefix='store_class')\n",
    "# X_test3.index = df_2017_store_class.index\n",
    "# X_test3 = X_test3.reindex(df_2017_store_class_index).reset_index(drop=True)\n",
    "\n",
    "# X_test = pd.concat([X_test, X_test2, X_test3, items.reset_index(), stores.reset_index()], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(670060, 119)\n",
      "(167515, 119)\n",
      "(167515, 119)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_2017_item, promo_2017_item, df_2017_store_class, df_2017_promo_store_class, df_2017_store_class_index\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正規化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(pd.concat([X_train, X_val]))\n",
    "\n",
    "X_train[:] = scaler.transform(X_train)\n",
    "X_val[:] = scaler.transform(X_val)\n",
    "\n",
    "X_train = X_train.values\n",
    "X_val = X_val.values\n",
    "\n",
    "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_val = X_val.reshape((X_val.shape[0], 1, X_val.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[:] = scaler.transform(X_test)\n",
    "X_test = X_test.values\n",
    "X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = X_train.reshape((X_train.shape[0], X_train.shape[2], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_val = X_val.reshape((X_val.shape[0], X_val.shape[2], 1))\n",
    "#X_test = X_test.reshape((X_test.shape[0], X_test.shape[2], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense,  Dropout, Activation, Masking,Flatten\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import LSTM,Conv1D,MaxPooling1D\n",
    "from keras import callbacks\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = X_train.shape[1]\n",
    "data_dim = X_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    # PReLU是高級激活函數, 不要直接放進LSTM的 activation=, 建議要額外 model.add(PReLU())\n",
    "    # BatchNormalization(), 將激活函數的輸出值壓在接近 0, 標準差 1, 可以加速收斂, 控制過擬合\n",
    "    \n",
    "    # Flatten層和 input層\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512,input_shape=(timesteps, data_dim)))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.2))\n",
    "    \n",
    "    # 加第1層 Dense\n",
    "    model.add(Dense(512))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.1))\n",
    "      \n",
    "    # 加第2層 Dense\n",
    "    model.add(Dense(256))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.1))\n",
    "    \n",
    "    # 加第3層 Dense\n",
    "    model.add(Dense(256))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.05))\n",
    "    \n",
    "    # 加第4層 Dense\n",
    "    model.add(Dense(128))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.05))\n",
    "    \n",
    "    # 加第5層 Dense\n",
    "    model.add(Dense(128))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.05))\n",
    "    # 加第6層 Dense\n",
    "    model.add(Dense(64))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.05))\n",
    "    model.add(Dense(64))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.05))\n",
    "    # 加第7層 Dense\n",
    "    model.add(Dense(32))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.05))\n",
    "    model.add(Dense(32))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.05))\n",
    "    # 加第8層 Dense\n",
    "    model.add(Dense(16))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.05))\n",
    "    \n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  VGG\n",
    "#  def build_model():\n",
    "#         '''以Sequential()逐層疊加模型。'''\n",
    "        \n",
    "#         model = Sequential()\n",
    "#         # conv block 1\n",
    "#         model.add(Conv1D(32, (3), padding=\"same\",activation=\"relu\",\n",
    "#                                      input_shape=(timesteps,data_dim)) )\n",
    "#         model.add(Conv1D(32, (3),padding=\"same\",activation=\"relu\"))\n",
    "#         model.add(MaxPooling1D(pool_size=(2)))\n",
    "#         model.add(BatchNormalization())\n",
    "#         model.add(Dropout(0.2))\n",
    "#         # conv block 2\n",
    "#         model.add(Conv1D(64, (3), padding='same',activation=\"relu\"))\n",
    "#         model.add(Conv1D(64, (3),padding=\"same\",activation=\"relu\") )\n",
    "#         model.add(MaxPooling1D(pool_size=(2)))\n",
    "#         model.add(BatchNormalization())\n",
    "#         model.add(Dropout(0.1))\n",
    "#         # conv block 3\n",
    "#         model.add(Conv1D(128, (3), padding='same',activation=\"relu\"))\n",
    "#         model.add(Conv1D(128, (3),padding=\"same\",activation=\"relu\") )\n",
    "#         model.add(MaxPooling1D(pool_size=(2)))\n",
    "#         model.add(BatchNormalization())\n",
    "#         model.add(Dropout(0.05))\n",
    "#         # conv block 4\n",
    "#         model.add(Conv1D(256, (3), padding='same',activation=\"relu\"))\n",
    "#         model.add(Conv1D(256, (3),padding=\"same\",activation=\"relu\") )\n",
    "#         model.add(MaxPooling1D(pool_size=(2)))\n",
    "#         model.add(BatchNormalization())\n",
    "#         model.add(Dropout(0.05))\n",
    "#         # dense block\n",
    "#         \"\"\"Dense層吃向量, 所以要用Flatten壓成一維向量\n",
    "#         \"\"\"\n",
    "#         model.add(Flatten())\n",
    "#         model.add(Dense(512,activation=\"relu\"))\n",
    "#         model.add(BatchNormalization())\n",
    "#         model.add(Dropout(0.05))\n",
    "        \n",
    "        \n",
    "        \n",
    "#         model.add(Dense(1))\n",
    "        \n",
    "#         return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Step 1\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 133s - loss: 1.4421 - mean_squared_error: 1.4421 - val_loss: 0.7421 - val_mean_squared_error: 0.7421\n",
      "Epoch 2/2000\n",
      " - 9s - loss: 0.7788 - mean_squared_error: 0.7788 - val_loss: 0.5442 - val_mean_squared_error: 0.5442\n",
      "Epoch 3/2000\n",
      " - 9s - loss: 0.6222 - mean_squared_error: 0.6222 - val_loss: 0.4358 - val_mean_squared_error: 0.4358\n",
      "Epoch 4/2000\n",
      " - 9s - loss: 0.5587 - mean_squared_error: 0.5587 - val_loss: 0.3813 - val_mean_squared_error: 0.3813\n",
      "Epoch 5/2000\n",
      " - 9s - loss: 0.5209 - mean_squared_error: 0.5209 - val_loss: 0.3511 - val_mean_squared_error: 0.3511\n",
      "Epoch 6/2000\n",
      " - 9s - loss: 0.4967 - mean_squared_error: 0.4967 - val_loss: 0.3370 - val_mean_squared_error: 0.3370\n",
      "Epoch 7/2000\n",
      " - 9s - loss: 0.4809 - mean_squared_error: 0.4809 - val_loss: 0.3287 - val_mean_squared_error: 0.3287\n",
      "Epoch 8/2000\n",
      " - 9s - loss: 0.4655 - mean_squared_error: 0.4655 - val_loss: 0.3227 - val_mean_squared_error: 0.3227\n",
      "Epoch 9/2000\n",
      " - 9s - loss: 0.4559 - mean_squared_error: 0.4559 - val_loss: 0.3178 - val_mean_squared_error: 0.3178\n",
      "Epoch 10/2000\n",
      " - 9s - loss: 0.4447 - mean_squared_error: 0.4447 - val_loss: 0.3141 - val_mean_squared_error: 0.3141\n",
      "Epoch 11/2000\n",
      " - 9s - loss: 0.4348 - mean_squared_error: 0.4348 - val_loss: 0.3107 - val_mean_squared_error: 0.3107\n",
      "Epoch 12/2000\n",
      " - 9s - loss: 0.4281 - mean_squared_error: 0.4281 - val_loss: 0.3077 - val_mean_squared_error: 0.3077\n",
      "Epoch 13/2000\n",
      " - 9s - loss: 0.4201 - mean_squared_error: 0.4201 - val_loss: 0.3054 - val_mean_squared_error: 0.3054\n",
      "Epoch 14/2000\n",
      " - 9s - loss: 0.4139 - mean_squared_error: 0.4139 - val_loss: 0.3041 - val_mean_squared_error: 0.3041\n",
      "Epoch 15/2000\n",
      " - 9s - loss: 0.4078 - mean_squared_error: 0.4078 - val_loss: 0.3027 - val_mean_squared_error: 0.3027\n",
      "Epoch 16/2000\n",
      " - 9s - loss: 0.4025 - mean_squared_error: 0.4025 - val_loss: 0.3011 - val_mean_squared_error: 0.3011\n",
      "Epoch 17/2000\n",
      " - 9s - loss: 0.3977 - mean_squared_error: 0.3977 - val_loss: 0.3003 - val_mean_squared_error: 0.3003\n",
      "Epoch 18/2000\n",
      " - 9s - loss: 0.3921 - mean_squared_error: 0.3921 - val_loss: 0.2996 - val_mean_squared_error: 0.2996\n",
      "Epoch 19/2000\n",
      " - 9s - loss: 0.3892 - mean_squared_error: 0.3892 - val_loss: 0.2986 - val_mean_squared_error: 0.2986\n",
      "Epoch 20/2000\n",
      " - 10s - loss: 0.3853 - mean_squared_error: 0.3853 - val_loss: 0.2979 - val_mean_squared_error: 0.2979\n",
      "Epoch 21/2000\n",
      " - 10s - loss: 0.3805 - mean_squared_error: 0.3805 - val_loss: 0.2969 - val_mean_squared_error: 0.2969\n",
      "Epoch 22/2000\n",
      " - 10s - loss: 0.3767 - mean_squared_error: 0.3767 - val_loss: 0.2961 - val_mean_squared_error: 0.2961\n",
      "Epoch 23/2000\n",
      " - 10s - loss: 0.3732 - mean_squared_error: 0.3732 - val_loss: 0.2958 - val_mean_squared_error: 0.2958\n",
      "Epoch 24/2000\n",
      " - 10s - loss: 0.3696 - mean_squared_error: 0.3696 - val_loss: 0.2952 - val_mean_squared_error: 0.2952\n",
      "Epoch 25/2000\n",
      " - 10s - loss: 0.3670 - mean_squared_error: 0.3670 - val_loss: 0.2948 - val_mean_squared_error: 0.2948\n",
      "Epoch 26/2000\n",
      " - 10s - loss: 0.3632 - mean_squared_error: 0.3632 - val_loss: 0.2942 - val_mean_squared_error: 0.2942\n",
      "Epoch 27/2000\n",
      " - 10s - loss: 0.3601 - mean_squared_error: 0.3601 - val_loss: 0.2936 - val_mean_squared_error: 0.2936\n",
      "Epoch 28/2000\n",
      " - 10s - loss: 0.3572 - mean_squared_error: 0.3572 - val_loss: 0.2933 - val_mean_squared_error: 0.2933\n",
      "Epoch 29/2000\n",
      " - 10s - loss: 0.3539 - mean_squared_error: 0.3539 - val_loss: 0.2928 - val_mean_squared_error: 0.2928\n",
      "Epoch 30/2000\n",
      " - 10s - loss: 0.3519 - mean_squared_error: 0.3519 - val_loss: 0.2921 - val_mean_squared_error: 0.2921\n",
      "Epoch 31/2000\n",
      " - 10s - loss: 0.3487 - mean_squared_error: 0.3487 - val_loss: 0.2919 - val_mean_squared_error: 0.2919\n",
      "Epoch 32/2000\n",
      " - 10s - loss: 0.3464 - mean_squared_error: 0.3464 - val_loss: 0.2917 - val_mean_squared_error: 0.2917\n",
      "Epoch 33/2000\n",
      " - 10s - loss: 0.3440 - mean_squared_error: 0.3440 - val_loss: 0.2910 - val_mean_squared_error: 0.2910\n",
      "Epoch 34/2000\n",
      " - 10s - loss: 0.3411 - mean_squared_error: 0.3411 - val_loss: 0.2910 - val_mean_squared_error: 0.2910\n",
      "Epoch 35/2000\n",
      " - 10s - loss: 0.3397 - mean_squared_error: 0.3397 - val_loss: 0.2907 - val_mean_squared_error: 0.2907\n",
      "Epoch 36/2000\n",
      " - 10s - loss: 0.3373 - mean_squared_error: 0.3373 - val_loss: 0.2904 - val_mean_squared_error: 0.2904\n",
      "Epoch 37/2000\n",
      " - 10s - loss: 0.3355 - mean_squared_error: 0.3355 - val_loss: 0.2898 - val_mean_squared_error: 0.2898\n",
      "Epoch 38/2000\n",
      " - 10s - loss: 0.3333 - mean_squared_error: 0.3333 - val_loss: 0.2897 - val_mean_squared_error: 0.2897\n",
      "Epoch 39/2000\n",
      " - 10s - loss: 0.3312 - mean_squared_error: 0.3312 - val_loss: 0.2895 - val_mean_squared_error: 0.2895\n",
      "Epoch 40/2000\n",
      " - 9s - loss: 0.3293 - mean_squared_error: 0.3293 - val_loss: 0.2893 - val_mean_squared_error: 0.2893\n",
      "Epoch 41/2000\n",
      " - 10s - loss: 0.3279 - mean_squared_error: 0.3279 - val_loss: 0.2890 - val_mean_squared_error: 0.2890\n",
      "Epoch 42/2000\n",
      " - 10s - loss: 0.3266 - mean_squared_error: 0.3266 - val_loss: 0.2888 - val_mean_squared_error: 0.2888\n",
      "Epoch 43/2000\n",
      " - 10s - loss: 0.3241 - mean_squared_error: 0.3241 - val_loss: 0.2886 - val_mean_squared_error: 0.2886\n",
      "Epoch 44/2000\n",
      " - 10s - loss: 0.3231 - mean_squared_error: 0.3231 - val_loss: 0.2887 - val_mean_squared_error: 0.2887\n",
      "Epoch 45/2000\n",
      " - 10s - loss: 0.3218 - mean_squared_error: 0.3218 - val_loss: 0.2887 - val_mean_squared_error: 0.2887\n",
      "Epoch 46/2000\n",
      " - 10s - loss: 0.3205 - mean_squared_error: 0.3205 - val_loss: 0.2886 - val_mean_squared_error: 0.2886\n",
      "Epoch 47/2000\n",
      " - 10s - loss: 0.3193 - mean_squared_error: 0.3193 - val_loss: 0.2883 - val_mean_squared_error: 0.2883\n",
      "Epoch 48/2000\n",
      " - 10s - loss: 0.3176 - mean_squared_error: 0.3176 - val_loss: 0.2885 - val_mean_squared_error: 0.2885\n",
      "Epoch 49/2000\n",
      " - 10s - loss: 0.3165 - mean_squared_error: 0.3165 - val_loss: 0.2881 - val_mean_squared_error: 0.2881\n",
      "Epoch 50/2000\n",
      " - 10s - loss: 0.3153 - mean_squared_error: 0.3153 - val_loss: 0.2884 - val_mean_squared_error: 0.2884\n",
      "Epoch 51/2000\n",
      " - 10s - loss: 0.3144 - mean_squared_error: 0.3144 - val_loss: 0.2882 - val_mean_squared_error: 0.2882\n",
      "Epoch 52/2000\n",
      " - 10s - loss: 0.3135 - mean_squared_error: 0.3135 - val_loss: 0.2879 - val_mean_squared_error: 0.2879\n",
      "Epoch 53/2000\n",
      " - 10s - loss: 0.3127 - mean_squared_error: 0.3127 - val_loss: 0.2885 - val_mean_squared_error: 0.2885\n",
      "Epoch 54/2000\n",
      " - 10s - loss: 0.3114 - mean_squared_error: 0.3114 - val_loss: 0.2881 - val_mean_squared_error: 0.2881\n",
      "Epoch 55/2000\n",
      " - 9s - loss: 0.3105 - mean_squared_error: 0.3105 - val_loss: 0.2879 - val_mean_squared_error: 0.2879\n",
      "Epoch 56/2000\n",
      " - 10s - loss: 0.3099 - mean_squared_error: 0.3099 - val_loss: 0.2884 - val_mean_squared_error: 0.2884\n",
      "Epoch 57/2000\n",
      " - 10s - loss: 0.3084 - mean_squared_error: 0.3084 - val_loss: 0.2878 - val_mean_squared_error: 0.2878\n",
      "Epoch 58/2000\n",
      " - 10s - loss: 0.3078 - mean_squared_error: 0.3078 - val_loss: 0.2882 - val_mean_squared_error: 0.2882\n",
      "Epoch 59/2000\n",
      " - 10s - loss: 0.3069 - mean_squared_error: 0.3069 - val_loss: 0.2877 - val_mean_squared_error: 0.2877\n",
      "Epoch 60/2000\n",
      " - 10s - loss: 0.3065 - mean_squared_error: 0.3065 - val_loss: 0.2878 - val_mean_squared_error: 0.2878\n",
      "Epoch 61/2000\n",
      " - 10s - loss: 0.3054 - mean_squared_error: 0.3054 - val_loss: 0.2878 - val_mean_squared_error: 0.2878\n",
      "Epoch 62/2000\n",
      " - 10s - loss: 0.3049 - mean_squared_error: 0.3049 - val_loss: 0.2881 - val_mean_squared_error: 0.2881\n",
      "Epoch 63/2000\n",
      " - 10s - loss: 0.3040 - mean_squared_error: 0.3040 - val_loss: 0.2880 - val_mean_squared_error: 0.2880\n",
      "Epoch 64/2000\n",
      " - 10s - loss: 0.3036 - mean_squared_error: 0.3036 - val_loss: 0.2881 - val_mean_squared_error: 0.2881\n",
      "Epoch 65/2000\n",
      " - 10s - loss: 0.3030 - mean_squared_error: 0.3030 - val_loss: 0.2882 - val_mean_squared_error: 0.2882\n",
      "Epoch 66/2000\n",
      " - 10s - loss: 0.3022 - mean_squared_error: 0.3022 - val_loss: 0.2877 - val_mean_squared_error: 0.2877\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 67/2000\n",
      " - 10s - loss: 0.3016 - mean_squared_error: 0.3016 - val_loss: 0.2881 - val_mean_squared_error: 0.2881\n",
      "Epoch 68/2000\n",
      " - 10s - loss: 0.3015 - mean_squared_error: 0.3015 - val_loss: 0.2882 - val_mean_squared_error: 0.2882\n",
      "Epoch 69/2000\n",
      " - 10s - loss: 0.3014 - mean_squared_error: 0.3014 - val_loss: 0.2881 - val_mean_squared_error: 0.2881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Step 2\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 135s - loss: 1.1261 - mean_squared_error: 1.1261 - val_loss: 0.5914 - val_mean_squared_error: 0.5914\n",
      "Epoch 2/2000\n",
      " - 10s - loss: 0.6416 - mean_squared_error: 0.6416 - val_loss: 0.4762 - val_mean_squared_error: 0.4762\n",
      "Epoch 3/2000\n",
      " - 10s - loss: 0.5328 - mean_squared_error: 0.5328 - val_loss: 0.4271 - val_mean_squared_error: 0.4271\n",
      "Epoch 4/2000\n",
      " - 10s - loss: 0.4873 - mean_squared_error: 0.4873 - val_loss: 0.3923 - val_mean_squared_error: 0.3923\n",
      "Epoch 5/2000\n",
      " - 9s - loss: 0.4630 - mean_squared_error: 0.4630 - val_loss: 0.3677 - val_mean_squared_error: 0.3677\n",
      "Epoch 6/2000\n",
      " - 10s - loss: 0.4458 - mean_squared_error: 0.4458 - val_loss: 0.3548 - val_mean_squared_error: 0.3548\n",
      "Epoch 7/2000\n",
      " - 10s - loss: 0.4349 - mean_squared_error: 0.4349 - val_loss: 0.3473 - val_mean_squared_error: 0.3473\n",
      "Epoch 8/2000\n",
      " - 10s - loss: 0.4255 - mean_squared_error: 0.4255 - val_loss: 0.3417 - val_mean_squared_error: 0.3417\n",
      "Epoch 9/2000\n",
      " - 10s - loss: 0.4182 - mean_squared_error: 0.4182 - val_loss: 0.3386 - val_mean_squared_error: 0.3386\n",
      "Epoch 10/2000\n",
      " - 10s - loss: 0.4126 - mean_squared_error: 0.4126 - val_loss: 0.3360 - val_mean_squared_error: 0.3360\n",
      "Epoch 11/2000\n",
      " - 10s - loss: 0.4068 - mean_squared_error: 0.4068 - val_loss: 0.3341 - val_mean_squared_error: 0.3341\n",
      "Epoch 12/2000\n",
      " - 10s - loss: 0.4031 - mean_squared_error: 0.4031 - val_loss: 0.3328 - val_mean_squared_error: 0.3328\n",
      "Epoch 13/2000\n",
      " - 10s - loss: 0.3975 - mean_squared_error: 0.3975 - val_loss: 0.3315 - val_mean_squared_error: 0.3315\n",
      "Epoch 14/2000\n",
      " - 9s - loss: 0.3948 - mean_squared_error: 0.3948 - val_loss: 0.3306 - val_mean_squared_error: 0.3306\n",
      "Epoch 15/2000\n",
      " - 10s - loss: 0.3908 - mean_squared_error: 0.3908 - val_loss: 0.3298 - val_mean_squared_error: 0.3298\n",
      "Epoch 16/2000\n",
      " - 10s - loss: 0.3871 - mean_squared_error: 0.3871 - val_loss: 0.3289 - val_mean_squared_error: 0.3289\n",
      "Epoch 17/2000\n",
      " - 10s - loss: 0.3841 - mean_squared_error: 0.3841 - val_loss: 0.3286 - val_mean_squared_error: 0.3286\n",
      "Epoch 18/2000\n",
      " - 9s - loss: 0.3804 - mean_squared_error: 0.3804 - val_loss: 0.3277 - val_mean_squared_error: 0.3277\n",
      "Epoch 19/2000\n",
      " - 10s - loss: 0.3783 - mean_squared_error: 0.3783 - val_loss: 0.3272 - val_mean_squared_error: 0.3272\n",
      "Epoch 20/2000\n",
      " - 10s - loss: 0.3756 - mean_squared_error: 0.3756 - val_loss: 0.3270 - val_mean_squared_error: 0.3270\n",
      "Epoch 21/2000\n",
      " - 10s - loss: 0.3727 - mean_squared_error: 0.3727 - val_loss: 0.3262 - val_mean_squared_error: 0.3262\n",
      "Epoch 22/2000\n",
      " - 10s - loss: 0.3706 - mean_squared_error: 0.3706 - val_loss: 0.3261 - val_mean_squared_error: 0.3261\n",
      "Epoch 23/2000\n",
      " - 10s - loss: 0.3674 - mean_squared_error: 0.3674 - val_loss: 0.3253 - val_mean_squared_error: 0.3253\n",
      "Epoch 24/2000\n",
      " - 10s - loss: 0.3656 - mean_squared_error: 0.3656 - val_loss: 0.3252 - val_mean_squared_error: 0.3252\n",
      "Epoch 25/2000\n",
      " - 10s - loss: 0.3633 - mean_squared_error: 0.3633 - val_loss: 0.3248 - val_mean_squared_error: 0.3248\n",
      "Epoch 26/2000\n",
      " - 10s - loss: 0.3617 - mean_squared_error: 0.3617 - val_loss: 0.3245 - val_mean_squared_error: 0.3245\n",
      "Epoch 27/2000\n",
      " - 10s - loss: 0.3593 - mean_squared_error: 0.3593 - val_loss: 0.3242 - val_mean_squared_error: 0.3242\n",
      "Epoch 28/2000\n",
      " - 10s - loss: 0.3579 - mean_squared_error: 0.3579 - val_loss: 0.3242 - val_mean_squared_error: 0.3242\n",
      "Epoch 29/2000\n",
      " - 10s - loss: 0.3553 - mean_squared_error: 0.3553 - val_loss: 0.3237 - val_mean_squared_error: 0.3237\n",
      "Epoch 30/2000\n",
      " - 10s - loss: 0.3541 - mean_squared_error: 0.3541 - val_loss: 0.3231 - val_mean_squared_error: 0.3231\n",
      "Epoch 31/2000\n",
      " - 10s - loss: 0.3523 - mean_squared_error: 0.3523 - val_loss: 0.3229 - val_mean_squared_error: 0.3229\n",
      "Epoch 32/2000\n",
      " - 10s - loss: 0.3506 - mean_squared_error: 0.3506 - val_loss: 0.3233 - val_mean_squared_error: 0.3233\n",
      "Epoch 33/2000\n",
      " - 10s - loss: 0.3485 - mean_squared_error: 0.3485 - val_loss: 0.3232 - val_mean_squared_error: 0.3232\n",
      "Epoch 34/2000\n",
      " - 10s - loss: 0.3475 - mean_squared_error: 0.3475 - val_loss: 0.3224 - val_mean_squared_error: 0.3224\n",
      "Epoch 35/2000\n",
      " - 10s - loss: 0.3460 - mean_squared_error: 0.3460 - val_loss: 0.3224 - val_mean_squared_error: 0.3224\n",
      "Epoch 36/2000\n",
      " - 10s - loss: 0.3441 - mean_squared_error: 0.3441 - val_loss: 0.3218 - val_mean_squared_error: 0.3218\n",
      "Epoch 37/2000\n",
      " - 10s - loss: 0.3433 - mean_squared_error: 0.3433 - val_loss: 0.3221 - val_mean_squared_error: 0.3221\n",
      "Epoch 38/2000\n",
      " - 10s - loss: 0.3420 - mean_squared_error: 0.3420 - val_loss: 0.3213 - val_mean_squared_error: 0.3213\n",
      "Epoch 39/2000\n",
      " - 10s - loss: 0.3402 - mean_squared_error: 0.3402 - val_loss: 0.3215 - val_mean_squared_error: 0.3215\n",
      "Epoch 40/2000\n",
      " - 10s - loss: 0.3392 - mean_squared_error: 0.3392 - val_loss: 0.3214 - val_mean_squared_error: 0.3214\n",
      "Epoch 41/2000\n",
      " - 10s - loss: 0.3383 - mean_squared_error: 0.3383 - val_loss: 0.3214 - val_mean_squared_error: 0.3214\n",
      "Epoch 42/2000\n",
      " - 10s - loss: 0.3364 - mean_squared_error: 0.3364 - val_loss: 0.3212 - val_mean_squared_error: 0.3212\n",
      "Epoch 43/2000\n",
      " - 10s - loss: 0.3359 - mean_squared_error: 0.3359 - val_loss: 0.3217 - val_mean_squared_error: 0.3217\n",
      "Epoch 44/2000\n",
      " - 10s - loss: 0.3350 - mean_squared_error: 0.3350 - val_loss: 0.3205 - val_mean_squared_error: 0.3205\n",
      "Epoch 45/2000\n",
      " - 10s - loss: 0.3342 - mean_squared_error: 0.3342 - val_loss: 0.3209 - val_mean_squared_error: 0.3209\n",
      "Epoch 46/2000\n",
      " - 10s - loss: 0.3335 - mean_squared_error: 0.3335 - val_loss: 0.3203 - val_mean_squared_error: 0.3203\n",
      "Epoch 47/2000\n",
      " - 10s - loss: 0.3329 - mean_squared_error: 0.3329 - val_loss: 0.3206 - val_mean_squared_error: 0.3206\n",
      "Epoch 48/2000\n",
      " - 10s - loss: 0.3311 - mean_squared_error: 0.3311 - val_loss: 0.3210 - val_mean_squared_error: 0.3210\n",
      "Epoch 49/2000\n",
      " - 10s - loss: 0.3305 - mean_squared_error: 0.3305 - val_loss: 0.3208 - val_mean_squared_error: 0.3208\n",
      "Epoch 50/2000\n",
      " - 10s - loss: 0.3299 - mean_squared_error: 0.3299 - val_loss: 0.3205 - val_mean_squared_error: 0.3205\n",
      "Epoch 51/2000\n",
      " - 10s - loss: 0.3287 - mean_squared_error: 0.3287 - val_loss: 0.3203 - val_mean_squared_error: 0.3203\n",
      "Epoch 52/2000\n",
      " - 10s - loss: 0.3278 - mean_squared_error: 0.3278 - val_loss: 0.3217 - val_mean_squared_error: 0.3217\n",
      "Epoch 53/2000\n",
      " - 10s - loss: 0.3279 - mean_squared_error: 0.3279 - val_loss: 0.3206 - val_mean_squared_error: 0.3206\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 54/2000\n",
      " - 11s - loss: 0.3262 - mean_squared_error: 0.3262 - val_loss: 0.3211 - val_mean_squared_error: 0.3211\n",
      "Epoch 55/2000\n",
      " - 10s - loss: 0.3264 - mean_squared_error: 0.3264 - val_loss: 0.3212 - val_mean_squared_error: 0.3212\n",
      "Epoch 56/2000\n",
      " - 10s - loss: 0.3264 - mean_squared_error: 0.3264 - val_loss: 0.3213 - val_mean_squared_error: 0.3213\n",
      "==================================================\n",
      "Step 3\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 141s - loss: 1.4898 - mean_squared_error: 1.4898 - val_loss: 0.9713 - val_mean_squared_error: 0.9713\n",
      "Epoch 2/2000\n",
      " - 10s - loss: 0.7826 - mean_squared_error: 0.7826 - val_loss: 0.7407 - val_mean_squared_error: 0.7407\n",
      "Epoch 3/2000\n",
      " - 10s - loss: 0.6232 - mean_squared_error: 0.6232 - val_loss: 0.5218 - val_mean_squared_error: 0.5218\n",
      "Epoch 4/2000\n",
      " - 10s - loss: 0.5585 - mean_squared_error: 0.5585 - val_loss: 0.4257 - val_mean_squared_error: 0.4257\n",
      "Epoch 5/2000\n",
      " - 10s - loss: 0.5232 - mean_squared_error: 0.5232 - val_loss: 0.3906 - val_mean_squared_error: 0.3906\n",
      "Epoch 6/2000\n",
      " - 10s - loss: 0.5010 - mean_squared_error: 0.5010 - val_loss: 0.3763 - val_mean_squared_error: 0.3763\n",
      "Epoch 7/2000\n",
      " - 10s - loss: 0.4845 - mean_squared_error: 0.4845 - val_loss: 0.3681 - val_mean_squared_error: 0.3681\n",
      "Epoch 8/2000\n",
      " - 10s - loss: 0.4717 - mean_squared_error: 0.4717 - val_loss: 0.3623 - val_mean_squared_error: 0.3623\n",
      "Epoch 9/2000\n",
      " - 10s - loss: 0.4602 - mean_squared_error: 0.4602 - val_loss: 0.3582 - val_mean_squared_error: 0.3582\n",
      "Epoch 10/2000\n",
      " - 10s - loss: 0.4519 - mean_squared_error: 0.4519 - val_loss: 0.3555 - val_mean_squared_error: 0.3555\n",
      "Epoch 11/2000\n",
      " - 10s - loss: 0.4449 - mean_squared_error: 0.4449 - val_loss: 0.3534 - val_mean_squared_error: 0.3534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/2000\n",
      " - 10s - loss: 0.4369 - mean_squared_error: 0.4369 - val_loss: 0.3510 - val_mean_squared_error: 0.3510\n",
      "Epoch 13/2000\n",
      " - 10s - loss: 0.4315 - mean_squared_error: 0.4315 - val_loss: 0.3497 - val_mean_squared_error: 0.3497\n",
      "Epoch 14/2000\n",
      " - 10s - loss: 0.4267 - mean_squared_error: 0.4267 - val_loss: 0.3483 - val_mean_squared_error: 0.3483\n",
      "Epoch 15/2000\n",
      " - 10s - loss: 0.4218 - mean_squared_error: 0.4218 - val_loss: 0.3478 - val_mean_squared_error: 0.3478\n",
      "Epoch 16/2000\n",
      " - 10s - loss: 0.4167 - mean_squared_error: 0.4167 - val_loss: 0.3467 - val_mean_squared_error: 0.3467\n",
      "Epoch 17/2000\n",
      " - 10s - loss: 0.4125 - mean_squared_error: 0.4125 - val_loss: 0.3457 - val_mean_squared_error: 0.3457\n",
      "Epoch 18/2000\n",
      " - 10s - loss: 0.4093 - mean_squared_error: 0.4093 - val_loss: 0.3451 - val_mean_squared_error: 0.3451\n",
      "Epoch 19/2000\n",
      " - 11s - loss: 0.4046 - mean_squared_error: 0.4046 - val_loss: 0.3453 - val_mean_squared_error: 0.3453\n",
      "Epoch 20/2000\n",
      " - 10s - loss: 0.4014 - mean_squared_error: 0.4014 - val_loss: 0.3439 - val_mean_squared_error: 0.3439\n",
      "Epoch 21/2000\n",
      " - 10s - loss: 0.3983 - mean_squared_error: 0.3983 - val_loss: 0.3434 - val_mean_squared_error: 0.3434\n",
      "Epoch 22/2000\n",
      " - 10s - loss: 0.3939 - mean_squared_error: 0.3939 - val_loss: 0.3438 - val_mean_squared_error: 0.3438\n",
      "Epoch 23/2000\n",
      " - 10s - loss: 0.3919 - mean_squared_error: 0.3919 - val_loss: 0.3425 - val_mean_squared_error: 0.3425\n",
      "Epoch 24/2000\n",
      " - 10s - loss: 0.3888 - mean_squared_error: 0.3888 - val_loss: 0.3423 - val_mean_squared_error: 0.3423\n",
      "Epoch 25/2000\n",
      " - 10s - loss: 0.3857 - mean_squared_error: 0.3857 - val_loss: 0.3421 - val_mean_squared_error: 0.3421\n",
      "Epoch 26/2000\n",
      " - 10s - loss: 0.3833 - mean_squared_error: 0.3833 - val_loss: 0.3415 - val_mean_squared_error: 0.3415\n",
      "Epoch 27/2000\n",
      " - 10s - loss: 0.3806 - mean_squared_error: 0.3806 - val_loss: 0.3412 - val_mean_squared_error: 0.3412\n",
      "Epoch 28/2000\n",
      " - 10s - loss: 0.3779 - mean_squared_error: 0.3779 - val_loss: 0.3413 - val_mean_squared_error: 0.3413\n",
      "Epoch 29/2000\n",
      " - 10s - loss: 0.3755 - mean_squared_error: 0.3755 - val_loss: 0.3404 - val_mean_squared_error: 0.3404\n",
      "Epoch 30/2000\n",
      " - 10s - loss: 0.3727 - mean_squared_error: 0.3727 - val_loss: 0.3393 - val_mean_squared_error: 0.3393\n",
      "Epoch 31/2000\n",
      " - 10s - loss: 0.3705 - mean_squared_error: 0.3705 - val_loss: 0.3401 - val_mean_squared_error: 0.3401\n",
      "Epoch 32/2000\n",
      " - 10s - loss: 0.3687 - mean_squared_error: 0.3687 - val_loss: 0.3397 - val_mean_squared_error: 0.3397\n",
      "Epoch 33/2000\n",
      " - 10s - loss: 0.3666 - mean_squared_error: 0.3666 - val_loss: 0.3396 - val_mean_squared_error: 0.3396\n",
      "Epoch 34/2000\n",
      " - 10s - loss: 0.3648 - mean_squared_error: 0.3648 - val_loss: 0.3397 - val_mean_squared_error: 0.3397\n",
      "Epoch 35/2000\n",
      " - 10s - loss: 0.3626 - mean_squared_error: 0.3626 - val_loss: 0.3395 - val_mean_squared_error: 0.3395\n",
      "Epoch 36/2000\n",
      " - 10s - loss: 0.3607 - mean_squared_error: 0.3607 - val_loss: 0.3390 - val_mean_squared_error: 0.3390\n",
      "Epoch 37/2000\n",
      " - 10s - loss: 0.3584 - mean_squared_error: 0.3584 - val_loss: 0.3393 - val_mean_squared_error: 0.3393\n",
      "Epoch 38/2000\n",
      " - 10s - loss: 0.3564 - mean_squared_error: 0.3564 - val_loss: 0.3396 - val_mean_squared_error: 0.3396\n",
      "Epoch 39/2000\n",
      " - 10s - loss: 0.3552 - mean_squared_error: 0.3552 - val_loss: 0.3380 - val_mean_squared_error: 0.3380\n",
      "Epoch 40/2000\n",
      " - 10s - loss: 0.3533 - mean_squared_error: 0.3533 - val_loss: 0.3382 - val_mean_squared_error: 0.3382\n",
      "Epoch 41/2000\n",
      " - 10s - loss: 0.3518 - mean_squared_error: 0.3518 - val_loss: 0.3385 - val_mean_squared_error: 0.3385\n",
      "Epoch 42/2000\n",
      " - 10s - loss: 0.3499 - mean_squared_error: 0.3499 - val_loss: 0.3389 - val_mean_squared_error: 0.3389\n",
      "Epoch 43/2000\n",
      " - 10s - loss: 0.3483 - mean_squared_error: 0.3483 - val_loss: 0.3393 - val_mean_squared_error: 0.3393\n",
      "Epoch 44/2000\n",
      " - 10s - loss: 0.3473 - mean_squared_error: 0.3473 - val_loss: 0.3400 - val_mean_squared_error: 0.3400\n",
      "Epoch 45/2000\n",
      " - 10s - loss: 0.3455 - mean_squared_error: 0.3455 - val_loss: 0.3407 - val_mean_squared_error: 0.3407\n",
      "Epoch 46/2000\n",
      " - 10s - loss: 0.3440 - mean_squared_error: 0.3440 - val_loss: 0.3399 - val_mean_squared_error: 0.3399\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 47/2000\n",
      " - 11s - loss: 0.3431 - mean_squared_error: 0.3431 - val_loss: 0.3407 - val_mean_squared_error: 0.3407\n",
      "Epoch 48/2000\n",
      " - 10s - loss: 0.3429 - mean_squared_error: 0.3429 - val_loss: 0.3410 - val_mean_squared_error: 0.3410\n",
      "Epoch 49/2000\n",
      " - 10s - loss: 0.3436 - mean_squared_error: 0.3436 - val_loss: 0.3410 - val_mean_squared_error: 0.3410\n",
      "==================================================\n",
      "Step 4\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 150s - loss: 1.3806 - mean_squared_error: 1.3806 - val_loss: 0.9460 - val_mean_squared_error: 0.9460\n",
      "Epoch 2/2000\n",
      " - 10s - loss: 0.7830 - mean_squared_error: 0.7830 - val_loss: 0.6673 - val_mean_squared_error: 0.6673\n",
      "Epoch 3/2000\n",
      " - 10s - loss: 0.6423 - mean_squared_error: 0.6423 - val_loss: 0.5016 - val_mean_squared_error: 0.5016\n",
      "Epoch 4/2000\n",
      " - 10s - loss: 0.5867 - mean_squared_error: 0.5867 - val_loss: 0.4422 - val_mean_squared_error: 0.4422\n",
      "Epoch 5/2000\n",
      " - 10s - loss: 0.5549 - mean_squared_error: 0.5549 - val_loss: 0.4104 - val_mean_squared_error: 0.4104\n",
      "Epoch 6/2000\n",
      " - 10s - loss: 0.5357 - mean_squared_error: 0.5357 - val_loss: 0.3938 - val_mean_squared_error: 0.3938\n",
      "Epoch 7/2000\n",
      " - 10s - loss: 0.5182 - mean_squared_error: 0.5182 - val_loss: 0.3841 - val_mean_squared_error: 0.3841\n",
      "Epoch 8/2000\n",
      " - 10s - loss: 0.5083 - mean_squared_error: 0.5083 - val_loss: 0.3783 - val_mean_squared_error: 0.3783\n",
      "Epoch 9/2000\n",
      " - 10s - loss: 0.4969 - mean_squared_error: 0.4969 - val_loss: 0.3739 - val_mean_squared_error: 0.3739\n",
      "Epoch 10/2000\n",
      " - 10s - loss: 0.4892 - mean_squared_error: 0.4892 - val_loss: 0.3707 - val_mean_squared_error: 0.3707\n",
      "Epoch 11/2000\n",
      " - 10s - loss: 0.4788 - mean_squared_error: 0.4788 - val_loss: 0.3683 - val_mean_squared_error: 0.3683\n",
      "Epoch 12/2000\n",
      " - 10s - loss: 0.4726 - mean_squared_error: 0.4726 - val_loss: 0.3658 - val_mean_squared_error: 0.3658\n",
      "Epoch 13/2000\n",
      " - 10s - loss: 0.4670 - mean_squared_error: 0.4670 - val_loss: 0.3642 - val_mean_squared_error: 0.3642\n",
      "Epoch 14/2000\n",
      " - 10s - loss: 0.4590 - mean_squared_error: 0.4590 - val_loss: 0.3632 - val_mean_squared_error: 0.3632\n",
      "Epoch 15/2000\n",
      " - 10s - loss: 0.4561 - mean_squared_error: 0.4561 - val_loss: 0.3620 - val_mean_squared_error: 0.3620\n",
      "Epoch 16/2000\n",
      " - 10s - loss: 0.4496 - mean_squared_error: 0.4496 - val_loss: 0.3610 - val_mean_squared_error: 0.3610\n",
      "Epoch 17/2000\n",
      " - 10s - loss: 0.4464 - mean_squared_error: 0.4464 - val_loss: 0.3603 - val_mean_squared_error: 0.3603\n",
      "Epoch 18/2000\n",
      " - 10s - loss: 0.4426 - mean_squared_error: 0.4426 - val_loss: 0.3586 - val_mean_squared_error: 0.3586\n",
      "Epoch 19/2000\n",
      " - 10s - loss: 0.4365 - mean_squared_error: 0.4365 - val_loss: 0.3580 - val_mean_squared_error: 0.3580\n",
      "Epoch 20/2000\n",
      " - 10s - loss: 0.4341 - mean_squared_error: 0.4341 - val_loss: 0.3574 - val_mean_squared_error: 0.3574\n",
      "Epoch 21/2000\n",
      " - 10s - loss: 0.4291 - mean_squared_error: 0.4291 - val_loss: 0.3575 - val_mean_squared_error: 0.3575\n",
      "Epoch 22/2000\n",
      " - 10s - loss: 0.4260 - mean_squared_error: 0.4260 - val_loss: 0.3578 - val_mean_squared_error: 0.3578\n",
      "Epoch 23/2000\n",
      " - 10s - loss: 0.4229 - mean_squared_error: 0.4229 - val_loss: 0.3560 - val_mean_squared_error: 0.3560\n",
      "Epoch 24/2000\n",
      " - 10s - loss: 0.4199 - mean_squared_error: 0.4199 - val_loss: 0.3556 - val_mean_squared_error: 0.3556\n",
      "Epoch 25/2000\n",
      " - 10s - loss: 0.4157 - mean_squared_error: 0.4157 - val_loss: 0.3550 - val_mean_squared_error: 0.3550\n",
      "Epoch 26/2000\n",
      " - 10s - loss: 0.4131 - mean_squared_error: 0.4131 - val_loss: 0.3549 - val_mean_squared_error: 0.3549\n",
      "Epoch 27/2000\n",
      " - 10s - loss: 0.4093 - mean_squared_error: 0.4093 - val_loss: 0.3541 - val_mean_squared_error: 0.3541\n",
      "Epoch 28/2000\n",
      " - 10s - loss: 0.4073 - mean_squared_error: 0.4073 - val_loss: 0.3538 - val_mean_squared_error: 0.3538\n",
      "Epoch 29/2000\n",
      " - 10s - loss: 0.4050 - mean_squared_error: 0.4050 - val_loss: 0.3528 - val_mean_squared_error: 0.3528\n",
      "Epoch 30/2000\n",
      " - 10s - loss: 0.4013 - mean_squared_error: 0.4013 - val_loss: 0.3524 - val_mean_squared_error: 0.3524\n",
      "Epoch 31/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 10s - loss: 0.3991 - mean_squared_error: 0.3991 - val_loss: 0.3519 - val_mean_squared_error: 0.3519\n",
      "Epoch 32/2000\n",
      " - 10s - loss: 0.3965 - mean_squared_error: 0.3965 - val_loss: 0.3519 - val_mean_squared_error: 0.3519\n",
      "Epoch 33/2000\n",
      " - 11s - loss: 0.3947 - mean_squared_error: 0.3947 - val_loss: 0.3514 - val_mean_squared_error: 0.3514\n",
      "Epoch 34/2000\n",
      " - 10s - loss: 0.3926 - mean_squared_error: 0.3926 - val_loss: 0.3513 - val_mean_squared_error: 0.3513\n",
      "Epoch 35/2000\n",
      " - 10s - loss: 0.3900 - mean_squared_error: 0.3900 - val_loss: 0.3506 - val_mean_squared_error: 0.3506\n",
      "Epoch 36/2000\n",
      " - 10s - loss: 0.3877 - mean_squared_error: 0.3877 - val_loss: 0.3506 - val_mean_squared_error: 0.3506\n",
      "Epoch 37/2000\n",
      " - 10s - loss: 0.3860 - mean_squared_error: 0.3860 - val_loss: 0.3503 - val_mean_squared_error: 0.3503\n",
      "Epoch 38/2000\n",
      " - 10s - loss: 0.3833 - mean_squared_error: 0.3833 - val_loss: 0.3498 - val_mean_squared_error: 0.3498\n",
      "Epoch 39/2000\n",
      " - 10s - loss: 0.3820 - mean_squared_error: 0.3820 - val_loss: 0.3494 - val_mean_squared_error: 0.3494\n",
      "Epoch 40/2000\n",
      " - 11s - loss: 0.3795 - mean_squared_error: 0.3795 - val_loss: 0.3494 - val_mean_squared_error: 0.3494\n",
      "Epoch 41/2000\n",
      " - 10s - loss: 0.3787 - mean_squared_error: 0.3787 - val_loss: 0.3486 - val_mean_squared_error: 0.3486\n",
      "Epoch 42/2000\n",
      " - 11s - loss: 0.3764 - mean_squared_error: 0.3764 - val_loss: 0.3485 - val_mean_squared_error: 0.3485\n",
      "Epoch 43/2000\n",
      " - 10s - loss: 0.3755 - mean_squared_error: 0.3755 - val_loss: 0.3492 - val_mean_squared_error: 0.3492\n",
      "Epoch 44/2000\n",
      " - 10s - loss: 0.3731 - mean_squared_error: 0.3731 - val_loss: 0.3492 - val_mean_squared_error: 0.3492\n",
      "Epoch 45/2000\n",
      " - 10s - loss: 0.3716 - mean_squared_error: 0.3716 - val_loss: 0.3481 - val_mean_squared_error: 0.3481\n",
      "Epoch 46/2000\n",
      " - 10s - loss: 0.3707 - mean_squared_error: 0.3707 - val_loss: 0.3482 - val_mean_squared_error: 0.3482\n",
      "Epoch 47/2000\n",
      " - 10s - loss: 0.3691 - mean_squared_error: 0.3691 - val_loss: 0.3480 - val_mean_squared_error: 0.3480\n",
      "Epoch 48/2000\n",
      " - 10s - loss: 0.3678 - mean_squared_error: 0.3678 - val_loss: 0.3474 - val_mean_squared_error: 0.3474\n",
      "Epoch 49/2000\n",
      " - 10s - loss: 0.3657 - mean_squared_error: 0.3657 - val_loss: 0.3481 - val_mean_squared_error: 0.3481\n",
      "Epoch 50/2000\n",
      " - 10s - loss: 0.3654 - mean_squared_error: 0.3654 - val_loss: 0.3469 - val_mean_squared_error: 0.3469\n",
      "Epoch 51/2000\n",
      " - 10s - loss: 0.3644 - mean_squared_error: 0.3644 - val_loss: 0.3466 - val_mean_squared_error: 0.3466\n",
      "Epoch 52/2000\n",
      " - 10s - loss: 0.3632 - mean_squared_error: 0.3632 - val_loss: 0.3475 - val_mean_squared_error: 0.3475\n",
      "Epoch 53/2000\n",
      " - 10s - loss: 0.3613 - mean_squared_error: 0.3613 - val_loss: 0.3470 - val_mean_squared_error: 0.3470\n",
      "Epoch 54/2000\n",
      " - 10s - loss: 0.3605 - mean_squared_error: 0.3605 - val_loss: 0.3472 - val_mean_squared_error: 0.3472\n",
      "Epoch 55/2000\n",
      " - 10s - loss: 0.3594 - mean_squared_error: 0.3594 - val_loss: 0.3471 - val_mean_squared_error: 0.3471\n",
      "Epoch 56/2000\n",
      " - 10s - loss: 0.3587 - mean_squared_error: 0.3587 - val_loss: 0.3470 - val_mean_squared_error: 0.3470\n",
      "Epoch 57/2000\n",
      " - 10s - loss: 0.3581 - mean_squared_error: 0.3581 - val_loss: 0.3471 - val_mean_squared_error: 0.3471\n",
      "Epoch 58/2000\n",
      " - 10s - loss: 0.3571 - mean_squared_error: 0.3571 - val_loss: 0.3468 - val_mean_squared_error: 0.3468\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 59/2000\n",
      " - 12s - loss: 0.3552 - mean_squared_error: 0.3552 - val_loss: 0.3471 - val_mean_squared_error: 0.3471\n",
      "Epoch 60/2000\n",
      " - 10s - loss: 0.3558 - mean_squared_error: 0.3558 - val_loss: 0.3472 - val_mean_squared_error: 0.3472\n",
      "Epoch 61/2000\n",
      " - 10s - loss: 0.3559 - mean_squared_error: 0.3559 - val_loss: 0.3471 - val_mean_squared_error: 0.3471\n",
      "==================================================\n",
      "Step 5\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 147s - loss: 1.2115 - mean_squared_error: 1.2115 - val_loss: 0.8789 - val_mean_squared_error: 0.8789\n",
      "Epoch 2/2000\n",
      " - 10s - loss: 0.6804 - mean_squared_error: 0.6804 - val_loss: 0.6336 - val_mean_squared_error: 0.6336\n",
      "Epoch 3/2000\n",
      " - 10s - loss: 0.5791 - mean_squared_error: 0.5791 - val_loss: 0.5090 - val_mean_squared_error: 0.5090\n",
      "Epoch 4/2000\n",
      " - 10s - loss: 0.5386 - mean_squared_error: 0.5386 - val_loss: 0.4483 - val_mean_squared_error: 0.4483\n",
      "Epoch 5/2000\n",
      " - 10s - loss: 0.5155 - mean_squared_error: 0.5155 - val_loss: 0.4180 - val_mean_squared_error: 0.4180\n",
      "Epoch 6/2000\n",
      " - 10s - loss: 0.4989 - mean_squared_error: 0.4989 - val_loss: 0.4018 - val_mean_squared_error: 0.4018\n",
      "Epoch 7/2000\n",
      " - 10s - loss: 0.4848 - mean_squared_error: 0.4848 - val_loss: 0.3885 - val_mean_squared_error: 0.3885\n",
      "Epoch 8/2000\n",
      " - 10s - loss: 0.4766 - mean_squared_error: 0.4766 - val_loss: 0.3814 - val_mean_squared_error: 0.3814\n",
      "Epoch 9/2000\n",
      " - 10s - loss: 0.4665 - mean_squared_error: 0.4665 - val_loss: 0.3755 - val_mean_squared_error: 0.3755\n",
      "Epoch 10/2000\n",
      " - 10s - loss: 0.4615 - mean_squared_error: 0.4615 - val_loss: 0.3717 - val_mean_squared_error: 0.3717\n",
      "Epoch 11/2000\n",
      " - 10s - loss: 0.4553 - mean_squared_error: 0.4553 - val_loss: 0.3688 - val_mean_squared_error: 0.3688\n",
      "Epoch 12/2000\n",
      " - 10s - loss: 0.4501 - mean_squared_error: 0.4501 - val_loss: 0.3666 - val_mean_squared_error: 0.3666\n",
      "Epoch 13/2000\n",
      " - 11s - loss: 0.4445 - mean_squared_error: 0.4445 - val_loss: 0.3644 - val_mean_squared_error: 0.3644\n",
      "Epoch 14/2000\n",
      " - 10s - loss: 0.4410 - mean_squared_error: 0.4410 - val_loss: 0.3629 - val_mean_squared_error: 0.3629\n",
      "Epoch 15/2000\n",
      " - 10s - loss: 0.4368 - mean_squared_error: 0.4368 - val_loss: 0.3611 - val_mean_squared_error: 0.3611\n",
      "Epoch 16/2000\n",
      " - 10s - loss: 0.4322 - mean_squared_error: 0.4322 - val_loss: 0.3600 - val_mean_squared_error: 0.3600\n",
      "Epoch 17/2000\n",
      " - 10s - loss: 0.4289 - mean_squared_error: 0.4289 - val_loss: 0.3588 - val_mean_squared_error: 0.3588\n",
      "Epoch 18/2000\n",
      " - 10s - loss: 0.4249 - mean_squared_error: 0.4249 - val_loss: 0.3575 - val_mean_squared_error: 0.3575\n",
      "Epoch 19/2000\n",
      " - 10s - loss: 0.4225 - mean_squared_error: 0.4225 - val_loss: 0.3572 - val_mean_squared_error: 0.3572\n",
      "Epoch 20/2000\n",
      " - 10s - loss: 0.4188 - mean_squared_error: 0.4188 - val_loss: 0.3560 - val_mean_squared_error: 0.3560\n",
      "Epoch 21/2000\n",
      " - 10s - loss: 0.4164 - mean_squared_error: 0.4164 - val_loss: 0.3555 - val_mean_squared_error: 0.3555\n",
      "Epoch 22/2000\n",
      " - 10s - loss: 0.4130 - mean_squared_error: 0.4130 - val_loss: 0.3551 - val_mean_squared_error: 0.3551\n",
      "Epoch 23/2000\n",
      " - 10s - loss: 0.4106 - mean_squared_error: 0.4106 - val_loss: 0.3546 - val_mean_squared_error: 0.3546\n",
      "Epoch 24/2000\n",
      " - 10s - loss: 0.4085 - mean_squared_error: 0.4085 - val_loss: 0.3541 - val_mean_squared_error: 0.3541\n",
      "Epoch 25/2000\n",
      " - 11s - loss: 0.4060 - mean_squared_error: 0.4060 - val_loss: 0.3537 - val_mean_squared_error: 0.3537\n",
      "Epoch 26/2000\n",
      " - 11s - loss: 0.4037 - mean_squared_error: 0.4037 - val_loss: 0.3531 - val_mean_squared_error: 0.3531\n",
      "Epoch 27/2000\n",
      " - 10s - loss: 0.4018 - mean_squared_error: 0.4018 - val_loss: 0.3525 - val_mean_squared_error: 0.3525\n",
      "Epoch 28/2000\n",
      " - 10s - loss: 0.3995 - mean_squared_error: 0.3995 - val_loss: 0.3520 - val_mean_squared_error: 0.3520\n",
      "Epoch 29/2000\n",
      " - 10s - loss: 0.3973 - mean_squared_error: 0.3973 - val_loss: 0.3519 - val_mean_squared_error: 0.3519\n",
      "Epoch 30/2000\n",
      " - 11s - loss: 0.3953 - mean_squared_error: 0.3953 - val_loss: 0.3513 - val_mean_squared_error: 0.3513\n",
      "Epoch 31/2000\n",
      " - 10s - loss: 0.3931 - mean_squared_error: 0.3931 - val_loss: 0.3510 - val_mean_squared_error: 0.3510\n",
      "Epoch 32/2000\n",
      " - 11s - loss: 0.3917 - mean_squared_error: 0.3917 - val_loss: 0.3507 - val_mean_squared_error: 0.3507\n",
      "Epoch 33/2000\n",
      " - 10s - loss: 0.3901 - mean_squared_error: 0.3901 - val_loss: 0.3504 - val_mean_squared_error: 0.3504\n",
      "Epoch 34/2000\n",
      " - 10s - loss: 0.3885 - mean_squared_error: 0.3885 - val_loss: 0.3501 - val_mean_squared_error: 0.3501\n",
      "Epoch 35/2000\n",
      " - 10s - loss: 0.3867 - mean_squared_error: 0.3867 - val_loss: 0.3502 - val_mean_squared_error: 0.3502\n",
      "Epoch 36/2000\n",
      " - 10s - loss: 0.3849 - mean_squared_error: 0.3849 - val_loss: 0.3492 - val_mean_squared_error: 0.3492\n",
      "Epoch 37/2000\n",
      " - 10s - loss: 0.3839 - mean_squared_error: 0.3839 - val_loss: 0.3495 - val_mean_squared_error: 0.3495\n",
      "Epoch 38/2000\n",
      " - 10s - loss: 0.3823 - mean_squared_error: 0.3823 - val_loss: 0.3496 - val_mean_squared_error: 0.3496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/2000\n",
      " - 10s - loss: 0.3807 - mean_squared_error: 0.3807 - val_loss: 0.3492 - val_mean_squared_error: 0.3492\n",
      "Epoch 40/2000\n",
      " - 10s - loss: 0.3793 - mean_squared_error: 0.3793 - val_loss: 0.3491 - val_mean_squared_error: 0.3491\n",
      "Epoch 41/2000\n",
      " - 11s - loss: 0.3784 - mean_squared_error: 0.3784 - val_loss: 0.3486 - val_mean_squared_error: 0.3486\n",
      "Epoch 42/2000\n",
      " - 10s - loss: 0.3767 - mean_squared_error: 0.3767 - val_loss: 0.3481 - val_mean_squared_error: 0.3481\n",
      "Epoch 43/2000\n",
      " - 10s - loss: 0.3757 - mean_squared_error: 0.3757 - val_loss: 0.3482 - val_mean_squared_error: 0.3482\n",
      "Epoch 44/2000\n",
      " - 10s - loss: 0.3748 - mean_squared_error: 0.3748 - val_loss: 0.3481 - val_mean_squared_error: 0.3481\n",
      "Epoch 45/2000\n",
      " - 10s - loss: 0.3727 - mean_squared_error: 0.3727 - val_loss: 0.3479 - val_mean_squared_error: 0.3479\n",
      "Epoch 46/2000\n",
      " - 10s - loss: 0.3718 - mean_squared_error: 0.3718 - val_loss: 0.3475 - val_mean_squared_error: 0.3475\n",
      "Epoch 47/2000\n",
      " - 10s - loss: 0.3706 - mean_squared_error: 0.3706 - val_loss: 0.3475 - val_mean_squared_error: 0.3475\n",
      "Epoch 48/2000\n",
      " - 10s - loss: 0.3695 - mean_squared_error: 0.3695 - val_loss: 0.3471 - val_mean_squared_error: 0.3471\n",
      "Epoch 49/2000\n",
      " - 11s - loss: 0.3690 - mean_squared_error: 0.3690 - val_loss: 0.3474 - val_mean_squared_error: 0.3474\n",
      "Epoch 50/2000\n",
      " - 10s - loss: 0.3681 - mean_squared_error: 0.3681 - val_loss: 0.3477 - val_mean_squared_error: 0.3477\n",
      "Epoch 51/2000\n",
      " - 10s - loss: 0.3670 - mean_squared_error: 0.3670 - val_loss: 0.3472 - val_mean_squared_error: 0.3472\n",
      "Epoch 52/2000\n",
      " - 10s - loss: 0.3658 - mean_squared_error: 0.3658 - val_loss: 0.3472 - val_mean_squared_error: 0.3472\n",
      "Epoch 53/2000\n",
      " - 10s - loss: 0.3652 - mean_squared_error: 0.3652 - val_loss: 0.3477 - val_mean_squared_error: 0.3477\n",
      "Epoch 54/2000\n",
      " - 10s - loss: 0.3644 - mean_squared_error: 0.3644 - val_loss: 0.3476 - val_mean_squared_error: 0.3476\n",
      "Epoch 55/2000\n",
      " - 11s - loss: 0.3635 - mean_squared_error: 0.3635 - val_loss: 0.3474 - val_mean_squared_error: 0.3474\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 56/2000\n",
      " - 11s - loss: 0.3628 - mean_squared_error: 0.3628 - val_loss: 0.3474 - val_mean_squared_error: 0.3474\n",
      "Epoch 57/2000\n",
      " - 10s - loss: 0.3626 - mean_squared_error: 0.3626 - val_loss: 0.3475 - val_mean_squared_error: 0.3475\n",
      "Epoch 58/2000\n",
      " - 10s - loss: 0.3624 - mean_squared_error: 0.3624 - val_loss: 0.3475 - val_mean_squared_error: 0.3475\n",
      "==================================================\n",
      "Step 6\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 152s - loss: 1.8530 - mean_squared_error: 1.8530 - val_loss: 1.0398 - val_mean_squared_error: 1.0398\n",
      "Epoch 2/2000\n",
      " - 10s - loss: 0.9694 - mean_squared_error: 0.9694 - val_loss: 0.7423 - val_mean_squared_error: 0.7423\n",
      "Epoch 3/2000\n",
      " - 10s - loss: 0.7661 - mean_squared_error: 0.7661 - val_loss: 0.5427 - val_mean_squared_error: 0.5427\n",
      "Epoch 4/2000\n",
      " - 10s - loss: 0.6733 - mean_squared_error: 0.6733 - val_loss: 0.4707 - val_mean_squared_error: 0.4707\n",
      "Epoch 5/2000\n",
      " - 10s - loss: 0.6247 - mean_squared_error: 0.6247 - val_loss: 0.4310 - val_mean_squared_error: 0.4310\n",
      "Epoch 6/2000\n",
      " - 10s - loss: 0.5926 - mean_squared_error: 0.5926 - val_loss: 0.4118 - val_mean_squared_error: 0.4118\n",
      "Epoch 7/2000\n",
      " - 10s - loss: 0.5701 - mean_squared_error: 0.5701 - val_loss: 0.3996 - val_mean_squared_error: 0.3996\n",
      "Epoch 8/2000\n",
      " - 10s - loss: 0.5503 - mean_squared_error: 0.5503 - val_loss: 0.3932 - val_mean_squared_error: 0.3932\n",
      "Epoch 9/2000\n",
      " - 10s - loss: 0.5369 - mean_squared_error: 0.5369 - val_loss: 0.3886 - val_mean_squared_error: 0.3886\n",
      "Epoch 10/2000\n",
      " - 10s - loss: 0.5255 - mean_squared_error: 0.5255 - val_loss: 0.3859 - val_mean_squared_error: 0.3859\n",
      "Epoch 11/2000\n",
      " - 10s - loss: 0.5147 - mean_squared_error: 0.5147 - val_loss: 0.3842 - val_mean_squared_error: 0.3842\n",
      "Epoch 12/2000\n",
      " - 10s - loss: 0.5077 - mean_squared_error: 0.5077 - val_loss: 0.3809 - val_mean_squared_error: 0.3809\n",
      "Epoch 13/2000\n",
      " - 10s - loss: 0.4980 - mean_squared_error: 0.4980 - val_loss: 0.3802 - val_mean_squared_error: 0.3802\n",
      "Epoch 14/2000\n",
      " - 10s - loss: 0.4918 - mean_squared_error: 0.4918 - val_loss: 0.3787 - val_mean_squared_error: 0.3787\n",
      "Epoch 15/2000\n",
      " - 10s - loss: 0.4873 - mean_squared_error: 0.4873 - val_loss: 0.3772 - val_mean_squared_error: 0.3772\n",
      "Epoch 16/2000\n",
      " - 10s - loss: 0.4800 - mean_squared_error: 0.4800 - val_loss: 0.3767 - val_mean_squared_error: 0.3767\n",
      "Epoch 17/2000\n",
      " - 10s - loss: 0.4742 - mean_squared_error: 0.4742 - val_loss: 0.3756 - val_mean_squared_error: 0.3756\n",
      "Epoch 18/2000\n",
      " - 10s - loss: 0.4697 - mean_squared_error: 0.4697 - val_loss: 0.3744 - val_mean_squared_error: 0.3744\n",
      "Epoch 19/2000\n",
      " - 10s - loss: 0.4646 - mean_squared_error: 0.4646 - val_loss: 0.3730 - val_mean_squared_error: 0.3730\n",
      "Epoch 20/2000\n",
      " - 10s - loss: 0.4592 - mean_squared_error: 0.4592 - val_loss: 0.3733 - val_mean_squared_error: 0.3733\n",
      "Epoch 21/2000\n",
      " - 10s - loss: 0.4545 - mean_squared_error: 0.4545 - val_loss: 0.3725 - val_mean_squared_error: 0.3725\n",
      "Epoch 22/2000\n",
      " - 10s - loss: 0.4523 - mean_squared_error: 0.4523 - val_loss: 0.3715 - val_mean_squared_error: 0.3715\n",
      "Epoch 23/2000\n",
      " - 10s - loss: 0.4472 - mean_squared_error: 0.4472 - val_loss: 0.3709 - val_mean_squared_error: 0.3709\n",
      "Epoch 24/2000\n",
      " - 10s - loss: 0.4434 - mean_squared_error: 0.4434 - val_loss: 0.3696 - val_mean_squared_error: 0.3696\n",
      "Epoch 25/2000\n",
      " - 10s - loss: 0.4398 - mean_squared_error: 0.4398 - val_loss: 0.3689 - val_mean_squared_error: 0.3689\n",
      "Epoch 26/2000\n",
      " - 10s - loss: 0.4369 - mean_squared_error: 0.4369 - val_loss: 0.3698 - val_mean_squared_error: 0.3698\n",
      "Epoch 27/2000\n",
      " - 10s - loss: 0.4337 - mean_squared_error: 0.4337 - val_loss: 0.3694 - val_mean_squared_error: 0.3694\n",
      "Epoch 28/2000\n",
      " - 11s - loss: 0.4315 - mean_squared_error: 0.4315 - val_loss: 0.3700 - val_mean_squared_error: 0.3700\n",
      "Epoch 29/2000\n",
      " - 10s - loss: 0.4276 - mean_squared_error: 0.4276 - val_loss: 0.3694 - val_mean_squared_error: 0.3694\n",
      "Epoch 30/2000\n",
      " - 10s - loss: 0.4246 - mean_squared_error: 0.4246 - val_loss: 0.3683 - val_mean_squared_error: 0.3683\n",
      "Epoch 31/2000\n",
      " - 10s - loss: 0.4212 - mean_squared_error: 0.4212 - val_loss: 0.3677 - val_mean_squared_error: 0.3677\n",
      "Epoch 32/2000\n",
      " - 10s - loss: 0.4188 - mean_squared_error: 0.4188 - val_loss: 0.3669 - val_mean_squared_error: 0.3669\n",
      "Epoch 33/2000\n",
      " - 10s - loss: 0.4164 - mean_squared_error: 0.4164 - val_loss: 0.3660 - val_mean_squared_error: 0.3660\n",
      "Epoch 34/2000\n",
      " - 10s - loss: 0.4142 - mean_squared_error: 0.4142 - val_loss: 0.3667 - val_mean_squared_error: 0.3667\n",
      "Epoch 35/2000\n",
      " - 10s - loss: 0.4113 - mean_squared_error: 0.4113 - val_loss: 0.3658 - val_mean_squared_error: 0.3658\n",
      "Epoch 36/2000\n",
      " - 10s - loss: 0.4083 - mean_squared_error: 0.4083 - val_loss: 0.3654 - val_mean_squared_error: 0.3654\n",
      "Epoch 37/2000\n",
      " - 10s - loss: 0.4059 - mean_squared_error: 0.4059 - val_loss: 0.3658 - val_mean_squared_error: 0.3658\n",
      "Epoch 38/2000\n",
      " - 10s - loss: 0.4037 - mean_squared_error: 0.4037 - val_loss: 0.3649 - val_mean_squared_error: 0.3649\n",
      "Epoch 39/2000\n",
      " - 10s - loss: 0.4021 - mean_squared_error: 0.4021 - val_loss: 0.3648 - val_mean_squared_error: 0.3648\n",
      "Epoch 40/2000\n",
      " - 10s - loss: 0.3994 - mean_squared_error: 0.3994 - val_loss: 0.3643 - val_mean_squared_error: 0.3643\n",
      "Epoch 41/2000\n",
      " - 10s - loss: 0.3991 - mean_squared_error: 0.3991 - val_loss: 0.3642 - val_mean_squared_error: 0.3642\n",
      "Epoch 42/2000\n",
      " - 10s - loss: 0.3962 - mean_squared_error: 0.3962 - val_loss: 0.3634 - val_mean_squared_error: 0.3634\n",
      "Epoch 43/2000\n",
      " - 10s - loss: 0.3937 - mean_squared_error: 0.3937 - val_loss: 0.3643 - val_mean_squared_error: 0.3643\n",
      "Epoch 44/2000\n",
      " - 10s - loss: 0.3924 - mean_squared_error: 0.3924 - val_loss: 0.3633 - val_mean_squared_error: 0.3633\n",
      "Epoch 45/2000\n",
      " - 10s - loss: 0.3905 - mean_squared_error: 0.3905 - val_loss: 0.3631 - val_mean_squared_error: 0.3631\n",
      "Epoch 46/2000\n",
      " - 10s - loss: 0.3886 - mean_squared_error: 0.3886 - val_loss: 0.3635 - val_mean_squared_error: 0.3635\n",
      "Epoch 47/2000\n",
      " - 10s - loss: 0.3868 - mean_squared_error: 0.3868 - val_loss: 0.3644 - val_mean_squared_error: 0.3644\n",
      "Epoch 48/2000\n",
      " - 10s - loss: 0.3855 - mean_squared_error: 0.3855 - val_loss: 0.3622 - val_mean_squared_error: 0.3622\n",
      "Epoch 49/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 10s - loss: 0.3841 - mean_squared_error: 0.3841 - val_loss: 0.3638 - val_mean_squared_error: 0.3638\n",
      "Epoch 50/2000\n",
      " - 10s - loss: 0.3827 - mean_squared_error: 0.3827 - val_loss: 0.3626 - val_mean_squared_error: 0.3626\n",
      "Epoch 51/2000\n",
      " - 10s - loss: 0.3806 - mean_squared_error: 0.3806 - val_loss: 0.3616 - val_mean_squared_error: 0.3616\n",
      "Epoch 52/2000\n",
      " - 10s - loss: 0.3799 - mean_squared_error: 0.3799 - val_loss: 0.3625 - val_mean_squared_error: 0.3625\n",
      "Epoch 53/2000\n",
      " - 10s - loss: 0.3774 - mean_squared_error: 0.3774 - val_loss: 0.3632 - val_mean_squared_error: 0.3632\n",
      "Epoch 54/2000\n",
      " - 10s - loss: 0.3771 - mean_squared_error: 0.3771 - val_loss: 0.3628 - val_mean_squared_error: 0.3628\n",
      "Epoch 55/2000\n",
      " - 10s - loss: 0.3758 - mean_squared_error: 0.3758 - val_loss: 0.3619 - val_mean_squared_error: 0.3619\n",
      "Epoch 56/2000\n",
      " - 10s - loss: 0.3743 - mean_squared_error: 0.3743 - val_loss: 0.3613 - val_mean_squared_error: 0.3613\n",
      "Epoch 57/2000\n",
      " - 10s - loss: 0.3731 - mean_squared_error: 0.3731 - val_loss: 0.3625 - val_mean_squared_error: 0.3625\n",
      "Epoch 58/2000\n",
      " - 10s - loss: 0.3725 - mean_squared_error: 0.3725 - val_loss: 0.3611 - val_mean_squared_error: 0.3611\n",
      "Epoch 59/2000\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 67/2000\n",
      " - 11s - loss: 0.3635 - mean_squared_error: 0.3635 - val_loss: 0.3611 - val_mean_squared_error: 0.3611\n",
      "Epoch 68/2000\n",
      " - 10s - loss: 0.3634 - mean_squared_error: 0.3634 - val_loss: 0.3609 - val_mean_squared_error: 0.3609\n",
      "Epoch 69/2000\n",
      " - 10s - loss: 0.3633 - mean_squared_error: 0.3633 - val_loss: 0.3613 - val_mean_squared_error: 0.3613\n",
      "Epoch 70/2000\n",
      " - 11s - loss: 0.3637 - mean_squared_error: 0.3637 - val_loss: 0.3615 - val_mean_squared_error: 0.3615\n",
      "Epoch 71/2000\n",
      " - 10s - loss: 0.3637 - mean_squared_error: 0.3637 - val_loss: 0.3613 - val_mean_squared_error: 0.3613\n",
      "Epoch 72/2000\n",
      " - 10s - loss: 0.3631 - mean_squared_error: 0.3631 - val_loss: 0.3611 - val_mean_squared_error: 0.3611\n",
      "Epoch 73/2000\n",
      " - 10s - loss: 0.3631 - mean_squared_error: 0.3631 - val_loss: 0.3615 - val_mean_squared_error: 0.3615\n",
      "\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "==================================================\n",
      "Step 7\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 220s - loss: 1.6318 - mean_squared_error: 1.6318 - val_loss: 0.8834 - val_mean_squared_error: 0.8834\n",
      "Epoch 2/2000\n",
      " - 11s - loss: 0.7983 - mean_squared_error: 0.7983 - val_loss: 0.6010 - val_mean_squared_error: 0.6010\n",
      "Epoch 3/2000\n",
      " - 11s - loss: 0.6488 - mean_squared_error: 0.6488 - val_loss: 0.5038 - val_mean_squared_error: 0.5038\n",
      "Epoch 4/2000\n",
      " - 11s - loss: 0.5879 - mean_squared_error: 0.5879 - val_loss: 0.4658 - val_mean_squared_error: 0.4658\n",
      "Epoch 5/2000\n",
      " - 12s - loss: 0.5537 - mean_squared_error: 0.5537 - val_loss: 0.4490 - val_mean_squared_error: 0.4490\n",
      "Epoch 6/2000\n",
      " - 11s - loss: 0.5325 - mean_squared_error: 0.5325 - val_loss: 0.4414 - val_mean_squared_error: 0.4414\n",
      "Epoch 7/2000\n",
      " - 12s - loss: 0.5163 - mean_squared_error: 0.5163 - val_loss: 0.4372 - val_mean_squared_error: 0.4372\n",
      "Epoch 8/2000\n",
      " - 11s - loss: 0.5038 - mean_squared_error: 0.5038 - val_loss: 0.4357 - val_mean_squared_error: 0.4357\n",
      "Epoch 9/2000\n",
      " - 11s - loss: 0.4948 - mean_squared_error: 0.4948 - val_loss: 0.4334 - val_mean_squared_error: 0.4334\n",
      "Epoch 10/2000\n",
      " - 9s - loss: 0.4848 - mean_squared_error: 0.4848 - val_loss: 0.4336 - val_mean_squared_error: 0.4336\n",
      "Epoch 11/2000\n",
      " - 9s - loss: 0.4786 - mean_squared_error: 0.4786 - val_loss: 0.4312 - val_mean_squared_error: 0.4312\n",
      "Epoch 12/2000\n",
      " - 9s - loss: 0.4715 - mean_squared_error: 0.4715 - val_loss: 0.4307 - val_mean_squared_error: 0.4307\n",
      "Epoch 13/2000\n",
      " - 9s - loss: 0.4655 - mean_squared_error: 0.4655 - val_loss: 0.4301 - val_mean_squared_error: 0.4301\n",
      "Epoch 14/2000\n",
      " - 10s - loss: 0.4601 - mean_squared_error: 0.4601 - val_loss: 0.4287 - val_mean_squared_error: 0.4287\n",
      "Epoch 15/2000\n",
      " - 9s - loss: 0.4554 - mean_squared_error: 0.4554 - val_loss: 0.4269 - val_mean_squared_error: 0.4269\n",
      "Epoch 16/2000\n",
      " - 9s - loss: 0.4521 - mean_squared_error: 0.4521 - val_loss: 0.4261 - val_mean_squared_error: 0.4261\n",
      "Epoch 17/2000\n",
      " - 12s - loss: 0.4466 - mean_squared_error: 0.4466 - val_loss: 0.4280 - val_mean_squared_error: 0.4280\n",
      "Epoch 18/2000\n",
      " - 14s - loss: 0.4411 - mean_squared_error: 0.4411 - val_loss: 0.4257 - val_mean_squared_error: 0.4257\n",
      "Epoch 19/2000\n",
      " - 14s - loss: 0.4384 - mean_squared_error: 0.4384 - val_loss: 0.4247 - val_mean_squared_error: 0.4247\n",
      "Epoch 20/2000\n",
      " - 14s - loss: 0.4339 - mean_squared_error: 0.4339 - val_loss: 0.4255 - val_mean_squared_error: 0.4255\n",
      "Epoch 21/2000\n",
      " - 14s - loss: 0.4300 - mean_squared_error: 0.4300 - val_loss: 0.4237 - val_mean_squared_error: 0.4237\n",
      "Epoch 22/2000\n",
      " - 14s - loss: 0.4269 - mean_squared_error: 0.4269 - val_loss: 0.4259 - val_mean_squared_error: 0.4259\n",
      "Epoch 23/2000\n",
      " - 13s - loss: 0.4233 - mean_squared_error: 0.4233 - val_loss: 0.4271 - val_mean_squared_error: 0.4271\n",
      "Epoch 24/2000\n",
      " - 13s - loss: 0.4200 - mean_squared_error: 0.4200 - val_loss: 0.4254 - val_mean_squared_error: 0.4254\n",
      "Epoch 25/2000\n",
      " - 14s - loss: 0.4180 - mean_squared_error: 0.4180 - val_loss: 0.4246 - val_mean_squared_error: 0.4246\n",
      "Epoch 26/2000\n",
      " - 14s - loss: 0.4135 - mean_squared_error: 0.4135 - val_loss: 0.4252 - val_mean_squared_error: 0.4252\n",
      "Epoch 27/2000\n",
      " - 14s - loss: 0.4115 - mean_squared_error: 0.4115 - val_loss: 0.4246 - val_mean_squared_error: 0.4246\n",
      "Epoch 28/2000\n",
      " - 13s - loss: 0.4080 - mean_squared_error: 0.4080 - val_loss: 0.4248 - val_mean_squared_error: 0.4248\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 29/2000\n",
      " - 15s - loss: 0.4071 - mean_squared_error: 0.4071 - val_loss: 0.4301 - val_mean_squared_error: 0.4301\n",
      "Epoch 30/2000\n",
      " - 14s - loss: 0.4063 - mean_squared_error: 0.4063 - val_loss: 0.4316 - val_mean_squared_error: 0.4316\n",
      "Epoch 31/2000\n",
      " - 14s - loss: 0.4063 - mean_squared_error: 0.4063 - val_loss: 0.4319 - val_mean_squared_error: 0.4319\n",
      "==================================================\n",
      "Step 8\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 266s - loss: 1.4729 - mean_squared_error: 1.4729 - val_loss: 0.9201 - val_mean_squared_error: 0.9201\n",
      "Epoch 2/2000\n",
      " - 10s - loss: 0.8276 - mean_squared_error: 0.8276 - val_loss: 0.6724 - val_mean_squared_error: 0.6724\n",
      "Epoch 3/2000\n",
      " - 12s - loss: 0.6614 - mean_squared_error: 0.6614 - val_loss: 0.5256 - val_mean_squared_error: 0.5256\n",
      "Epoch 4/2000\n",
      " - 14s - loss: 0.5910 - mean_squared_error: 0.5910 - val_loss: 0.4591 - val_mean_squared_error: 0.4591\n",
      "Epoch 5/2000\n",
      " - 14s - loss: 0.5556 - mean_squared_error: 0.5556 - val_loss: 0.4338 - val_mean_squared_error: 0.4338\n",
      "Epoch 6/2000\n",
      " - 14s - loss: 0.5333 - mean_squared_error: 0.5333 - val_loss: 0.4201 - val_mean_squared_error: 0.4201\n",
      "Epoch 7/2000\n",
      " - 14s - loss: 0.5159 - mean_squared_error: 0.5159 - val_loss: 0.4135 - val_mean_squared_error: 0.4135\n",
      "Epoch 8/2000\n",
      " - 14s - loss: 0.5009 - mean_squared_error: 0.5009 - val_loss: 0.4089 - val_mean_squared_error: 0.4089\n",
      "Epoch 9/2000\n",
      " - 14s - loss: 0.4882 - mean_squared_error: 0.4882 - val_loss: 0.4058 - val_mean_squared_error: 0.4058\n",
      "Epoch 10/2000\n",
      " - 14s - loss: 0.4789 - mean_squared_error: 0.4789 - val_loss: 0.4026 - val_mean_squared_error: 0.4026\n",
      "Epoch 11/2000\n",
      " - 14s - loss: 0.4701 - mean_squared_error: 0.4701 - val_loss: 0.4022 - val_mean_squared_error: 0.4022\n",
      "Epoch 12/2000\n",
      " - 14s - loss: 0.4630 - mean_squared_error: 0.4630 - val_loss: 0.4011 - val_mean_squared_error: 0.4011\n",
      "Epoch 13/2000\n",
      " - 14s - loss: 0.4583 - mean_squared_error: 0.4583 - val_loss: 0.3982 - val_mean_squared_error: 0.3982\n",
      "Epoch 14/2000\n",
      " - 14s - loss: 0.4522 - mean_squared_error: 0.4522 - val_loss: 0.3977 - val_mean_squared_error: 0.3977\n",
      "Epoch 15/2000\n",
      " - 14s - loss: 0.4461 - mean_squared_error: 0.4461 - val_loss: 0.3974 - val_mean_squared_error: 0.3974\n",
      "Epoch 16/2000\n",
      " - 14s - loss: 0.4382 - mean_squared_error: 0.4382 - val_loss: 0.3968 - val_mean_squared_error: 0.3968\n",
      "Epoch 17/2000\n",
      " - 14s - loss: 0.4367 - mean_squared_error: 0.4367 - val_loss: 0.3964 - val_mean_squared_error: 0.3964\n",
      "Epoch 18/2000\n",
      " - 14s - loss: 0.4300 - mean_squared_error: 0.4300 - val_loss: 0.3982 - val_mean_squared_error: 0.3982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/2000\n",
      " - 14s - loss: 0.4266 - mean_squared_error: 0.4266 - val_loss: 0.3971 - val_mean_squared_error: 0.3971\n",
      "Epoch 20/2000\n",
      " - 14s - loss: 0.4223 - mean_squared_error: 0.4223 - val_loss: 0.3965 - val_mean_squared_error: 0.3965\n",
      "Epoch 21/2000\n",
      " - 14s - loss: 0.4196 - mean_squared_error: 0.4196 - val_loss: 0.3977 - val_mean_squared_error: 0.3977\n",
      "Epoch 22/2000\n",
      " - 14s - loss: 0.4154 - mean_squared_error: 0.4154 - val_loss: 0.3981 - val_mean_squared_error: 0.3981\n",
      "Epoch 23/2000\n",
      " - 14s - loss: 0.4119 - mean_squared_error: 0.4119 - val_loss: 0.3974 - val_mean_squared_error: 0.3974\n",
      "Epoch 24/2000\n",
      " - 12s - loss: 0.4083 - mean_squared_error: 0.4083 - val_loss: 0.3961 - val_mean_squared_error: 0.3961\n",
      "Epoch 25/2000\n",
      " - 11s - loss: 0.4055 - mean_squared_error: 0.4055 - val_loss: 0.3938 - val_mean_squared_error: 0.3938\n",
      "Epoch 26/2000\n",
      " - 10s - loss: 0.4020 - mean_squared_error: 0.4020 - val_loss: 0.3963 - val_mean_squared_error: 0.3963\n",
      "Epoch 27/2000\n",
      " - 10s - loss: 0.3991 - mean_squared_error: 0.3991 - val_loss: 0.3957 - val_mean_squared_error: 0.3957\n",
      "Epoch 28/2000\n",
      " - 10s - loss: 0.3965 - mean_squared_error: 0.3965 - val_loss: 0.3964 - val_mean_squared_error: 0.3964\n",
      "Epoch 29/2000\n",
      " - 10s - loss: 0.3939 - mean_squared_error: 0.3939 - val_loss: 0.3945 - val_mean_squared_error: 0.3945\n",
      "Epoch 30/2000\n",
      " - 11s - loss: 0.3914 - mean_squared_error: 0.3914 - val_loss: 0.3981 - val_mean_squared_error: 0.3981\n",
      "Epoch 31/2000\n",
      " - 13s - loss: 0.3881 - mean_squared_error: 0.3881 - val_loss: 0.3970 - val_mean_squared_error: 0.3970\n",
      "Epoch 32/2000\n",
      " - 14s - loss: 0.3855 - mean_squared_error: 0.3855 - val_loss: 0.3961 - val_mean_squared_error: 0.3961\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 33/2000\n",
      " - 16s - loss: 0.3854 - mean_squared_error: 0.3854 - val_loss: 0.3990 - val_mean_squared_error: 0.3990\n",
      "Epoch 34/2000\n",
      " - 14s - loss: 0.3842 - mean_squared_error: 0.3842 - val_loss: 0.3999 - val_mean_squared_error: 0.3999\n",
      "Epoch 35/2000\n",
      " - 14s - loss: 0.3844 - mean_squared_error: 0.3844 - val_loss: 0.4000 - val_mean_squared_error: 0.4000\n",
      "==================================================\n",
      "Step 9\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 254s - loss: 1.3003 - mean_squared_error: 1.3003 - val_loss: 0.8404 - val_mean_squared_error: 0.8404\n",
      "Epoch 2/2000\n",
      " - 11s - loss: 0.7391 - mean_squared_error: 0.7391 - val_loss: 0.5843 - val_mean_squared_error: 0.5843\n",
      "Epoch 3/2000\n",
      " - 10s - loss: 0.6283 - mean_squared_error: 0.6283 - val_loss: 0.4844 - val_mean_squared_error: 0.4844\n",
      "Epoch 4/2000\n",
      " - 10s - loss: 0.5756 - mean_squared_error: 0.5756 - val_loss: 0.4388 - val_mean_squared_error: 0.4388\n",
      "Epoch 5/2000\n",
      " - 11s - loss: 0.5448 - mean_squared_error: 0.5448 - val_loss: 0.4193 - val_mean_squared_error: 0.4193\n",
      "Epoch 6/2000\n",
      " - 11s - loss: 0.5225 - mean_squared_error: 0.5225 - val_loss: 0.4072 - val_mean_squared_error: 0.4072\n",
      "Epoch 7/2000\n",
      " - 12s - loss: 0.5065 - mean_squared_error: 0.5065 - val_loss: 0.4005 - val_mean_squared_error: 0.4005\n",
      "Epoch 8/2000\n",
      " - 13s - loss: 0.4941 - mean_squared_error: 0.4941 - val_loss: 0.3960 - val_mean_squared_error: 0.3960\n",
      "Epoch 9/2000\n",
      " - 14s - loss: 0.4831 - mean_squared_error: 0.4831 - val_loss: 0.3931 - val_mean_squared_error: 0.3931\n",
      "Epoch 10/2000\n",
      " - 14s - loss: 0.4729 - mean_squared_error: 0.4729 - val_loss: 0.3917 - val_mean_squared_error: 0.3917\n",
      "Epoch 11/2000\n",
      " - 14s - loss: 0.4658 - mean_squared_error: 0.4658 - val_loss: 0.3900 - val_mean_squared_error: 0.3900\n",
      "Epoch 12/2000\n",
      " - 14s - loss: 0.4604 - mean_squared_error: 0.4604 - val_loss: 0.3896 - val_mean_squared_error: 0.3896\n",
      "Epoch 13/2000\n",
      " - 14s - loss: 0.4545 - mean_squared_error: 0.4545 - val_loss: 0.3878 - val_mean_squared_error: 0.3878\n",
      "Epoch 14/2000\n",
      " - 14s - loss: 0.4496 - mean_squared_error: 0.4496 - val_loss: 0.3877 - val_mean_squared_error: 0.3877\n",
      "Epoch 15/2000\n",
      " - 14s - loss: 0.4432 - mean_squared_error: 0.4432 - val_loss: 0.3876 - val_mean_squared_error: 0.3876\n",
      "Epoch 16/2000\n",
      " - 14s - loss: 0.4389 - mean_squared_error: 0.4389 - val_loss: 0.3855 - val_mean_squared_error: 0.3855\n",
      "Epoch 17/2000\n",
      " - 14s - loss: 0.4343 - mean_squared_error: 0.4343 - val_loss: 0.3853 - val_mean_squared_error: 0.3853\n",
      "Epoch 18/2000\n",
      " - 14s - loss: 0.4296 - mean_squared_error: 0.4296 - val_loss: 0.3841 - val_mean_squared_error: 0.3841\n",
      "Epoch 19/2000\n",
      " - 14s - loss: 0.4259 - mean_squared_error: 0.4259 - val_loss: 0.3831 - val_mean_squared_error: 0.3831\n",
      "Epoch 20/2000\n",
      " - 14s - loss: 0.4230 - mean_squared_error: 0.4230 - val_loss: 0.3827 - val_mean_squared_error: 0.3827\n",
      "Epoch 21/2000\n",
      " - 14s - loss: 0.4179 - mean_squared_error: 0.4179 - val_loss: 0.3826 - val_mean_squared_error: 0.3826\n",
      "Epoch 22/2000\n",
      " - 14s - loss: 0.4159 - mean_squared_error: 0.4159 - val_loss: 0.3823 - val_mean_squared_error: 0.3823\n",
      "Epoch 23/2000\n",
      " - 14s - loss: 0.4115 - mean_squared_error: 0.4115 - val_loss: 0.3817 - val_mean_squared_error: 0.3817\n",
      "Epoch 24/2000\n",
      " - 14s - loss: 0.4094 - mean_squared_error: 0.4094 - val_loss: 0.3826 - val_mean_squared_error: 0.3826\n",
      "Epoch 25/2000\n",
      " - 14s - loss: 0.4066 - mean_squared_error: 0.4066 - val_loss: 0.3814 - val_mean_squared_error: 0.3814\n",
      "Epoch 26/2000\n",
      " - 14s - loss: 0.4039 - mean_squared_error: 0.4039 - val_loss: 0.3821 - val_mean_squared_error: 0.3821\n",
      "Epoch 27/2000\n",
      " - 14s - loss: 0.4010 - mean_squared_error: 0.4010 - val_loss: 0.3818 - val_mean_squared_error: 0.3818\n",
      "Epoch 28/2000\n",
      " - 14s - loss: 0.3973 - mean_squared_error: 0.3973 - val_loss: 0.3816 - val_mean_squared_error: 0.3816\n",
      "Epoch 29/2000\n",
      " - 11s - loss: 0.3952 - mean_squared_error: 0.3952 - val_loss: 0.3830 - val_mean_squared_error: 0.3830\n",
      "Epoch 30/2000\n",
      " - 10s - loss: 0.3939 - mean_squared_error: 0.3939 - val_loss: 0.3813 - val_mean_squared_error: 0.3813\n",
      "Epoch 31/2000\n",
      " - 10s - loss: 0.3909 - mean_squared_error: 0.3909 - val_loss: 0.3801 - val_mean_squared_error: 0.3801\n",
      "Epoch 32/2000\n",
      " - 10s - loss: 0.3889 - mean_squared_error: 0.3889 - val_loss: 0.3795 - val_mean_squared_error: 0.3795\n",
      "Epoch 33/2000\n",
      " - 10s - loss: 0.3871 - mean_squared_error: 0.3871 - val_loss: 0.3790 - val_mean_squared_error: 0.3790\n",
      "Epoch 34/2000\n",
      " - 10s - loss: 0.3854 - mean_squared_error: 0.3854 - val_loss: 0.3798 - val_mean_squared_error: 0.3798\n",
      "Epoch 35/2000\n",
      " - 11s - loss: 0.3836 - mean_squared_error: 0.3836 - val_loss: 0.3784 - val_mean_squared_error: 0.3784\n",
      "Epoch 36/2000\n",
      " - 14s - loss: 0.3801 - mean_squared_error: 0.3801 - val_loss: 0.3807 - val_mean_squared_error: 0.3807\n",
      "Epoch 37/2000\n",
      " - 14s - loss: 0.3795 - mean_squared_error: 0.3795 - val_loss: 0.3798 - val_mean_squared_error: 0.3798\n",
      "Epoch 38/2000\n",
      " - 14s - loss: 0.3772 - mean_squared_error: 0.3772 - val_loss: 0.3802 - val_mean_squared_error: 0.3802\n",
      "Epoch 39/2000\n",
      " - 14s - loss: 0.3756 - mean_squared_error: 0.3756 - val_loss: 0.3799 - val_mean_squared_error: 0.3799\n",
      "Epoch 40/2000\n",
      " - 14s - loss: 0.3737 - mean_squared_error: 0.3737 - val_loss: 0.3800 - val_mean_squared_error: 0.3800\n",
      "Epoch 41/2000\n",
      " - 14s - loss: 0.3723 - mean_squared_error: 0.3723 - val_loss: 0.3794 - val_mean_squared_error: 0.3794\n",
      "Epoch 42/2000\n",
      " - 14s - loss: 0.3707 - mean_squared_error: 0.3707 - val_loss: 0.3791 - val_mean_squared_error: 0.3791\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 43/2000\n",
      " - 18s - loss: 0.3693 - mean_squared_error: 0.3693 - val_loss: 0.3804 - val_mean_squared_error: 0.3804\n",
      "Epoch 44/2000\n",
      " - 14s - loss: 0.3692 - mean_squared_error: 0.3692 - val_loss: 0.3808 - val_mean_squared_error: 0.3808\n",
      "Epoch 45/2000\n",
      " - 14s - loss: 0.3683 - mean_squared_error: 0.3683 - val_loss: 0.3810 - val_mean_squared_error: 0.3810\n",
      "==================================================\n",
      "Step 10\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 366s - loss: 1.7545 - mean_squared_error: 1.7545 - val_loss: 0.9747 - val_mean_squared_error: 0.9747\n",
      "Epoch 2/2000\n",
      " - 12s - loss: 1.0007 - mean_squared_error: 1.0007 - val_loss: 0.7162 - val_mean_squared_error: 0.7162\n",
      "Epoch 3/2000\n",
      " - 11s - loss: 0.7797 - mean_squared_error: 0.7797 - val_loss: 0.5686 - val_mean_squared_error: 0.5686\n",
      "Epoch 4/2000\n",
      " - 11s - loss: 0.6876 - mean_squared_error: 0.6876 - val_loss: 0.4837 - val_mean_squared_error: 0.4837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/2000\n",
      " - 11s - loss: 0.6393 - mean_squared_error: 0.6393 - val_loss: 0.4435 - val_mean_squared_error: 0.4435\n",
      "Epoch 6/2000\n",
      " - 12s - loss: 0.6035 - mean_squared_error: 0.6035 - val_loss: 0.4238 - val_mean_squared_error: 0.4238\n",
      "Epoch 7/2000\n",
      " - 14s - loss: 0.5794 - mean_squared_error: 0.5794 - val_loss: 0.4140 - val_mean_squared_error: 0.4140\n",
      "Epoch 8/2000\n",
      " - 15s - loss: 0.5607 - mean_squared_error: 0.5607 - val_loss: 0.4080 - val_mean_squared_error: 0.4080\n",
      "Epoch 9/2000\n",
      " - 15s - loss: 0.5463 - mean_squared_error: 0.5463 - val_loss: 0.4038 - val_mean_squared_error: 0.4038\n",
      "Epoch 10/2000\n",
      " - 15s - loss: 0.5355 - mean_squared_error: 0.5355 - val_loss: 0.3992 - val_mean_squared_error: 0.3992\n",
      "Epoch 11/2000\n",
      " - 15s - loss: 0.5217 - mean_squared_error: 0.5217 - val_loss: 0.3961 - val_mean_squared_error: 0.3961\n",
      "Epoch 12/2000\n",
      " - 15s - loss: 0.5144 - mean_squared_error: 0.5144 - val_loss: 0.3929 - val_mean_squared_error: 0.3929\n",
      "Epoch 13/2000\n",
      " - 15s - loss: 0.5051 - mean_squared_error: 0.5051 - val_loss: 0.3903 - val_mean_squared_error: 0.3903\n",
      "Epoch 14/2000\n",
      " - 15s - loss: 0.4959 - mean_squared_error: 0.4959 - val_loss: 0.3894 - val_mean_squared_error: 0.3894\n",
      "Epoch 15/2000\n",
      " - 15s - loss: 0.4877 - mean_squared_error: 0.4877 - val_loss: 0.3878 - val_mean_squared_error: 0.3878\n",
      "Epoch 16/2000\n",
      " - 15s - loss: 0.4828 - mean_squared_error: 0.4828 - val_loss: 0.3853 - val_mean_squared_error: 0.3853\n",
      "Epoch 17/2000\n",
      " - 15s - loss: 0.4754 - mean_squared_error: 0.4754 - val_loss: 0.3842 - val_mean_squared_error: 0.3842\n",
      "Epoch 18/2000\n",
      " - 15s - loss: 0.4707 - mean_squared_error: 0.4707 - val_loss: 0.3844 - val_mean_squared_error: 0.3844\n",
      "Epoch 19/2000\n",
      " - 15s - loss: 0.4639 - mean_squared_error: 0.4639 - val_loss: 0.3827 - val_mean_squared_error: 0.3827\n",
      "Epoch 20/2000\n",
      " - 15s - loss: 0.4608 - mean_squared_error: 0.4608 - val_loss: 0.3826 - val_mean_squared_error: 0.3826\n",
      "Epoch 21/2000\n",
      " - 15s - loss: 0.4553 - mean_squared_error: 0.4553 - val_loss: 0.3810 - val_mean_squared_error: 0.3810\n",
      "Epoch 22/2000\n",
      " - 15s - loss: 0.4508 - mean_squared_error: 0.4508 - val_loss: 0.3803 - val_mean_squared_error: 0.3803\n",
      "Epoch 23/2000\n",
      " - 15s - loss: 0.4436 - mean_squared_error: 0.4436 - val_loss: 0.3800 - val_mean_squared_error: 0.3800\n",
      "Epoch 24/2000\n",
      " - 15s - loss: 0.4384 - mean_squared_error: 0.4384 - val_loss: 0.3791 - val_mean_squared_error: 0.3791\n",
      "Epoch 25/2000\n",
      " - 15s - loss: 0.4378 - mean_squared_error: 0.4378 - val_loss: 0.3777 - val_mean_squared_error: 0.3777\n",
      "Epoch 26/2000\n",
      " - 15s - loss: 0.4331 - mean_squared_error: 0.4331 - val_loss: 0.3765 - val_mean_squared_error: 0.3765\n",
      "Epoch 27/2000\n",
      " - 15s - loss: 0.4292 - mean_squared_error: 0.4292 - val_loss: 0.3778 - val_mean_squared_error: 0.3778\n",
      "Epoch 28/2000\n",
      " - 15s - loss: 0.4266 - mean_squared_error: 0.4266 - val_loss: 0.3765 - val_mean_squared_error: 0.3765\n",
      "Epoch 29/2000\n",
      " - 15s - loss: 0.4229 - mean_squared_error: 0.4229 - val_loss: 0.3772 - val_mean_squared_error: 0.3772\n",
      "Epoch 30/2000\n",
      " - 15s - loss: 0.4183 - mean_squared_error: 0.4183 - val_loss: 0.3766 - val_mean_squared_error: 0.3766\n",
      "Epoch 31/2000\n",
      " - 17s - loss: 0.4155 - mean_squared_error: 0.4155 - val_loss: 0.3758 - val_mean_squared_error: 0.3758\n",
      "Epoch 32/2000\n",
      " - 15s - loss: 0.4128 - mean_squared_error: 0.4128 - val_loss: 0.3770 - val_mean_squared_error: 0.3770\n",
      "Epoch 33/2000\n",
      " - 15s - loss: 0.4101 - mean_squared_error: 0.4101 - val_loss: 0.3762 - val_mean_squared_error: 0.3762\n",
      "Epoch 34/2000\n",
      " - 14s - loss: 0.4063 - mean_squared_error: 0.4063 - val_loss: 0.3745 - val_mean_squared_error: 0.3745\n",
      "Epoch 35/2000\n",
      " - 12s - loss: 0.4040 - mean_squared_error: 0.4040 - val_loss: 0.3747 - val_mean_squared_error: 0.3747\n",
      "Epoch 36/2000\n",
      " - 12s - loss: 0.4009 - mean_squared_error: 0.4009 - val_loss: 0.3737 - val_mean_squared_error: 0.3737\n",
      "Epoch 37/2000\n",
      " - 12s - loss: 0.3994 - mean_squared_error: 0.3994 - val_loss: 0.3729 - val_mean_squared_error: 0.3729\n",
      "Epoch 38/2000\n",
      " - 12s - loss: 0.3964 - mean_squared_error: 0.3964 - val_loss: 0.3730 - val_mean_squared_error: 0.3730\n",
      "Epoch 39/2000\n",
      " - 12s - loss: 0.3928 - mean_squared_error: 0.3928 - val_loss: 0.3722 - val_mean_squared_error: 0.3722\n",
      "Epoch 40/2000\n",
      " - 12s - loss: 0.3914 - mean_squared_error: 0.3914 - val_loss: 0.3734 - val_mean_squared_error: 0.3734\n",
      "Epoch 41/2000\n",
      " - 13s - loss: 0.3910 - mean_squared_error: 0.3910 - val_loss: 0.3719 - val_mean_squared_error: 0.3719\n",
      "Epoch 42/2000\n",
      " - 15s - loss: 0.3869 - mean_squared_error: 0.3869 - val_loss: 0.3721 - val_mean_squared_error: 0.3721\n",
      "Epoch 43/2000\n",
      " - 15s - loss: 0.3852 - mean_squared_error: 0.3852 - val_loss: 0.3718 - val_mean_squared_error: 0.3718\n",
      "Epoch 44/2000\n",
      " - 15s - loss: 0.3842 - mean_squared_error: 0.3842 - val_loss: 0.3721 - val_mean_squared_error: 0.3721\n",
      "Epoch 45/2000\n",
      " - 15s - loss: 0.3819 - mean_squared_error: 0.3819 - val_loss: 0.3718 - val_mean_squared_error: 0.3718\n",
      "Epoch 46/2000\n",
      " - 15s - loss: 0.3793 - mean_squared_error: 0.3793 - val_loss: 0.3727 - val_mean_squared_error: 0.3727\n",
      "Epoch 47/2000\n",
      " - 15s - loss: 0.3783 - mean_squared_error: 0.3783 - val_loss: 0.3738 - val_mean_squared_error: 0.3738\n",
      "Epoch 48/2000\n",
      " - 15s - loss: 0.3760 - mean_squared_error: 0.3760 - val_loss: 0.3716 - val_mean_squared_error: 0.3716\n",
      "Epoch 49/2000\n",
      " - 15s - loss: 0.3744 - mean_squared_error: 0.3744 - val_loss: 0.3716 - val_mean_squared_error: 0.3716\n",
      "Epoch 50/2000\n",
      " - 15s - loss: 0.3727 - mean_squared_error: 0.3727 - val_loss: 0.3707 - val_mean_squared_error: 0.3707\n",
      "Epoch 51/2000\n",
      " - 15s - loss: 0.3709 - mean_squared_error: 0.3709 - val_loss: 0.3703 - val_mean_squared_error: 0.3703\n",
      "Epoch 52/2000\n",
      " - 15s - loss: 0.3698 - mean_squared_error: 0.3698 - val_loss: 0.3703 - val_mean_squared_error: 0.3703\n",
      "Epoch 53/2000\n",
      " - 15s - loss: 0.3689 - mean_squared_error: 0.3689 - val_loss: 0.3706 - val_mean_squared_error: 0.3706\n",
      "Epoch 54/2000\n",
      " - 15s - loss: 0.3671 - mean_squared_error: 0.3671 - val_loss: 0.3693 - val_mean_squared_error: 0.3693\n",
      "Epoch 55/2000\n",
      " - 15s - loss: 0.3653 - mean_squared_error: 0.3653 - val_loss: 0.3702 - val_mean_squared_error: 0.3702\n",
      "Epoch 56/2000\n",
      " - 15s - loss: 0.3644 - mean_squared_error: 0.3644 - val_loss: 0.3702 - val_mean_squared_error: 0.3702\n",
      "Epoch 57/2000\n",
      " - 15s - loss: 0.3632 - mean_squared_error: 0.3632 - val_loss: 0.3703 - val_mean_squared_error: 0.3703\n",
      "Epoch 58/2000\n",
      " - 15s - loss: 0.3630 - mean_squared_error: 0.3630 - val_loss: 0.3690 - val_mean_squared_error: 0.3690\n",
      "Epoch 59/2000\n",
      " - 15s - loss: 0.3604 - mean_squared_error: 0.3604 - val_loss: 0.3700 - val_mean_squared_error: 0.3700\n",
      "Epoch 60/2000\n",
      " - 15s - loss: 0.3595 - mean_squared_error: 0.3595 - val_loss: 0.3714 - val_mean_squared_error: 0.3714\n",
      "Epoch 61/2000\n",
      " - 15s - loss: 0.3592 - mean_squared_error: 0.3592 - val_loss: 0.3713 - val_mean_squared_error: 0.3713\n",
      "Epoch 62/2000\n",
      " - 15s - loss: 0.3572 - mean_squared_error: 0.3572 - val_loss: 0.3696 - val_mean_squared_error: 0.3696\n",
      "Epoch 63/2000\n",
      " - 15s - loss: 0.3571 - mean_squared_error: 0.3571 - val_loss: 0.3705 - val_mean_squared_error: 0.3705\n",
      "Epoch 64/2000\n",
      " - 15s - loss: 0.3557 - mean_squared_error: 0.3557 - val_loss: 0.3691 - val_mean_squared_error: 0.3691\n",
      "Epoch 65/2000\n",
      " - 15s - loss: 0.3551 - mean_squared_error: 0.3551 - val_loss: 0.3686 - val_mean_squared_error: 0.3686\n",
      "Epoch 66/2000\n",
      " - 15s - loss: 0.3541 - mean_squared_error: 0.3541 - val_loss: 0.3693 - val_mean_squared_error: 0.3693\n",
      "Epoch 67/2000\n",
      " - 15s - loss: 0.3532 - mean_squared_error: 0.3532 - val_loss: 0.3705 - val_mean_squared_error: 0.3705\n",
      "Epoch 68/2000\n",
      " - 15s - loss: 0.3522 - mean_squared_error: 0.3522 - val_loss: 0.3690 - val_mean_squared_error: 0.3690\n",
      "Epoch 69/2000\n",
      " - 14s - loss: 0.3516 - mean_squared_error: 0.3516 - val_loss: 0.3681 - val_mean_squared_error: 0.3681\n",
      "Epoch 70/2000\n",
      " - 11s - loss: 0.3507 - mean_squared_error: 0.3507 - val_loss: 0.3689 - val_mean_squared_error: 0.3689\n",
      "Epoch 71/2000\n",
      " - 12s - loss: 0.3494 - mean_squared_error: 0.3494 - val_loss: 0.3671 - val_mean_squared_error: 0.3671\n",
      "Epoch 72/2000\n",
      " - 12s - loss: 0.3489 - mean_squared_error: 0.3489 - val_loss: 0.3683 - val_mean_squared_error: 0.3683\n",
      "Epoch 73/2000\n",
      " - 11s - loss: 0.3485 - mean_squared_error: 0.3485 - val_loss: 0.3693 - val_mean_squared_error: 0.3693\n",
      "Epoch 74/2000\n",
      " - 11s - loss: 0.3475 - mean_squared_error: 0.3475 - val_loss: 0.3691 - val_mean_squared_error: 0.3691\n",
      "Epoch 75/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 10s - loss: 0.3469 - mean_squared_error: 0.3469 - val_loss: 0.3689 - val_mean_squared_error: 0.3689\n",
      "Epoch 76/2000\n",
      " - 13s - loss: 0.3461 - mean_squared_error: 0.3461 - val_loss: 0.3698 - val_mean_squared_error: 0.3698\n",
      "Epoch 77/2000\n",
      " - 15s - loss: 0.3460 - mean_squared_error: 0.3460 - val_loss: 0.3706 - val_mean_squared_error: 0.3706\n",
      "Epoch 78/2000\n",
      " - 15s - loss: 0.3456 - mean_squared_error: 0.3456 - val_loss: 0.3691 - val_mean_squared_error: 0.3691\n",
      "\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 79/2000\n",
      " - 16s - loss: 0.3442 - mean_squared_error: 0.3442 - val_loss: 0.3699 - val_mean_squared_error: 0.3699\n",
      "Epoch 80/2000\n",
      " - 15s - loss: 0.3436 - mean_squared_error: 0.3436 - val_loss: 0.3700 - val_mean_squared_error: 0.3700\n",
      "Epoch 81/2000\n",
      " - 15s - loss: 0.3434 - mean_squared_error: 0.3434 - val_loss: 0.3701 - val_mean_squared_error: 0.3701\n",
      "==================================================\n",
      "Step 11\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 334s - loss: 1.6189 - mean_squared_error: 1.6189 - val_loss: 0.9085 - val_mean_squared_error: 0.9085\n",
      "Epoch 2/2000\n",
      " - 15s - loss: 0.8501 - mean_squared_error: 0.8501 - val_loss: 0.7316 - val_mean_squared_error: 0.7316\n",
      "Epoch 3/2000\n",
      " - 15s - loss: 0.7001 - mean_squared_error: 0.7001 - val_loss: 0.5628 - val_mean_squared_error: 0.5628\n",
      "Epoch 4/2000\n",
      " - 15s - loss: 0.6420 - mean_squared_error: 0.6420 - val_loss: 0.4801 - val_mean_squared_error: 0.4801\n",
      "Epoch 5/2000\n",
      " - 15s - loss: 0.6078 - mean_squared_error: 0.6078 - val_loss: 0.4454 - val_mean_squared_error: 0.4454\n",
      "Epoch 6/2000\n",
      " - 15s - loss: 0.5857 - mean_squared_error: 0.5857 - val_loss: 0.4268 - val_mean_squared_error: 0.4268\n",
      "Epoch 7/2000\n",
      " - 15s - loss: 0.5701 - mean_squared_error: 0.5701 - val_loss: 0.4130 - val_mean_squared_error: 0.4130\n",
      "Epoch 8/2000\n",
      " - 15s - loss: 0.5543 - mean_squared_error: 0.5543 - val_loss: 0.4056 - val_mean_squared_error: 0.4056\n",
      "Epoch 9/2000\n",
      " - 15s - loss: 0.5443 - mean_squared_error: 0.5443 - val_loss: 0.3996 - val_mean_squared_error: 0.3996\n",
      "Epoch 10/2000\n",
      " - 12s - loss: 0.5333 - mean_squared_error: 0.5333 - val_loss: 0.3954 - val_mean_squared_error: 0.3954\n",
      "Epoch 11/2000\n",
      " - 12s - loss: 0.5267 - mean_squared_error: 0.5267 - val_loss: 0.3930 - val_mean_squared_error: 0.3930\n",
      "Epoch 12/2000\n",
      " - 13s - loss: 0.5187 - mean_squared_error: 0.5187 - val_loss: 0.3900 - val_mean_squared_error: 0.3900\n",
      "Epoch 13/2000\n",
      " - 11s - loss: 0.5122 - mean_squared_error: 0.5122 - val_loss: 0.3882 - val_mean_squared_error: 0.3882\n",
      "Epoch 14/2000\n",
      " - 11s - loss: 0.5049 - mean_squared_error: 0.5049 - val_loss: 0.3865 - val_mean_squared_error: 0.3865\n",
      "Epoch 15/2000\n",
      " - 11s - loss: 0.4979 - mean_squared_error: 0.4979 - val_loss: 0.3849 - val_mean_squared_error: 0.3849\n",
      "Epoch 16/2000\n",
      " - 11s - loss: 0.4939 - mean_squared_error: 0.4939 - val_loss: 0.3838 - val_mean_squared_error: 0.3838\n",
      "Epoch 17/2000\n",
      " - 12s - loss: 0.4888 - mean_squared_error: 0.4888 - val_loss: 0.3826 - val_mean_squared_error: 0.3826\n",
      "Epoch 18/2000\n",
      " - 15s - loss: 0.4834 - mean_squared_error: 0.4834 - val_loss: 0.3819 - val_mean_squared_error: 0.3819\n",
      "Epoch 19/2000\n",
      " - 15s - loss: 0.4795 - mean_squared_error: 0.4795 - val_loss: 0.3810 - val_mean_squared_error: 0.3810\n",
      "Epoch 20/2000\n",
      " - 15s - loss: 0.4750 - mean_squared_error: 0.4750 - val_loss: 0.3800 - val_mean_squared_error: 0.3800\n",
      "Epoch 21/2000\n",
      " - 14s - loss: 0.4695 - mean_squared_error: 0.4695 - val_loss: 0.3794 - val_mean_squared_error: 0.3794\n",
      "Epoch 22/2000\n",
      " - 15s - loss: 0.4653 - mean_squared_error: 0.4653 - val_loss: 0.3787 - val_mean_squared_error: 0.3787\n",
      "Epoch 23/2000\n",
      " - 15s - loss: 0.4614 - mean_squared_error: 0.4614 - val_loss: 0.3785 - val_mean_squared_error: 0.3785\n",
      "Epoch 24/2000\n",
      " - 15s - loss: 0.4586 - mean_squared_error: 0.4586 - val_loss: 0.3778 - val_mean_squared_error: 0.3778\n",
      "Epoch 25/2000\n",
      " - 15s - loss: 0.4550 - mean_squared_error: 0.4550 - val_loss: 0.3779 - val_mean_squared_error: 0.3779\n",
      "Epoch 26/2000\n",
      " - 14s - loss: 0.4521 - mean_squared_error: 0.4521 - val_loss: 0.3772 - val_mean_squared_error: 0.3772\n",
      "Epoch 27/2000\n",
      " - 15s - loss: 0.4474 - mean_squared_error: 0.4474 - val_loss: 0.3767 - val_mean_squared_error: 0.3767\n",
      "Epoch 28/2000\n",
      " - 15s - loss: 0.4455 - mean_squared_error: 0.4455 - val_loss: 0.3761 - val_mean_squared_error: 0.3761\n",
      "Epoch 29/2000\n",
      " - 15s - loss: 0.4414 - mean_squared_error: 0.4414 - val_loss: 0.3758 - val_mean_squared_error: 0.3758\n",
      "Epoch 30/2000\n",
      " - 15s - loss: 0.4385 - mean_squared_error: 0.4385 - val_loss: 0.3758 - val_mean_squared_error: 0.3758\n",
      "Epoch 31/2000\n",
      " - 15s - loss: 0.4350 - mean_squared_error: 0.4350 - val_loss: 0.3752 - val_mean_squared_error: 0.3752\n",
      "Epoch 32/2000\n",
      " - 15s - loss: 0.4327 - mean_squared_error: 0.4327 - val_loss: 0.3749 - val_mean_squared_error: 0.3749\n",
      "Epoch 33/2000\n",
      " - 14s - loss: 0.4292 - mean_squared_error: 0.4292 - val_loss: 0.3740 - val_mean_squared_error: 0.3740\n",
      "Epoch 34/2000\n",
      " - 14s - loss: 0.4264 - mean_squared_error: 0.4264 - val_loss: 0.3737 - val_mean_squared_error: 0.3737\n",
      "Epoch 35/2000\n",
      " - 15s - loss: 0.4252 - mean_squared_error: 0.4252 - val_loss: 0.3740 - val_mean_squared_error: 0.3740\n",
      "Epoch 36/2000\n",
      " - 15s - loss: 0.4222 - mean_squared_error: 0.4222 - val_loss: 0.3736 - val_mean_squared_error: 0.3736\n",
      "Epoch 37/2000\n",
      " - 15s - loss: 0.4191 - mean_squared_error: 0.4191 - val_loss: 0.3735 - val_mean_squared_error: 0.3735\n",
      "Epoch 38/2000\n",
      " - 15s - loss: 0.4169 - mean_squared_error: 0.4169 - val_loss: 0.3732 - val_mean_squared_error: 0.3732\n",
      "Epoch 39/2000\n",
      " - 15s - loss: 0.4159 - mean_squared_error: 0.4159 - val_loss: 0.3728 - val_mean_squared_error: 0.3728\n",
      "Epoch 40/2000\n",
      " - 15s - loss: 0.4131 - mean_squared_error: 0.4131 - val_loss: 0.3727 - val_mean_squared_error: 0.3727\n",
      "Epoch 41/2000\n",
      " - 14s - loss: 0.4111 - mean_squared_error: 0.4111 - val_loss: 0.3723 - val_mean_squared_error: 0.3723\n",
      "Epoch 42/2000\n",
      " - 15s - loss: 0.4091 - mean_squared_error: 0.4091 - val_loss: 0.3724 - val_mean_squared_error: 0.3724\n",
      "Epoch 43/2000\n",
      " - 14s - loss: 0.4075 - mean_squared_error: 0.4075 - val_loss: 0.3723 - val_mean_squared_error: 0.3723\n",
      "Epoch 44/2000\n",
      " - 14s - loss: 0.4051 - mean_squared_error: 0.4051 - val_loss: 0.3729 - val_mean_squared_error: 0.3729\n",
      "Epoch 45/2000\n",
      " - 15s - loss: 0.4033 - mean_squared_error: 0.4033 - val_loss: 0.3726 - val_mean_squared_error: 0.3726\n",
      "Epoch 46/2000\n",
      " - 15s - loss: 0.4019 - mean_squared_error: 0.4019 - val_loss: 0.3728 - val_mean_squared_error: 0.3728\n",
      "Epoch 47/2000\n",
      " - 11s - loss: 0.4000 - mean_squared_error: 0.4000 - val_loss: 0.3724 - val_mean_squared_error: 0.3724\n",
      "Epoch 48/2000\n",
      " - 11s - loss: 0.3988 - mean_squared_error: 0.3988 - val_loss: 0.3722 - val_mean_squared_error: 0.3722\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 49/2000\n",
      " - 16s - loss: 0.3968 - mean_squared_error: 0.3968 - val_loss: 0.3725 - val_mean_squared_error: 0.3725\n",
      "Epoch 50/2000\n",
      " - 15s - loss: 0.3973 - mean_squared_error: 0.3973 - val_loss: 0.3727 - val_mean_squared_error: 0.3727\n",
      "Epoch 51/2000\n",
      " - 15s - loss: 0.3963 - mean_squared_error: 0.3963 - val_loss: 0.3728 - val_mean_squared_error: 0.3728\n",
      "Epoch 52/2000\n",
      " - 15s - loss: 0.3974 - mean_squared_error: 0.3974 - val_loss: 0.3728 - val_mean_squared_error: 0.3728\n",
      "Epoch 53/2000\n",
      " - 15s - loss: 0.3959 - mean_squared_error: 0.3959 - val_loss: 0.3727 - val_mean_squared_error: 0.3727\n",
      "Epoch 54/2000\n",
      " - 15s - loss: 0.3960 - mean_squared_error: 0.3960 - val_loss: 0.3727 - val_mean_squared_error: 0.3727\n",
      "Epoch 55/2000\n",
      " - 15s - loss: 0.3966 - mean_squared_error: 0.3966 - val_loss: 0.3729 - val_mean_squared_error: 0.3729\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 56/2000\n",
      " - 15s - loss: 0.3958 - mean_squared_error: 0.3958 - val_loss: 0.3729 - val_mean_squared_error: 0.3729\n",
      "Epoch 57/2000\n",
      " - 15s - loss: 0.3956 - mean_squared_error: 0.3956 - val_loss: 0.3729 - val_mean_squared_error: 0.3729\n",
      "Epoch 58/2000\n",
      " - 15s - loss: 0.3958 - mean_squared_error: 0.3958 - val_loss: 0.3729 - val_mean_squared_error: 0.3729\n",
      "==================================================\n",
      "Step 12\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 305s - loss: 1.6935 - mean_squared_error: 1.6935 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2000\n",
      " - 15s - loss: 0.9321 - mean_squared_error: 0.9321 - val_loss: 0.6884 - val_mean_squared_error: 0.6884\n",
      "Epoch 3/2000\n",
      " - 15s - loss: 0.7626 - mean_squared_error: 0.7626 - val_loss: 0.5621 - val_mean_squared_error: 0.5621\n",
      "Epoch 4/2000\n",
      " - 15s - loss: 0.6885 - mean_squared_error: 0.6885 - val_loss: 0.5023 - val_mean_squared_error: 0.5023\n",
      "Epoch 5/2000\n",
      " - 15s - loss: 0.6518 - mean_squared_error: 0.6518 - val_loss: 0.4734 - val_mean_squared_error: 0.4734\n",
      "Epoch 6/2000\n",
      " - 15s - loss: 0.6221 - mean_squared_error: 0.6221 - val_loss: 0.4525 - val_mean_squared_error: 0.4525\n",
      "Epoch 7/2000\n",
      " - 15s - loss: 0.6024 - mean_squared_error: 0.6024 - val_loss: 0.4377 - val_mean_squared_error: 0.4377\n",
      "Epoch 8/2000\n",
      " - 15s - loss: 0.5888 - mean_squared_error: 0.5888 - val_loss: 0.4294 - val_mean_squared_error: 0.4294\n",
      "Epoch 9/2000\n",
      " - 15s - loss: 0.5754 - mean_squared_error: 0.5754 - val_loss: 0.4220 - val_mean_squared_error: 0.4220\n",
      "Epoch 10/2000\n",
      " - 15s - loss: 0.5635 - mean_squared_error: 0.5635 - val_loss: 0.4165 - val_mean_squared_error: 0.4165\n",
      "Epoch 11/2000\n",
      " - 15s - loss: 0.5543 - mean_squared_error: 0.5543 - val_loss: 0.4130 - val_mean_squared_error: 0.4130\n",
      "Epoch 12/2000\n",
      " - 15s - loss: 0.5456 - mean_squared_error: 0.5456 - val_loss: 0.4099 - val_mean_squared_error: 0.4099\n",
      "Epoch 13/2000\n",
      " - 15s - loss: 0.5375 - mean_squared_error: 0.5375 - val_loss: 0.4071 - val_mean_squared_error: 0.4071\n",
      "Epoch 14/2000\n",
      " - 15s - loss: 0.5301 - mean_squared_error: 0.5301 - val_loss: 0.4049 - val_mean_squared_error: 0.4049\n",
      "Epoch 15/2000\n",
      " - 15s - loss: 0.5231 - mean_squared_error: 0.5231 - val_loss: 0.4034 - val_mean_squared_error: 0.4034\n",
      "Epoch 16/2000\n",
      " - 12s - loss: 0.5192 - mean_squared_error: 0.5192 - val_loss: 0.4016 - val_mean_squared_error: 0.4016\n",
      "Epoch 17/2000\n",
      " - 11s - loss: 0.5118 - mean_squared_error: 0.5118 - val_loss: 0.4001 - val_mean_squared_error: 0.4001\n",
      "Epoch 18/2000\n",
      " - 12s - loss: 0.5046 - mean_squared_error: 0.5046 - val_loss: 0.3990 - val_mean_squared_error: 0.3990\n",
      "Epoch 19/2000\n",
      " - 11s - loss: 0.5007 - mean_squared_error: 0.5007 - val_loss: 0.3974 - val_mean_squared_error: 0.3974\n",
      "Epoch 20/2000\n",
      " - 12s - loss: 0.4944 - mean_squared_error: 0.4944 - val_loss: 0.3962 - val_mean_squared_error: 0.3962\n",
      "Epoch 21/2000\n",
      " - 11s - loss: 0.4909 - mean_squared_error: 0.4909 - val_loss: 0.3951 - val_mean_squared_error: 0.3951\n",
      "Epoch 22/2000\n",
      " - 12s - loss: 0.4863 - mean_squared_error: 0.4863 - val_loss: 0.3940 - val_mean_squared_error: 0.3940\n",
      "Epoch 23/2000\n",
      " - 14s - loss: 0.4828 - mean_squared_error: 0.4828 - val_loss: 0.3931 - val_mean_squared_error: 0.3931\n",
      "Epoch 24/2000\n",
      " - 15s - loss: 0.4773 - mean_squared_error: 0.4773 - val_loss: 0.3926 - val_mean_squared_error: 0.3926\n",
      "Epoch 25/2000\n",
      " - 15s - loss: 0.4737 - mean_squared_error: 0.4737 - val_loss: 0.3913 - val_mean_squared_error: 0.3913\n",
      "Epoch 26/2000\n",
      " - 15s - loss: 0.4704 - mean_squared_error: 0.4704 - val_loss: 0.3907 - val_mean_squared_error: 0.3907\n",
      "Epoch 27/2000\n",
      " - 15s - loss: 0.4659 - mean_squared_error: 0.4659 - val_loss: 0.3902 - val_mean_squared_error: 0.3902\n",
      "Epoch 28/2000\n",
      " - 15s - loss: 0.4620 - mean_squared_error: 0.4620 - val_loss: 0.3895 - val_mean_squared_error: 0.3895\n",
      "Epoch 29/2000\n",
      " - 15s - loss: 0.4586 - mean_squared_error: 0.4586 - val_loss: 0.3888 - val_mean_squared_error: 0.3888\n",
      "Epoch 30/2000\n",
      " - 15s - loss: 0.4553 - mean_squared_error: 0.4553 - val_loss: 0.3887 - val_mean_squared_error: 0.3887\n",
      "Epoch 31/2000\n",
      " - 15s - loss: 0.4525 - mean_squared_error: 0.4525 - val_loss: 0.3880 - val_mean_squared_error: 0.3880\n",
      "Epoch 32/2000\n",
      " - 15s - loss: 0.4492 - mean_squared_error: 0.4492 - val_loss: 0.3876 - val_mean_squared_error: 0.3876\n",
      "Epoch 33/2000\n",
      " - 15s - loss: 0.4464 - mean_squared_error: 0.4464 - val_loss: 0.3869 - val_mean_squared_error: 0.3869\n",
      "Epoch 34/2000\n",
      " - 15s - loss: 0.4437 - mean_squared_error: 0.4437 - val_loss: 0.3863 - val_mean_squared_error: 0.3863\n",
      "Epoch 35/2000\n",
      " - 15s - loss: 0.4412 - mean_squared_error: 0.4412 - val_loss: 0.3863 - val_mean_squared_error: 0.3863\n",
      "Epoch 36/2000\n",
      " - 15s - loss: 0.4388 - mean_squared_error: 0.4388 - val_loss: 0.3861 - val_mean_squared_error: 0.3861\n",
      "Epoch 37/2000\n",
      " - 15s - loss: 0.4357 - mean_squared_error: 0.4357 - val_loss: 0.3859 - val_mean_squared_error: 0.3859\n",
      "Epoch 38/2000\n",
      " - 15s - loss: 0.4334 - mean_squared_error: 0.4334 - val_loss: 0.3855 - val_mean_squared_error: 0.3855\n",
      "Epoch 39/2000\n",
      " - 15s - loss: 0.4308 - mean_squared_error: 0.4308 - val_loss: 0.3853 - val_mean_squared_error: 0.3853\n",
      "Epoch 40/2000\n",
      " - 15s - loss: 0.4284 - mean_squared_error: 0.4284 - val_loss: 0.3849 - val_mean_squared_error: 0.3849\n",
      "Epoch 41/2000\n",
      " - 15s - loss: 0.4256 - mean_squared_error: 0.4256 - val_loss: 0.3845 - val_mean_squared_error: 0.3845\n",
      "Epoch 42/2000\n",
      " - 15s - loss: 0.4240 - mean_squared_error: 0.4240 - val_loss: 0.3841 - val_mean_squared_error: 0.3841\n",
      "Epoch 43/2000\n",
      " - 15s - loss: 0.4218 - mean_squared_error: 0.4218 - val_loss: 0.3839 - val_mean_squared_error: 0.3839\n",
      "Epoch 44/2000\n",
      " - 15s - loss: 0.4205 - mean_squared_error: 0.4205 - val_loss: 0.3835 - val_mean_squared_error: 0.3835\n",
      "Epoch 45/2000\n",
      " - 14s - loss: 0.4187 - mean_squared_error: 0.4187 - val_loss: 0.3844 - val_mean_squared_error: 0.3844\n",
      "Epoch 46/2000\n",
      " - 15s - loss: 0.4159 - mean_squared_error: 0.4159 - val_loss: 0.3837 - val_mean_squared_error: 0.3837\n",
      "Epoch 47/2000\n",
      " - 15s - loss: 0.4143 - mean_squared_error: 0.4143 - val_loss: 0.3838 - val_mean_squared_error: 0.3838\n",
      "Epoch 48/2000\n",
      " - 15s - loss: 0.4127 - mean_squared_error: 0.4127 - val_loss: 0.3839 - val_mean_squared_error: 0.3839\n",
      "Epoch 49/2000\n",
      " - 14s - loss: 0.4107 - mean_squared_error: 0.4107 - val_loss: 0.3834 - val_mean_squared_error: 0.3834\n",
      "Epoch 50/2000\n",
      " - 15s - loss: 0.4086 - mean_squared_error: 0.4086 - val_loss: 0.3829 - val_mean_squared_error: 0.3829\n",
      "Epoch 51/2000\n",
      " - 15s - loss: 0.4082 - mean_squared_error: 0.4082 - val_loss: 0.3833 - val_mean_squared_error: 0.3833\n",
      "Epoch 52/2000\n",
      " - 12s - loss: 0.4062 - mean_squared_error: 0.4062 - val_loss: 0.3830 - val_mean_squared_error: 0.3830\n",
      "Epoch 53/2000\n",
      " - 11s - loss: 0.4051 - mean_squared_error: 0.4051 - val_loss: 0.3835 - val_mean_squared_error: 0.3835\n",
      "Epoch 54/2000\n",
      " - 11s - loss: 0.4032 - mean_squared_error: 0.4032 - val_loss: 0.3826 - val_mean_squared_error: 0.3826\n",
      "Epoch 55/2000\n",
      " - 11s - loss: 0.4018 - mean_squared_error: 0.4018 - val_loss: 0.3825 - val_mean_squared_error: 0.3825\n",
      "Epoch 56/2000\n",
      " - 11s - loss: 0.4001 - mean_squared_error: 0.4001 - val_loss: 0.3832 - val_mean_squared_error: 0.3832\n",
      "Epoch 57/2000\n",
      " - 11s - loss: 0.3989 - mean_squared_error: 0.3989 - val_loss: 0.3829 - val_mean_squared_error: 0.3829\n",
      "Epoch 58/2000\n",
      " - 12s - loss: 0.3978 - mean_squared_error: 0.3978 - val_loss: 0.3832 - val_mean_squared_error: 0.3832\n",
      "Epoch 59/2000\n",
      " - 14s - loss: 0.3968 - mean_squared_error: 0.3968 - val_loss: 0.3827 - val_mean_squared_error: 0.3827\n",
      "Epoch 60/2000\n",
      " - 15s - loss: 0.3958 - mean_squared_error: 0.3958 - val_loss: 0.3822 - val_mean_squared_error: 0.3822\n",
      "Epoch 61/2000\n",
      " - 15s - loss: 0.3940 - mean_squared_error: 0.3940 - val_loss: 0.3824 - val_mean_squared_error: 0.3824\n",
      "Epoch 62/2000\n",
      " - 15s - loss: 0.3932 - mean_squared_error: 0.3932 - val_loss: 0.3816 - val_mean_squared_error: 0.3816\n",
      "Epoch 63/2000\n",
      " - 15s - loss: 0.3918 - mean_squared_error: 0.3918 - val_loss: 0.3828 - val_mean_squared_error: 0.3828\n",
      "Epoch 64/2000\n",
      " - 15s - loss: 0.3909 - mean_squared_error: 0.3909 - val_loss: 0.3822 - val_mean_squared_error: 0.3822\n",
      "Epoch 65/2000\n",
      " - 15s - loss: 0.3902 - mean_squared_error: 0.3902 - val_loss: 0.3821 - val_mean_squared_error: 0.3821\n",
      "Epoch 66/2000\n",
      " - 15s - loss: 0.3889 - mean_squared_error: 0.3889 - val_loss: 0.3825 - val_mean_squared_error: 0.3825\n",
      "Epoch 67/2000\n",
      " - 15s - loss: 0.3884 - mean_squared_error: 0.3884 - val_loss: 0.3822 - val_mean_squared_error: 0.3822\n",
      "Epoch 68/2000\n",
      " - 15s - loss: 0.3874 - mean_squared_error: 0.3874 - val_loss: 0.3825 - val_mean_squared_error: 0.3825\n",
      "Epoch 69/2000\n",
      " - 15s - loss: 0.3863 - mean_squared_error: 0.3863 - val_loss: 0.3821 - val_mean_squared_error: 0.3821\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 70/2000\n",
      " - 16s - loss: 0.3856 - mean_squared_error: 0.3856 - val_loss: 0.3823 - val_mean_squared_error: 0.3823\n",
      "Epoch 71/2000\n",
      " - 14s - loss: 0.3849 - mean_squared_error: 0.3849 - val_loss: 0.3822 - val_mean_squared_error: 0.3822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/2000\n",
      " - 14s - loss: 0.3852 - mean_squared_error: 0.3852 - val_loss: 0.3821 - val_mean_squared_error: 0.3821\n",
      "==================================================\n",
      "Step 13\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 212s - loss: 1.2916 - mean_squared_error: 1.2916 - val_loss: 1.0313 - val_mean_squared_error: 1.0313\n",
      "Epoch 2/2000\n",
      " - 11s - loss: 0.7194 - mean_squared_error: 0.7194 - val_loss: 0.6313 - val_mean_squared_error: 0.6313\n",
      "Epoch 3/2000\n",
      " - 11s - loss: 0.6207 - mean_squared_error: 0.6207 - val_loss: 0.4959 - val_mean_squared_error: 0.4959\n",
      "Epoch 4/2000\n",
      " - 11s - loss: 0.5790 - mean_squared_error: 0.5790 - val_loss: 0.4434 - val_mean_squared_error: 0.4434\n",
      "Epoch 5/2000\n",
      " - 11s - loss: 0.5523 - mean_squared_error: 0.5523 - val_loss: 0.4201 - val_mean_squared_error: 0.4201\n",
      "Epoch 6/2000\n",
      " - 11s - loss: 0.5370 - mean_squared_error: 0.5370 - val_loss: 0.4080 - val_mean_squared_error: 0.4080\n",
      "Epoch 7/2000\n",
      " - 11s - loss: 0.5230 - mean_squared_error: 0.5230 - val_loss: 0.4004 - val_mean_squared_error: 0.4004\n",
      "Epoch 8/2000\n",
      " - 11s - loss: 0.5120 - mean_squared_error: 0.5120 - val_loss: 0.3957 - val_mean_squared_error: 0.3957\n",
      "Epoch 9/2000\n",
      " - 11s - loss: 0.5048 - mean_squared_error: 0.5048 - val_loss: 0.3925 - val_mean_squared_error: 0.3925\n",
      "Epoch 10/2000\n",
      " - 11s - loss: 0.4963 - mean_squared_error: 0.4963 - val_loss: 0.3897 - val_mean_squared_error: 0.3897\n",
      "Epoch 11/2000\n",
      " - 11s - loss: 0.4895 - mean_squared_error: 0.4895 - val_loss: 0.3874 - val_mean_squared_error: 0.3874\n",
      "Epoch 12/2000\n",
      " - 11s - loss: 0.4822 - mean_squared_error: 0.4822 - val_loss: 0.3853 - val_mean_squared_error: 0.3853\n",
      "Epoch 13/2000\n",
      " - 11s - loss: 0.4785 - mean_squared_error: 0.4785 - val_loss: 0.3841 - val_mean_squared_error: 0.3841\n",
      "Epoch 14/2000\n",
      " - 11s - loss: 0.4726 - mean_squared_error: 0.4726 - val_loss: 0.3834 - val_mean_squared_error: 0.3834\n",
      "Epoch 15/2000\n",
      " - 11s - loss: 0.4679 - mean_squared_error: 0.4679 - val_loss: 0.3819 - val_mean_squared_error: 0.3819\n",
      "Epoch 16/2000\n",
      " - 11s - loss: 0.4633 - mean_squared_error: 0.4633 - val_loss: 0.3812 - val_mean_squared_error: 0.3812\n",
      "Epoch 17/2000\n",
      " - 11s - loss: 0.4597 - mean_squared_error: 0.4597 - val_loss: 0.3804 - val_mean_squared_error: 0.3804\n",
      "Epoch 18/2000\n",
      " - 11s - loss: 0.4556 - mean_squared_error: 0.4556 - val_loss: 0.3799 - val_mean_squared_error: 0.3799\n",
      "Epoch 19/2000\n",
      " - 11s - loss: 0.4527 - mean_squared_error: 0.4527 - val_loss: 0.3792 - val_mean_squared_error: 0.3792\n",
      "Epoch 20/2000\n",
      " - 11s - loss: 0.4476 - mean_squared_error: 0.4476 - val_loss: 0.3788 - val_mean_squared_error: 0.3788\n",
      "Epoch 21/2000\n",
      " - 11s - loss: 0.4460 - mean_squared_error: 0.4460 - val_loss: 0.3786 - val_mean_squared_error: 0.3786\n",
      "Epoch 22/2000\n",
      " - 11s - loss: 0.4417 - mean_squared_error: 0.4417 - val_loss: 0.3788 - val_mean_squared_error: 0.3788\n",
      "Epoch 23/2000\n",
      " - 11s - loss: 0.4387 - mean_squared_error: 0.4387 - val_loss: 0.3781 - val_mean_squared_error: 0.3781\n",
      "Epoch 24/2000\n",
      " - 11s - loss: 0.4371 - mean_squared_error: 0.4371 - val_loss: 0.3779 - val_mean_squared_error: 0.3779\n",
      "Epoch 25/2000\n",
      " - 11s - loss: 0.4330 - mean_squared_error: 0.4330 - val_loss: 0.3773 - val_mean_squared_error: 0.3773\n",
      "Epoch 26/2000\n",
      " - 11s - loss: 0.4310 - mean_squared_error: 0.4310 - val_loss: 0.3775 - val_mean_squared_error: 0.3775\n",
      "Epoch 27/2000\n",
      " - 11s - loss: 0.4288 - mean_squared_error: 0.4288 - val_loss: 0.3769 - val_mean_squared_error: 0.3769\n",
      "Epoch 28/2000\n",
      " - 11s - loss: 0.4254 - mean_squared_error: 0.4254 - val_loss: 0.3769 - val_mean_squared_error: 0.3769\n",
      "Epoch 29/2000\n",
      " - 11s - loss: 0.4244 - mean_squared_error: 0.4244 - val_loss: 0.3766 - val_mean_squared_error: 0.3766\n",
      "Epoch 30/2000\n",
      " - 11s - loss: 0.4215 - mean_squared_error: 0.4215 - val_loss: 0.3767 - val_mean_squared_error: 0.3767\n",
      "Epoch 31/2000\n",
      " - 11s - loss: 0.4192 - mean_squared_error: 0.4192 - val_loss: 0.3762 - val_mean_squared_error: 0.3762\n",
      "Epoch 32/2000\n",
      " - 11s - loss: 0.4175 - mean_squared_error: 0.4175 - val_loss: 0.3758 - val_mean_squared_error: 0.3758\n",
      "Epoch 33/2000\n",
      " - 11s - loss: 0.4154 - mean_squared_error: 0.4154 - val_loss: 0.3759 - val_mean_squared_error: 0.3759\n",
      "Epoch 34/2000\n",
      " - 11s - loss: 0.4135 - mean_squared_error: 0.4135 - val_loss: 0.3758 - val_mean_squared_error: 0.3758\n",
      "Epoch 35/2000\n",
      " - 11s - loss: 0.4122 - mean_squared_error: 0.4122 - val_loss: 0.3758 - val_mean_squared_error: 0.3758\n",
      "Epoch 36/2000\n",
      " - 11s - loss: 0.4106 - mean_squared_error: 0.4106 - val_loss: 0.3760 - val_mean_squared_error: 0.3760\n",
      "Epoch 37/2000\n",
      " - 10s - loss: 0.4083 - mean_squared_error: 0.4083 - val_loss: 0.3752 - val_mean_squared_error: 0.3752\n",
      "Epoch 38/2000\n",
      " - 11s - loss: 0.4067 - mean_squared_error: 0.4067 - val_loss: 0.3761 - val_mean_squared_error: 0.3761\n",
      "Epoch 39/2000\n",
      " - 11s - loss: 0.4054 - mean_squared_error: 0.4054 - val_loss: 0.3753 - val_mean_squared_error: 0.3753\n",
      "Epoch 40/2000\n",
      " - 11s - loss: 0.4032 - mean_squared_error: 0.4032 - val_loss: 0.3755 - val_mean_squared_error: 0.3755\n",
      "Epoch 41/2000\n",
      " - 11s - loss: 0.4022 - mean_squared_error: 0.4022 - val_loss: 0.3753 - val_mean_squared_error: 0.3753\n",
      "Epoch 42/2000\n",
      " - 11s - loss: 0.4004 - mean_squared_error: 0.4004 - val_loss: 0.3751 - val_mean_squared_error: 0.3751\n",
      "Epoch 43/2000\n",
      " - 10s - loss: 0.4002 - mean_squared_error: 0.4002 - val_loss: 0.3753 - val_mean_squared_error: 0.3753\n",
      "Epoch 44/2000\n",
      " - 10s - loss: 0.3978 - mean_squared_error: 0.3978 - val_loss: 0.3751 - val_mean_squared_error: 0.3751\n",
      "Epoch 45/2000\n",
      " - 10s - loss: 0.3972 - mean_squared_error: 0.3972 - val_loss: 0.3749 - val_mean_squared_error: 0.3749\n",
      "Epoch 46/2000\n",
      " - 10s - loss: 0.3952 - mean_squared_error: 0.3952 - val_loss: 0.3748 - val_mean_squared_error: 0.3748\n",
      "Epoch 47/2000\n",
      " - 11s - loss: 0.3947 - mean_squared_error: 0.3947 - val_loss: 0.3750 - val_mean_squared_error: 0.3750\n",
      "Epoch 48/2000\n",
      " - 10s - loss: 0.3929 - mean_squared_error: 0.3929 - val_loss: 0.3749 - val_mean_squared_error: 0.3749\n",
      "Epoch 49/2000\n",
      " - 10s - loss: 0.3923 - mean_squared_error: 0.3923 - val_loss: 0.3755 - val_mean_squared_error: 0.3755\n",
      "Epoch 50/2000\n",
      " - 10s - loss: 0.3910 - mean_squared_error: 0.3910 - val_loss: 0.3750 - val_mean_squared_error: 0.3750\n",
      "Epoch 51/2000\n",
      " - 10s - loss: 0.3898 - mean_squared_error: 0.3898 - val_loss: 0.3745 - val_mean_squared_error: 0.3745\n",
      "Epoch 52/2000\n",
      " - 10s - loss: 0.3886 - mean_squared_error: 0.3886 - val_loss: 0.3748 - val_mean_squared_error: 0.3748\n",
      "Epoch 53/2000\n",
      " - 10s - loss: 0.3870 - mean_squared_error: 0.3870 - val_loss: 0.3746 - val_mean_squared_error: 0.3746\n",
      "Epoch 54/2000\n",
      " - 10s - loss: 0.3870 - mean_squared_error: 0.3870 - val_loss: 0.3748 - val_mean_squared_error: 0.3748\n",
      "Epoch 55/2000\n",
      " - 10s - loss: 0.3859 - mean_squared_error: 0.3859 - val_loss: 0.3747 - val_mean_squared_error: 0.3747\n",
      "Epoch 56/2000\n",
      " - 10s - loss: 0.3851 - mean_squared_error: 0.3851 - val_loss: 0.3743 - val_mean_squared_error: 0.3743\n",
      "Epoch 57/2000\n",
      " - 10s - loss: 0.3840 - mean_squared_error: 0.3840 - val_loss: 0.3745 - val_mean_squared_error: 0.3745\n",
      "Epoch 58/2000\n",
      " - 10s - loss: 0.3831 - mean_squared_error: 0.3831 - val_loss: 0.3743 - val_mean_squared_error: 0.3743\n",
      "Epoch 59/2000\n",
      " - 10s - loss: 0.3824 - mean_squared_error: 0.3824 - val_loss: 0.3749 - val_mean_squared_error: 0.3749\n",
      "Epoch 60/2000\n",
      " - 10s - loss: 0.3814 - mean_squared_error: 0.3814 - val_loss: 0.3740 - val_mean_squared_error: 0.3740\n",
      "Epoch 61/2000\n",
      " - 10s - loss: 0.3815 - mean_squared_error: 0.3815 - val_loss: 0.3747 - val_mean_squared_error: 0.3747\n",
      "Epoch 62/2000\n",
      " - 10s - loss: 0.3802 - mean_squared_error: 0.3802 - val_loss: 0.3759 - val_mean_squared_error: 0.3759\n",
      "Epoch 63/2000\n",
      " - 10s - loss: 0.3794 - mean_squared_error: 0.3794 - val_loss: 0.3748 - val_mean_squared_error: 0.3748\n",
      "Epoch 64/2000\n",
      " - 10s - loss: 0.3791 - mean_squared_error: 0.3791 - val_loss: 0.3744 - val_mean_squared_error: 0.3744\n",
      "Epoch 65/2000\n",
      " - 10s - loss: 0.3785 - mean_squared_error: 0.3785 - val_loss: 0.3752 - val_mean_squared_error: 0.3752\n",
      "Epoch 66/2000\n",
      " - 11s - loss: 0.3775 - mean_squared_error: 0.3775 - val_loss: 0.3752 - val_mean_squared_error: 0.3752\n",
      "Epoch 67/2000\n",
      " - 11s - loss: 0.3770 - mean_squared_error: 0.3770 - val_loss: 0.3742 - val_mean_squared_error: 0.3742\n",
      "\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 68/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 12s - loss: 0.3764 - mean_squared_error: 0.3764 - val_loss: 0.3749 - val_mean_squared_error: 0.3749\n",
      "Epoch 69/2000\n",
      " - 11s - loss: 0.3758 - mean_squared_error: 0.3758 - val_loss: 0.3755 - val_mean_squared_error: 0.3755\n",
      "Epoch 70/2000\n",
      " - 11s - loss: 0.3754 - mean_squared_error: 0.3754 - val_loss: 0.3754 - val_mean_squared_error: 0.3754\n",
      "==================================================\n",
      "Step 14\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 194s - loss: 1.3194 - mean_squared_error: 1.3194 - val_loss: 0.8433 - val_mean_squared_error: 0.8433\n",
      "Epoch 2/2000\n",
      " - 11s - loss: 0.7563 - mean_squared_error: 0.7563 - val_loss: 0.6114 - val_mean_squared_error: 0.6114\n",
      "Epoch 3/2000\n",
      " - 11s - loss: 0.6273 - mean_squared_error: 0.6273 - val_loss: 0.5164 - val_mean_squared_error: 0.5164\n",
      "Epoch 4/2000\n",
      " - 11s - loss: 0.5742 - mean_squared_error: 0.5742 - val_loss: 0.4449 - val_mean_squared_error: 0.4449\n",
      "Epoch 5/2000\n",
      " - 10s - loss: 0.5453 - mean_squared_error: 0.5453 - val_loss: 0.4123 - val_mean_squared_error: 0.4123\n",
      "Epoch 6/2000\n",
      " - 11s - loss: 0.5232 - mean_squared_error: 0.5232 - val_loss: 0.3958 - val_mean_squared_error: 0.3958\n",
      "Epoch 7/2000\n",
      " - 11s - loss: 0.5111 - mean_squared_error: 0.5111 - val_loss: 0.3876 - val_mean_squared_error: 0.3876\n",
      "Epoch 8/2000\n",
      " - 10s - loss: 0.4978 - mean_squared_error: 0.4978 - val_loss: 0.3815 - val_mean_squared_error: 0.3815\n",
      "Epoch 9/2000\n",
      " - 11s - loss: 0.4878 - mean_squared_error: 0.4878 - val_loss: 0.3763 - val_mean_squared_error: 0.3763\n",
      "Epoch 10/2000\n",
      " - 10s - loss: 0.4796 - mean_squared_error: 0.4796 - val_loss: 0.3736 - val_mean_squared_error: 0.3736\n",
      "Epoch 11/2000\n",
      " - 11s - loss: 0.4734 - mean_squared_error: 0.4734 - val_loss: 0.3716 - val_mean_squared_error: 0.3716\n",
      "Epoch 12/2000\n",
      " - 10s - loss: 0.4666 - mean_squared_error: 0.4666 - val_loss: 0.3699 - val_mean_squared_error: 0.3699\n",
      "Epoch 13/2000\n",
      " - 11s - loss: 0.4612 - mean_squared_error: 0.4612 - val_loss: 0.3691 - val_mean_squared_error: 0.3691\n",
      "Epoch 14/2000\n",
      " - 11s - loss: 0.4561 - mean_squared_error: 0.4561 - val_loss: 0.3682 - val_mean_squared_error: 0.3682\n",
      "Epoch 15/2000\n",
      " - 10s - loss: 0.4515 - mean_squared_error: 0.4515 - val_loss: 0.3673 - val_mean_squared_error: 0.3673\n",
      "Epoch 16/2000\n",
      " - 10s - loss: 0.4477 - mean_squared_error: 0.4477 - val_loss: 0.3666 - val_mean_squared_error: 0.3666\n",
      "Epoch 17/2000\n",
      " - 10s - loss: 0.4443 - mean_squared_error: 0.4443 - val_loss: 0.3656 - val_mean_squared_error: 0.3656\n",
      "Epoch 18/2000\n",
      " - 10s - loss: 0.4405 - mean_squared_error: 0.4405 - val_loss: 0.3656 - val_mean_squared_error: 0.3656\n",
      "Epoch 19/2000\n",
      " - 10s - loss: 0.4371 - mean_squared_error: 0.4371 - val_loss: 0.3651 - val_mean_squared_error: 0.3651\n",
      "Epoch 20/2000\n",
      " - 10s - loss: 0.4338 - mean_squared_error: 0.4338 - val_loss: 0.3647 - val_mean_squared_error: 0.3647\n",
      "Epoch 21/2000\n",
      " - 11s - loss: 0.4301 - mean_squared_error: 0.4301 - val_loss: 0.3644 - val_mean_squared_error: 0.3644\n",
      "Epoch 22/2000\n",
      " - 10s - loss: 0.4280 - mean_squared_error: 0.4280 - val_loss: 0.3639 - val_mean_squared_error: 0.3639\n",
      "Epoch 23/2000\n",
      " - 11s - loss: 0.4247 - mean_squared_error: 0.4247 - val_loss: 0.3638 - val_mean_squared_error: 0.3638\n",
      "Epoch 24/2000\n",
      " - 11s - loss: 0.4219 - mean_squared_error: 0.4219 - val_loss: 0.3632 - val_mean_squared_error: 0.3632\n",
      "Epoch 25/2000\n",
      " - 10s - loss: 0.4191 - mean_squared_error: 0.4191 - val_loss: 0.3630 - val_mean_squared_error: 0.3630\n",
      "Epoch 26/2000\n",
      " - 10s - loss: 0.4174 - mean_squared_error: 0.4174 - val_loss: 0.3634 - val_mean_squared_error: 0.3634\n",
      "Epoch 27/2000\n",
      " - 10s - loss: 0.4139 - mean_squared_error: 0.4139 - val_loss: 0.3629 - val_mean_squared_error: 0.3629\n",
      "Epoch 28/2000\n",
      " - 10s - loss: 0.4116 - mean_squared_error: 0.4116 - val_loss: 0.3627 - val_mean_squared_error: 0.3627\n",
      "Epoch 29/2000\n",
      " - 11s - loss: 0.4101 - mean_squared_error: 0.4101 - val_loss: 0.3627 - val_mean_squared_error: 0.3627\n",
      "Epoch 30/2000\n",
      " - 10s - loss: 0.4069 - mean_squared_error: 0.4069 - val_loss: 0.3623 - val_mean_squared_error: 0.3623\n",
      "Epoch 31/2000\n",
      " - 11s - loss: 0.4045 - mean_squared_error: 0.4045 - val_loss: 0.3624 - val_mean_squared_error: 0.3624\n",
      "Epoch 32/2000\n",
      " - 10s - loss: 0.4021 - mean_squared_error: 0.4021 - val_loss: 0.3623 - val_mean_squared_error: 0.3623\n",
      "Epoch 33/2000\n",
      " - 11s - loss: 0.4010 - mean_squared_error: 0.4010 - val_loss: 0.3625 - val_mean_squared_error: 0.3625\n",
      "Epoch 34/2000\n",
      " - 10s - loss: 0.3984 - mean_squared_error: 0.3984 - val_loss: 0.3616 - val_mean_squared_error: 0.3616\n",
      "Epoch 35/2000\n",
      " - 11s - loss: 0.3969 - mean_squared_error: 0.3969 - val_loss: 0.3623 - val_mean_squared_error: 0.3623\n",
      "Epoch 36/2000\n",
      " - 10s - loss: 0.3959 - mean_squared_error: 0.3959 - val_loss: 0.3614 - val_mean_squared_error: 0.3614\n",
      "Epoch 37/2000\n",
      " - 10s - loss: 0.3936 - mean_squared_error: 0.3936 - val_loss: 0.3617 - val_mean_squared_error: 0.3617\n",
      "Epoch 38/2000\n",
      " - 10s - loss: 0.3919 - mean_squared_error: 0.3919 - val_loss: 0.3619 - val_mean_squared_error: 0.3619\n",
      "Epoch 39/2000\n",
      " - 11s - loss: 0.3901 - mean_squared_error: 0.3901 - val_loss: 0.3618 - val_mean_squared_error: 0.3618\n",
      "Epoch 40/2000\n",
      " - 11s - loss: 0.3881 - mean_squared_error: 0.3881 - val_loss: 0.3617 - val_mean_squared_error: 0.3617\n",
      "Epoch 41/2000\n",
      " - 11s - loss: 0.3873 - mean_squared_error: 0.3873 - val_loss: 0.3613 - val_mean_squared_error: 0.3613\n",
      "Epoch 42/2000\n",
      " - 10s - loss: 0.3855 - mean_squared_error: 0.3855 - val_loss: 0.3618 - val_mean_squared_error: 0.3618\n",
      "Epoch 43/2000\n",
      " - 10s - loss: 0.3845 - mean_squared_error: 0.3845 - val_loss: 0.3613 - val_mean_squared_error: 0.3613\n",
      "Epoch 44/2000\n",
      " - 10s - loss: 0.3833 - mean_squared_error: 0.3833 - val_loss: 0.3613 - val_mean_squared_error: 0.3613\n",
      "Epoch 45/2000\n",
      " - 10s - loss: 0.3815 - mean_squared_error: 0.3815 - val_loss: 0.3620 - val_mean_squared_error: 0.3620\n",
      "Epoch 46/2000\n",
      " - 11s - loss: 0.3804 - mean_squared_error: 0.3804 - val_loss: 0.3618 - val_mean_squared_error: 0.3618\n",
      "Epoch 47/2000\n",
      " - 10s - loss: 0.3796 - mean_squared_error: 0.3796 - val_loss: 0.3619 - val_mean_squared_error: 0.3619\n",
      "Epoch 48/2000\n",
      " - 10s - loss: 0.3783 - mean_squared_error: 0.3783 - val_loss: 0.3611 - val_mean_squared_error: 0.3611\n",
      "Epoch 49/2000\n",
      " - 11s - loss: 0.3776 - mean_squared_error: 0.3776 - val_loss: 0.3609 - val_mean_squared_error: 0.3609\n",
      "Epoch 50/2000\n",
      " - 10s - loss: 0.3768 - mean_squared_error: 0.3768 - val_loss: 0.3614 - val_mean_squared_error: 0.3614\n",
      "Epoch 51/2000\n",
      " - 11s - loss: 0.3756 - mean_squared_error: 0.3756 - val_loss: 0.3620 - val_mean_squared_error: 0.3620\n",
      "Epoch 52/2000\n",
      " - 11s - loss: 0.3743 - mean_squared_error: 0.3743 - val_loss: 0.3616 - val_mean_squared_error: 0.3616\n",
      "Epoch 53/2000\n",
      " - 10s - loss: 0.3737 - mean_squared_error: 0.3737 - val_loss: 0.3618 - val_mean_squared_error: 0.3618\n",
      "Epoch 54/2000\n",
      " - 11s - loss: 0.3728 - mean_squared_error: 0.3728 - val_loss: 0.3615 - val_mean_squared_error: 0.3615\n",
      "Epoch 55/2000\n",
      " - 11s - loss: 0.3720 - mean_squared_error: 0.3720 - val_loss: 0.3606 - val_mean_squared_error: 0.3606\n",
      "Epoch 56/2000\n",
      " - 10s - loss: 0.3706 - mean_squared_error: 0.3706 - val_loss: 0.3632 - val_mean_squared_error: 0.3632\n",
      "Epoch 57/2000\n",
      " - 11s - loss: 0.3700 - mean_squared_error: 0.3700 - val_loss: 0.3618 - val_mean_squared_error: 0.3618\n",
      "Epoch 58/2000\n",
      " - 10s - loss: 0.3694 - mean_squared_error: 0.3694 - val_loss: 0.3613 - val_mean_squared_error: 0.3613\n",
      "Epoch 59/2000\n",
      " - 10s - loss: 0.3685 - mean_squared_error: 0.3685 - val_loss: 0.3614 - val_mean_squared_error: 0.3614\n",
      "Epoch 60/2000\n",
      " - 10s - loss: 0.3679 - mean_squared_error: 0.3679 - val_loss: 0.3611 - val_mean_squared_error: 0.3611\n",
      "Epoch 61/2000\n",
      " - 10s - loss: 0.3672 - mean_squared_error: 0.3672 - val_loss: 0.3622 - val_mean_squared_error: 0.3622\n",
      "Epoch 62/2000\n",
      " - 10s - loss: 0.3667 - mean_squared_error: 0.3667 - val_loss: 0.3616 - val_mean_squared_error: 0.3616\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 63/2000\n",
      " - 12s - loss: 0.3655 - mean_squared_error: 0.3655 - val_loss: 0.3617 - val_mean_squared_error: 0.3617\n",
      "Epoch 64/2000\n",
      " - 11s - loss: 0.3655 - mean_squared_error: 0.3655 - val_loss: 0.3617 - val_mean_squared_error: 0.3617\n",
      "Epoch 65/2000\n",
      " - 11s - loss: 0.3655 - mean_squared_error: 0.3655 - val_loss: 0.3619 - val_mean_squared_error: 0.3619\n",
      "==================================================\n",
      "Step 15\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 187s - loss: 1.8575 - mean_squared_error: 1.8575 - val_loss: 0.9296 - val_mean_squared_error: 0.9296\n",
      "Epoch 2/2000\n",
      " - 10s - loss: 0.9970 - mean_squared_error: 0.9970 - val_loss: 0.6549 - val_mean_squared_error: 0.6549\n",
      "Epoch 3/2000\n",
      " - 11s - loss: 0.7966 - mean_squared_error: 0.7966 - val_loss: 0.5375 - val_mean_squared_error: 0.5375\n",
      "Epoch 4/2000\n",
      " - 11s - loss: 0.7003 - mean_squared_error: 0.7003 - val_loss: 0.4532 - val_mean_squared_error: 0.4532\n",
      "Epoch 5/2000\n",
      " - 11s - loss: 0.6466 - mean_squared_error: 0.6466 - val_loss: 0.4187 - val_mean_squared_error: 0.4187\n",
      "Epoch 6/2000\n",
      " - 11s - loss: 0.6131 - mean_squared_error: 0.6131 - val_loss: 0.4002 - val_mean_squared_error: 0.4002\n",
      "Epoch 7/2000\n",
      " - 11s - loss: 0.5883 - mean_squared_error: 0.5883 - val_loss: 0.3897 - val_mean_squared_error: 0.3897\n",
      "Epoch 8/2000\n",
      " - 10s - loss: 0.5674 - mean_squared_error: 0.5674 - val_loss: 0.3831 - val_mean_squared_error: 0.3831\n",
      "Epoch 9/2000\n",
      " - 12s - loss: 0.5515 - mean_squared_error: 0.5515 - val_loss: 0.3781 - val_mean_squared_error: 0.3781\n",
      "Epoch 10/2000\n",
      " - 11s - loss: 0.5387 - mean_squared_error: 0.5387 - val_loss: 0.3744 - val_mean_squared_error: 0.3744\n",
      "Epoch 11/2000\n",
      " - 11s - loss: 0.5290 - mean_squared_error: 0.5290 - val_loss: 0.3706 - val_mean_squared_error: 0.3706\n",
      "Epoch 12/2000\n",
      " - 11s - loss: 0.5197 - mean_squared_error: 0.5197 - val_loss: 0.3674 - val_mean_squared_error: 0.3674\n",
      "Epoch 13/2000\n",
      " - 11s - loss: 0.5102 - mean_squared_error: 0.5102 - val_loss: 0.3655 - val_mean_squared_error: 0.3655\n",
      "Epoch 14/2000\n",
      " - 11s - loss: 0.5021 - mean_squared_error: 0.5021 - val_loss: 0.3639 - val_mean_squared_error: 0.3639\n",
      "Epoch 15/2000\n",
      " - 11s - loss: 0.4962 - mean_squared_error: 0.4962 - val_loss: 0.3624 - val_mean_squared_error: 0.3624\n",
      "Epoch 16/2000\n",
      " - 11s - loss: 0.4902 - mean_squared_error: 0.4902 - val_loss: 0.3614 - val_mean_squared_error: 0.3614\n",
      "Epoch 17/2000\n",
      " - 10s - loss: 0.4830 - mean_squared_error: 0.4830 - val_loss: 0.3598 - val_mean_squared_error: 0.3598\n",
      "Epoch 18/2000\n",
      " - 11s - loss: 0.4780 - mean_squared_error: 0.4780 - val_loss: 0.3586 - val_mean_squared_error: 0.3586\n",
      "Epoch 19/2000\n",
      " - 10s - loss: 0.4720 - mean_squared_error: 0.4720 - val_loss: 0.3580 - val_mean_squared_error: 0.3580\n",
      "Epoch 20/2000\n",
      " - 11s - loss: 0.4665 - mean_squared_error: 0.4665 - val_loss: 0.3571 - val_mean_squared_error: 0.3571\n",
      "Epoch 21/2000\n",
      " - 11s - loss: 0.4620 - mean_squared_error: 0.4620 - val_loss: 0.3563 - val_mean_squared_error: 0.3563\n",
      "Epoch 22/2000\n",
      " - 10s - loss: 0.4580 - mean_squared_error: 0.4580 - val_loss: 0.3554 - val_mean_squared_error: 0.3554\n",
      "Epoch 23/2000\n",
      " - 11s - loss: 0.4541 - mean_squared_error: 0.4541 - val_loss: 0.3544 - val_mean_squared_error: 0.3544\n",
      "Epoch 24/2000\n",
      " - 11s - loss: 0.4495 - mean_squared_error: 0.4495 - val_loss: 0.3542 - val_mean_squared_error: 0.3542\n",
      "Epoch 25/2000\n",
      " - 11s - loss: 0.4452 - mean_squared_error: 0.4452 - val_loss: 0.3531 - val_mean_squared_error: 0.3531\n",
      "Epoch 26/2000\n",
      " - 11s - loss: 0.4405 - mean_squared_error: 0.4405 - val_loss: 0.3530 - val_mean_squared_error: 0.3530\n",
      "Epoch 27/2000\n",
      " - 11s - loss: 0.4368 - mean_squared_error: 0.4368 - val_loss: 0.3524 - val_mean_squared_error: 0.3524\n",
      "Epoch 28/2000\n",
      " - 11s - loss: 0.4340 - mean_squared_error: 0.4340 - val_loss: 0.3516 - val_mean_squared_error: 0.3516\n",
      "Epoch 29/2000\n",
      " - 11s - loss: 0.4302 - mean_squared_error: 0.4302 - val_loss: 0.3513 - val_mean_squared_error: 0.3513\n",
      "Epoch 30/2000\n",
      " - 11s - loss: 0.4252 - mean_squared_error: 0.4252 - val_loss: 0.3509 - val_mean_squared_error: 0.3509\n",
      "Epoch 31/2000\n",
      " - 11s - loss: 0.4223 - mean_squared_error: 0.4223 - val_loss: 0.3507 - val_mean_squared_error: 0.3507\n",
      "Epoch 32/2000\n",
      " - 10s - loss: 0.4205 - mean_squared_error: 0.4205 - val_loss: 0.3501 - val_mean_squared_error: 0.3501\n",
      "Epoch 33/2000\n",
      " - 10s - loss: 0.4168 - mean_squared_error: 0.4168 - val_loss: 0.3495 - val_mean_squared_error: 0.3495\n",
      "Epoch 34/2000\n",
      " - 10s - loss: 0.4137 - mean_squared_error: 0.4137 - val_loss: 0.3490 - val_mean_squared_error: 0.3490\n",
      "Epoch 35/2000\n",
      " - 10s - loss: 0.4109 - mean_squared_error: 0.4109 - val_loss: 0.3493 - val_mean_squared_error: 0.3493\n",
      "Epoch 36/2000\n",
      " - 10s - loss: 0.4082 - mean_squared_error: 0.4082 - val_loss: 0.3492 - val_mean_squared_error: 0.3492\n",
      "Epoch 37/2000\n",
      " - 11s - loss: 0.4050 - mean_squared_error: 0.4050 - val_loss: 0.3494 - val_mean_squared_error: 0.3494\n",
      "Epoch 38/2000\n",
      " - 11s - loss: 0.4033 - mean_squared_error: 0.4033 - val_loss: 0.3490 - val_mean_squared_error: 0.3490\n",
      "Epoch 39/2000\n",
      " - 10s - loss: 0.4013 - mean_squared_error: 0.4013 - val_loss: 0.3486 - val_mean_squared_error: 0.3486\n",
      "Epoch 40/2000\n",
      " - 10s - loss: 0.3967 - mean_squared_error: 0.3967 - val_loss: 0.3482 - val_mean_squared_error: 0.3482\n",
      "Epoch 41/2000\n",
      " - 11s - loss: 0.3956 - mean_squared_error: 0.3956 - val_loss: 0.3475 - val_mean_squared_error: 0.3475\n",
      "Epoch 42/2000\n",
      " - 11s - loss: 0.3938 - mean_squared_error: 0.3938 - val_loss: 0.3475 - val_mean_squared_error: 0.3475\n",
      "Epoch 43/2000\n",
      " - 10s - loss: 0.3910 - mean_squared_error: 0.3910 - val_loss: 0.3482 - val_mean_squared_error: 0.3482\n",
      "Epoch 44/2000\n",
      " - 11s - loss: 0.3895 - mean_squared_error: 0.3895 - val_loss: 0.3473 - val_mean_squared_error: 0.3473\n",
      "Epoch 45/2000\n",
      " - 10s - loss: 0.3868 - mean_squared_error: 0.3868 - val_loss: 0.3478 - val_mean_squared_error: 0.3478\n",
      "Epoch 46/2000\n",
      " - 11s - loss: 0.3846 - mean_squared_error: 0.3846 - val_loss: 0.3475 - val_mean_squared_error: 0.3475\n",
      "Epoch 47/2000\n",
      " - 10s - loss: 0.3828 - mean_squared_error: 0.3828 - val_loss: 0.3470 - val_mean_squared_error: 0.3470\n",
      "Epoch 48/2000\n",
      " - 10s - loss: 0.3812 - mean_squared_error: 0.3812 - val_loss: 0.3467 - val_mean_squared_error: 0.3467\n",
      "Epoch 49/2000\n",
      " - 11s - loss: 0.3789 - mean_squared_error: 0.3789 - val_loss: 0.3467 - val_mean_squared_error: 0.3467\n",
      "Epoch 50/2000\n",
      " - 10s - loss: 0.3775 - mean_squared_error: 0.3775 - val_loss: 0.3464 - val_mean_squared_error: 0.3464\n",
      "Epoch 51/2000\n",
      " - 11s - loss: 0.3764 - mean_squared_error: 0.3764 - val_loss: 0.3477 - val_mean_squared_error: 0.3477\n",
      "Epoch 52/2000\n",
      " - 10s - loss: 0.3752 - mean_squared_error: 0.3752 - val_loss: 0.3471 - val_mean_squared_error: 0.3471\n",
      "Epoch 53/2000\n",
      " - 10s - loss: 0.3730 - mean_squared_error: 0.3730 - val_loss: 0.3462 - val_mean_squared_error: 0.3462\n",
      "Epoch 54/2000\n",
      " - 11s - loss: 0.3725 - mean_squared_error: 0.3725 - val_loss: 0.3459 - val_mean_squared_error: 0.3459\n",
      "Epoch 55/2000\n",
      " - 10s - loss: 0.3708 - mean_squared_error: 0.3708 - val_loss: 0.3463 - val_mean_squared_error: 0.3463\n",
      "Epoch 56/2000\n",
      " - 10s - loss: 0.3696 - mean_squared_error: 0.3696 - val_loss: 0.3463 - val_mean_squared_error: 0.3463\n",
      "Epoch 57/2000\n",
      " - 10s - loss: 0.3679 - mean_squared_error: 0.3679 - val_loss: 0.3459 - val_mean_squared_error: 0.3459\n",
      "Epoch 58/2000\n",
      " - 10s - loss: 0.3669 - mean_squared_error: 0.3669 - val_loss: 0.3463 - val_mean_squared_error: 0.3463\n",
      "Epoch 59/2000\n",
      " - 11s - loss: 0.3651 - mean_squared_error: 0.3651 - val_loss: 0.3467 - val_mean_squared_error: 0.3467\n",
      "Epoch 60/2000\n",
      " - 11s - loss: 0.3644 - mean_squared_error: 0.3644 - val_loss: 0.3458 - val_mean_squared_error: 0.3458\n",
      "Epoch 61/2000\n",
      " - 11s - loss: 0.3635 - mean_squared_error: 0.3635 - val_loss: 0.3460 - val_mean_squared_error: 0.3460\n",
      "Epoch 62/2000\n",
      " - 10s - loss: 0.3628 - mean_squared_error: 0.3628 - val_loss: 0.3461 - val_mean_squared_error: 0.3461\n",
      "Epoch 63/2000\n",
      " - 10s - loss: 0.3614 - mean_squared_error: 0.3614 - val_loss: 0.3461 - val_mean_squared_error: 0.3461\n",
      "Epoch 64/2000\n",
      " - 11s - loss: 0.3602 - mean_squared_error: 0.3602 - val_loss: 0.3455 - val_mean_squared_error: 0.3455\n",
      "Epoch 65/2000\n",
      " - 11s - loss: 0.3596 - mean_squared_error: 0.3596 - val_loss: 0.3460 - val_mean_squared_error: 0.3460\n",
      "Epoch 66/2000\n",
      " - 11s - loss: 0.3588 - mean_squared_error: 0.3588 - val_loss: 0.3464 - val_mean_squared_error: 0.3464\n",
      "Epoch 67/2000\n",
      " - 10s - loss: 0.3576 - mean_squared_error: 0.3576 - val_loss: 0.3467 - val_mean_squared_error: 0.3467\n",
      "Epoch 68/2000\n",
      " - 11s - loss: 0.3571 - mean_squared_error: 0.3571 - val_loss: 0.3462 - val_mean_squared_error: 0.3462\n",
      "Epoch 69/2000\n",
      " - 10s - loss: 0.3563 - mean_squared_error: 0.3563 - val_loss: 0.3458 - val_mean_squared_error: 0.3458\n",
      "Epoch 70/2000\n",
      " - 11s - loss: 0.3553 - mean_squared_error: 0.3553 - val_loss: 0.3457 - val_mean_squared_error: 0.3457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/2000\n",
      " - 11s - loss: 0.3545 - mean_squared_error: 0.3545 - val_loss: 0.3457 - val_mean_squared_error: 0.3457\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 72/2000\n",
      " - 12s - loss: 0.3540 - mean_squared_error: 0.3540 - val_loss: 0.3457 - val_mean_squared_error: 0.3457\n",
      "Epoch 73/2000\n",
      " - 11s - loss: 0.3534 - mean_squared_error: 0.3534 - val_loss: 0.3462 - val_mean_squared_error: 0.3462\n",
      "Epoch 74/2000\n",
      " - 11s - loss: 0.3533 - mean_squared_error: 0.3533 - val_loss: 0.3463 - val_mean_squared_error: 0.3463\n",
      "==================================================\n",
      "Step 16\n",
      "==================================================\n",
      "Train on 670060 samples, validate on 167515 samples\n",
      "Epoch 1/2000\n",
      " - 214s - loss: 1.6049 - mean_squared_error: 1.6049 - val_loss: 1.0745 - val_mean_squared_error: 1.0745\n",
      "Epoch 2/2000\n",
      " - 11s - loss: 0.8621 - mean_squared_error: 0.8621 - val_loss: 0.7258 - val_mean_squared_error: 0.7258\n",
      "Epoch 3/2000\n",
      " - 11s - loss: 0.6873 - mean_squared_error: 0.6873 - val_loss: 0.5603 - val_mean_squared_error: 0.5603\n",
      "Epoch 4/2000\n",
      " - 10s - loss: 0.6141 - mean_squared_error: 0.6141 - val_loss: 0.4793 - val_mean_squared_error: 0.4793\n",
      "Epoch 5/2000\n",
      " - 11s - loss: 0.5749 - mean_squared_error: 0.5749 - val_loss: 0.4416 - val_mean_squared_error: 0.4416\n",
      "Epoch 6/2000\n",
      " - 11s - loss: 0.5487 - mean_squared_error: 0.5487 - val_loss: 0.4182 - val_mean_squared_error: 0.4182\n",
      "Epoch 7/2000\n",
      " - 10s - loss: 0.5287 - mean_squared_error: 0.5287 - val_loss: 0.4047 - val_mean_squared_error: 0.4047\n",
      "Epoch 8/2000\n",
      " - 11s - loss: 0.5119 - mean_squared_error: 0.5119 - val_loss: 0.3974 - val_mean_squared_error: 0.3974\n",
      "Epoch 9/2000\n",
      " - 10s - loss: 0.5025 - mean_squared_error: 0.5025 - val_loss: 0.3924 - val_mean_squared_error: 0.3924\n",
      "Epoch 10/2000\n",
      " - 10s - loss: 0.4948 - mean_squared_error: 0.4948 - val_loss: 0.3891 - val_mean_squared_error: 0.3891\n",
      "Epoch 11/2000\n",
      " - 10s - loss: 0.4852 - mean_squared_error: 0.4852 - val_loss: 0.3871 - val_mean_squared_error: 0.3871\n",
      "Epoch 12/2000\n",
      " - 10s - loss: 0.4797 - mean_squared_error: 0.4797 - val_loss: 0.3853 - val_mean_squared_error: 0.3853\n",
      "Epoch 13/2000\n",
      " - 11s - loss: 0.4742 - mean_squared_error: 0.4742 - val_loss: 0.3838 - val_mean_squared_error: 0.3838\n",
      "Epoch 14/2000\n",
      " - 11s - loss: 0.4679 - mean_squared_error: 0.4679 - val_loss: 0.3829 - val_mean_squared_error: 0.3829\n",
      "Epoch 15/2000\n",
      " - 11s - loss: 0.4633 - mean_squared_error: 0.4633 - val_loss: 0.3813 - val_mean_squared_error: 0.3813\n",
      "Epoch 16/2000\n",
      " - 11s - loss: 0.4589 - mean_squared_error: 0.4589 - val_loss: 0.3807 - val_mean_squared_error: 0.3807\n",
      "Epoch 17/2000\n",
      " - 11s - loss: 0.4561 - mean_squared_error: 0.4561 - val_loss: 0.3793 - val_mean_squared_error: 0.3793\n",
      "Epoch 18/2000\n",
      " - 11s - loss: 0.4515 - mean_squared_error: 0.4515 - val_loss: 0.3787 - val_mean_squared_error: 0.3787\n",
      "Epoch 19/2000\n",
      " - 11s - loss: 0.4482 - mean_squared_error: 0.4482 - val_loss: 0.3786 - val_mean_squared_error: 0.3786\n",
      "Epoch 20/2000\n",
      " - 11s - loss: 0.4438 - mean_squared_error: 0.4438 - val_loss: 0.3780 - val_mean_squared_error: 0.3780\n",
      "Epoch 21/2000\n",
      " - 11s - loss: 0.4409 - mean_squared_error: 0.4409 - val_loss: 0.3768 - val_mean_squared_error: 0.3768\n",
      "Epoch 22/2000\n",
      " - 10s - loss: 0.4369 - mean_squared_error: 0.4369 - val_loss: 0.3765 - val_mean_squared_error: 0.3765\n",
      "Epoch 23/2000\n",
      " - 11s - loss: 0.4351 - mean_squared_error: 0.4351 - val_loss: 0.3760 - val_mean_squared_error: 0.3760\n",
      "Epoch 24/2000\n",
      " - 11s - loss: 0.4321 - mean_squared_error: 0.4321 - val_loss: 0.3756 - val_mean_squared_error: 0.3756\n",
      "Epoch 25/2000\n",
      " - 11s - loss: 0.4291 - mean_squared_error: 0.4291 - val_loss: 0.3756 - val_mean_squared_error: 0.3756\n",
      "Epoch 26/2000\n",
      " - 11s - loss: 0.4253 - mean_squared_error: 0.4253 - val_loss: 0.3754 - val_mean_squared_error: 0.3754\n",
      "Epoch 27/2000\n",
      " - 11s - loss: 0.4228 - mean_squared_error: 0.4228 - val_loss: 0.3749 - val_mean_squared_error: 0.3749\n",
      "Epoch 28/2000\n",
      " - 11s - loss: 0.4210 - mean_squared_error: 0.4210 - val_loss: 0.3748 - val_mean_squared_error: 0.3748\n",
      "Epoch 29/2000\n",
      " - 11s - loss: 0.4180 - mean_squared_error: 0.4180 - val_loss: 0.3743 - val_mean_squared_error: 0.3743\n",
      "Epoch 30/2000\n",
      " - 11s - loss: 0.4156 - mean_squared_error: 0.4156 - val_loss: 0.3744 - val_mean_squared_error: 0.3744\n",
      "Epoch 31/2000\n",
      " - 11s - loss: 0.4138 - mean_squared_error: 0.4138 - val_loss: 0.3736 - val_mean_squared_error: 0.3736\n",
      "Epoch 32/2000\n",
      " - 11s - loss: 0.4121 - mean_squared_error: 0.4121 - val_loss: 0.3732 - val_mean_squared_error: 0.3732\n",
      "Epoch 33/2000\n",
      " - 11s - loss: 0.4097 - mean_squared_error: 0.4097 - val_loss: 0.3736 - val_mean_squared_error: 0.3736\n",
      "Epoch 34/2000\n",
      " - 11s - loss: 0.4076 - mean_squared_error: 0.4076 - val_loss: 0.3741 - val_mean_squared_error: 0.3741\n",
      "Epoch 35/2000\n",
      " - 11s - loss: 0.4056 - mean_squared_error: 0.4056 - val_loss: 0.3741 - val_mean_squared_error: 0.3741\n",
      "Epoch 36/2000\n",
      " - 11s - loss: 0.4037 - mean_squared_error: 0.4037 - val_loss: 0.3735 - val_mean_squared_error: 0.3735\n",
      "Epoch 37/2000\n",
      " - 11s - loss: 0.4014 - mean_squared_error: 0.4014 - val_loss: 0.3732 - val_mean_squared_error: 0.3732\n",
      "Epoch 38/2000\n",
      " - 11s - loss: 0.3993 - mean_squared_error: 0.3993 - val_loss: 0.3734 - val_mean_squared_error: 0.3734\n",
      "Epoch 39/2000\n",
      " - 11s - loss: 0.3976 - mean_squared_error: 0.3976 - val_loss: 0.3731 - val_mean_squared_error: 0.3731\n",
      "Epoch 40/2000\n",
      " - 11s - loss: 0.3964 - mean_squared_error: 0.3964 - val_loss: 0.3732 - val_mean_squared_error: 0.3732\n",
      "Epoch 41/2000\n",
      " - 11s - loss: 0.3947 - mean_squared_error: 0.3947 - val_loss: 0.3732 - val_mean_squared_error: 0.3732\n",
      "Epoch 42/2000\n",
      " - 11s - loss: 0.3929 - mean_squared_error: 0.3929 - val_loss: 0.3723 - val_mean_squared_error: 0.3723\n",
      "Epoch 43/2000\n",
      " - 11s - loss: 0.3913 - mean_squared_error: 0.3913 - val_loss: 0.3731 - val_mean_squared_error: 0.3731\n",
      "Epoch 44/2000\n",
      " - 11s - loss: 0.3897 - mean_squared_error: 0.3897 - val_loss: 0.3724 - val_mean_squared_error: 0.3724\n",
      "Epoch 45/2000\n",
      " - 11s - loss: 0.3879 - mean_squared_error: 0.3879 - val_loss: 0.3728 - val_mean_squared_error: 0.3728\n",
      "Epoch 46/2000\n",
      " - 11s - loss: 0.3867 - mean_squared_error: 0.3867 - val_loss: 0.3735 - val_mean_squared_error: 0.3735\n",
      "Epoch 47/2000\n",
      " - 11s - loss: 0.3852 - mean_squared_error: 0.3852 - val_loss: 0.3742 - val_mean_squared_error: 0.3742\n",
      "Epoch 48/2000\n",
      " - 12s - loss: 0.3835 - mean_squared_error: 0.3835 - val_loss: 0.3728 - val_mean_squared_error: 0.3728\n",
      "Epoch 49/2000\n",
      " - 11s - loss: 0.3829 - mean_squared_error: 0.3829 - val_loss: 0.3744 - val_mean_squared_error: 0.3744\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 50/2000\n",
      " - 12s - loss: 0.3811 - mean_squared_error: 0.3811 - val_loss: 0.3744 - val_mean_squared_error: 0.3744\n",
      "Epoch 51/2000\n",
      " - 11s - loss: 0.3816 - mean_squared_error: 0.3816 - val_loss: 0.3744 - val_mean_squared_error: 0.3744\n",
      "Epoch 52/2000\n",
      " - 11s - loss: 0.3812 - mean_squared_error: 0.3812 - val_loss: 0.3743 - val_mean_squared_error: 0.3743\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "N_EPOCHS = 2000\n",
    "\n",
    "val_pred = []\n",
    "test_pred = []\n",
    "\n",
    "for i in range(16):\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Step %d\" % (i+1))\n",
    "    print(\"=\" * 50)\n",
    "    y = y_train[:, i]\n",
    "    y_mean = y.mean()\n",
    "    xv = X_val\n",
    "    yv = y_val[:, i]\n",
    "    model = build_model()\n",
    "    opt = optimizers.Adam(lr=0.0001) \n",
    "    model.compile(loss='mse', optimizer=opt, metrics=['mse'])\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=10, verbose=0),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, min_delta=1e-4, mode='min')\n",
    "        ]\n",
    "   \n",
    "\n",
    "    model.fit(X_train, y - y_mean, batch_size = 6400, epochs = N_EPOCHS, verbose=2,\n",
    "              validation_data=(xv,yv-y_mean), callbacks=callbacks ) \n",
    "\n",
    "    val_pred.append(model.predict(X_val)+y_mean)\n",
    "    test_pred.append(model.predict(X_test)+y_mean)\n",
    "\n",
    "t1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 回傳建模時間\n",
    "def GetTime(t1,t0):\n",
    "    sec = timedelta(seconds=int(t1-t0))\n",
    "    d = datetime(1,1,1) + sec\n",
    "    print('cpu version elapse time:')\n",
    "    print(\"DAYS:HOURS:MIN:SEC\")\n",
    "    print(\"%d:%d:%d:%d\" % (d.day-1, d.hour, d.minute, d.second))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu version elapse time:\n",
      "DAYS:HOURS:MIN:SEC\n",
      "0:6:14:22\n"
     ]
    }
   ],
   "source": [
    "GetTime(t1,t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mse: 0.36265633274193393\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation mse:\", mean_squared_error(\n",
    "    y_val, np.array(val_pred).squeeze(axis=2).transpose())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nwrmsle = 0.6017403293636413\n"
     ]
    }
   ],
   "source": [
    "weight = items[\"perishable\"] * 0.25 + 1\n",
    "err = (y_val - np.array(val_pred).squeeze(axis=2).transpose())**2\n",
    "err = err.sum(axis=1) * weight\n",
    "err = np.sqrt(err.sum() / weight.sum() / 16)\n",
    "print('nwrmsle = {}'.format(err)) #nwrmsle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. 輸出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making submission...\n"
     ]
    }
   ],
   "source": [
    "print(\"Making submission...\")\n",
    "y_test = np.array(test_pred).squeeze(axis=2).transpose()\n",
    "df_preds = pd.DataFrame(\n",
    "    y_test, index=df_2017.index,\n",
    "    columns=pd.date_range(\"2017-08-16\", periods=16)\n",
    ").stack().to_frame(\"unit_sales\")\n",
    "df_preds.index.set_names([\"store_nbr\", \"item_nbr\", \"date\"], inplace=True)\n",
    "\n",
    "submission = df_test[[\"id\"]].join(df_preds, how=\"left\").fillna(0)\n",
    "submission[\"unit_sales\"] = np.clip(np.expm1(submission[\"unit_sales\"]), 0, 1000)\n",
    "submission.to_csv('NN_10_119c.csv', float_format='%.4f', index=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125497040</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>96995</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125497041</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>99197</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>125497042</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>103501</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>125497043</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>103520</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>125497044</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>103665</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id        date  store_nbr  item_nbr  onpromotion\n",
       "0  125497040  2017-08-16          1     96995        False\n",
       "1  125497041  2017-08-16          1     99197        False\n",
       "2  125497042  2017-08-16          1    103501        False\n",
       "3  125497043  2017-08-16          1    103520        False\n",
       "4  125497044  2017-08-16          1    103665        False"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.merge(test_df,submission,how='left',on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('dataset/train.csv',parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.loc[train_df.date>=pd.datetime(2017,1,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/intel/intelpython3/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "nn_data_2017 = pd.concat([train_df,test_df],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_data_2017.to_csv('nn_data_2017.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = np.array(val_pred).squeeze(axis=2).transpose()\n",
    "df_vals = pd.DataFrame(\n",
    "    y_val, index=df_2017.index,\n",
    "    columns=pd.date_range(\"2017-07-26\", periods=16)\n",
    ").stack().to_frame(\"unit_sales\")\n",
    "df_vals.index.set_names([\"store_nbr\", \"item_nbr\", \"date\"], inplace=True)\n",
    "df_vals[\"unit_sales\"] = np.clip(np.expm1(df_preds[\"unit_sales\"]), 0, 1000)\n",
    "df_vals.reset_index().to_csv('VGGNET_val_cv.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. val與pred_val圖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_pred\n",
    "val_test = np.array(val_pred).squeeze(axis=2).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = pd.DataFrame(\n",
    "    val_test, index=df_2017.index,\n",
    "    columns=pd.date_range(\"2017-07-26\", periods=16)\n",
    ").stack().to_frame(\"unit_sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data=val_preds.reset_index().set_index('level_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data.index.names = ['date']\n",
    "pred_data = pred_data \\\n",
    "    .groupby([\"date\"], as_index=True) \\\n",
    "    .aggregate({\"unit_sales\": \"sum\"})\n",
    "true_data=df_train[(df_train.date>='2017-05-21') & (df_train.date<='2017-08-10')]\n",
    "true_data = true_data \\\n",
    "    .groupby([\"date\"], as_index=True) \\\n",
    "    .aggregate({\"unit_sales\": \"sum\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_unit_sales</th>\n",
       "      <th>pred_unit_sales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-05-21</th>\n",
       "      <td>214874.857718</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-22</th>\n",
       "      <td>172057.169848</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-23</th>\n",
       "      <td>166283.291942</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-24</th>\n",
       "      <td>164415.488436</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-25</th>\n",
       "      <td>152391.272447</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-26</th>\n",
       "      <td>194863.341801</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-27</th>\n",
       "      <td>192781.623115</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-28</th>\n",
       "      <td>203012.928701</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-29</th>\n",
       "      <td>171622.946610</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-30</th>\n",
       "      <td>167896.255093</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-31</th>\n",
       "      <td>179100.076582</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-01</th>\n",
       "      <td>175396.914193</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-02</th>\n",
       "      <td>186411.476125</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-03</th>\n",
       "      <td>216182.873469</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-04</th>\n",
       "      <td>227544.935753</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-05</th>\n",
       "      <td>182722.489487</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-06</th>\n",
       "      <td>172596.564520</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-07</th>\n",
       "      <td>172300.369443</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-08</th>\n",
       "      <td>155259.683557</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-09</th>\n",
       "      <td>168459.509175</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-10</th>\n",
       "      <td>196036.317962</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-11</th>\n",
       "      <td>212332.700096</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-12</th>\n",
       "      <td>167782.360852</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-13</th>\n",
       "      <td>162847.692208</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-14</th>\n",
       "      <td>165220.834969</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-15</th>\n",
       "      <td>158763.114150</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-16</th>\n",
       "      <td>175426.614864</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-17</th>\n",
       "      <td>208119.019927</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-18</th>\n",
       "      <td>192223.913386</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-19</th>\n",
       "      <td>173279.982469</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-12</th>\n",
       "      <td>165009.362778</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-13</th>\n",
       "      <td>151734.104311</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-14</th>\n",
       "      <td>166900.312271</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-15</th>\n",
       "      <td>194846.162183</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-16</th>\n",
       "      <td>203338.869094</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-17</th>\n",
       "      <td>175072.912500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-18</th>\n",
       "      <td>164578.147310</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-19</th>\n",
       "      <td>165430.770565</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-20</th>\n",
       "      <td>159647.658844</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-21</th>\n",
       "      <td>168005.682645</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-22</th>\n",
       "      <td>190105.649241</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-23</th>\n",
       "      <td>196660.019618</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-24</th>\n",
       "      <td>175781.908351</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-25</th>\n",
       "      <td>163300.002204</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-26</th>\n",
       "      <td>162058.997103</td>\n",
       "      <td>161229.468750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-27</th>\n",
       "      <td>151813.416802</td>\n",
       "      <td>148349.984375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-28</th>\n",
       "      <td>171258.644533</td>\n",
       "      <td>162881.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-29</th>\n",
       "      <td>197266.629849</td>\n",
       "      <td>194091.703125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-30</th>\n",
       "      <td>202177.608623</td>\n",
       "      <td>203795.593750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-31</th>\n",
       "      <td>181851.023491</td>\n",
       "      <td>169485.703125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-01</th>\n",
       "      <td>193035.736539</td>\n",
       "      <td>162273.046875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-02</th>\n",
       "      <td>187371.332188</td>\n",
       "      <td>159262.156250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-03</th>\n",
       "      <td>166133.002347</td>\n",
       "      <td>149759.468750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-04</th>\n",
       "      <td>174868.768363</td>\n",
       "      <td>161550.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-05</th>\n",
       "      <td>195610.308390</td>\n",
       "      <td>193909.484375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-06</th>\n",
       "      <td>200435.667263</td>\n",
       "      <td>201063.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-07</th>\n",
       "      <td>173651.856413</td>\n",
       "      <td>173555.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-08</th>\n",
       "      <td>164277.118193</td>\n",
       "      <td>161939.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-09</th>\n",
       "      <td>163976.009450</td>\n",
       "      <td>158573.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-10</th>\n",
       "      <td>154912.084496</td>\n",
       "      <td>149373.781250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            true_unit_sales  pred_unit_sales\n",
       "date                                        \n",
       "2017-05-21    214874.857718              NaN\n",
       "2017-05-22    172057.169848              NaN\n",
       "2017-05-23    166283.291942              NaN\n",
       "2017-05-24    164415.488436              NaN\n",
       "2017-05-25    152391.272447              NaN\n",
       "2017-05-26    194863.341801              NaN\n",
       "2017-05-27    192781.623115              NaN\n",
       "2017-05-28    203012.928701              NaN\n",
       "2017-05-29    171622.946610              NaN\n",
       "2017-05-30    167896.255093              NaN\n",
       "2017-05-31    179100.076582              NaN\n",
       "2017-06-01    175396.914193              NaN\n",
       "2017-06-02    186411.476125              NaN\n",
       "2017-06-03    216182.873469              NaN\n",
       "2017-06-04    227544.935753              NaN\n",
       "2017-06-05    182722.489487              NaN\n",
       "2017-06-06    172596.564520              NaN\n",
       "2017-06-07    172300.369443              NaN\n",
       "2017-06-08    155259.683557              NaN\n",
       "2017-06-09    168459.509175              NaN\n",
       "2017-06-10    196036.317962              NaN\n",
       "2017-06-11    212332.700096              NaN\n",
       "2017-06-12    167782.360852              NaN\n",
       "2017-06-13    162847.692208              NaN\n",
       "2017-06-14    165220.834969              NaN\n",
       "2017-06-15    158763.114150              NaN\n",
       "2017-06-16    175426.614864              NaN\n",
       "2017-06-17    208119.019927              NaN\n",
       "2017-06-18    192223.913386              NaN\n",
       "2017-06-19    173279.982469              NaN\n",
       "...                     ...              ...\n",
       "2017-07-12    165009.362778              NaN\n",
       "2017-07-13    151734.104311              NaN\n",
       "2017-07-14    166900.312271              NaN\n",
       "2017-07-15    194846.162183              NaN\n",
       "2017-07-16    203338.869094              NaN\n",
       "2017-07-17    175072.912500              NaN\n",
       "2017-07-18    164578.147310              NaN\n",
       "2017-07-19    165430.770565              NaN\n",
       "2017-07-20    159647.658844              NaN\n",
       "2017-07-21    168005.682645              NaN\n",
       "2017-07-22    190105.649241              NaN\n",
       "2017-07-23    196660.019618              NaN\n",
       "2017-07-24    175781.908351              NaN\n",
       "2017-07-25    163300.002204              NaN\n",
       "2017-07-26    162058.997103    161229.468750\n",
       "2017-07-27    151813.416802    148349.984375\n",
       "2017-07-28    171258.644533    162881.062500\n",
       "2017-07-29    197266.629849    194091.703125\n",
       "2017-07-30    202177.608623    203795.593750\n",
       "2017-07-31    181851.023491    169485.703125\n",
       "2017-08-01    193035.736539    162273.046875\n",
       "2017-08-02    187371.332188    159262.156250\n",
       "2017-08-03    166133.002347    149759.468750\n",
       "2017-08-04    174868.768363    161550.687500\n",
       "2017-08-05    195610.308390    193909.484375\n",
       "2017-08-06    200435.667263    201063.125000\n",
       "2017-08-07    173651.856413    173555.062500\n",
       "2017-08-08    164277.118193    161939.062500\n",
       "2017-08-09    163976.009450    158573.890625\n",
       "2017-08-10    154912.084496    149373.781250\n",
       "\n",
       "[82 rows x 2 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_plot = pd.concat([true_data,pred_data],axis=1, join_axes=[true_data.index])\n",
    "df_plot.columns = ['true_unit_sales', 'pred_unit_sales']\n",
    "df_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "sns.set_color_codes(\"pastel\")\n",
    "g=sns.pointplot(x=df_plot.index, y=\"pred_unit_sales\", data=df_plot,color='#CA972C',markers='p')\n",
    "sns.pointplot(x=df_plot.index, y=\"true_unit_sales\", data=df_plot,color='#FEBBAA',markers='p',linestyles='--')\n",
    "plt.autoscale()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
